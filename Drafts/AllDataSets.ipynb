{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AllDataSets.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "10Q4C9D1TtT6",
        "q2DUzfTBVGDh",
        "LftfGaf7VxA5",
        "IC8WTXSKWG4Y"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alymostafa/Nlp_task/blob/main/AllDataSets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10Q4C9D1TtT6"
      },
      "source": [
        "##weights and biases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS4H24CcTb3m",
        "outputId": "a67716b0-520b-45ed-8403-6ee84d39dc9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install  wandb"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/14/9a2c792e48e01e55913b9495ce0e8a16297e2bc1cc99e86a848d205c91e7/wandb-0.10.5-py2.py3-none-any.whl (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7MB 6.4MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from wandb) (3.13)\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 15.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.8.1)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/08/b2/ef713e0e67f6e7ec7d59aea3ee78d05b39c15930057e724cc6d362a8c3bb/configparser-5.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.1.2)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/df/1145dc9389138eb47649806b42aaad5b0ecdfd3e93c7c51c1fffd80a8f90/sentry_sdk-0.18.0-py2.py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 43.6MB/s \n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/d7/b2b0672e0331567157adf9281f41ee731c412ee518ca5e6552c27fa73c91/GitPython-3.1.9-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 39.3MB/s \n",
            "\u001b[?25hCollecting watchdog>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/06/121302598a4fc01aca942d937f4a2c33430b7181137b35758913a8db10ad/watchdog-0.10.3.tar.gz (94kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.12.0->wandb) (50.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.6.20)\n",
            "Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.8MB/s \n",
            "\u001b[?25hCollecting pathtools>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: subprocess32, watchdog, pathtools\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp36-none-any.whl size=6489 sha256=03dac6a84cc2622c7b072ed7c1389bd4ca34a3ab9125d415dfd72fd090a3f948\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for watchdog: filename=watchdog-0.10.3-cp36-none-any.whl size=73873 sha256=0075b83e7a51be98c9b1954bd2143206180dc6e5c368dc4fc98ccee731305535\n",
            "  Stored in directory: /root/.cache/pip/wheels/a8/1d/38/2c19bb311f67cc7b4d07a2ec5ea36ab1a0a0ea50db994a5bc7\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8785 sha256=b2ceb7f85937d40204c319be0b605d3fb56c02f025c65c40134b4f82c8d7df52\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "Successfully built subprocess32 watchdog pathtools\n",
            "Installing collected packages: docker-pycreds, subprocess32, configparser, shortuuid, sentry-sdk, smmap, gitdb, GitPython, pathtools, watchdog, wandb\n",
            "Successfully installed GitPython-3.1.9 configparser-5.0.1 docker-pycreds-0.4.0 gitdb-4.0.5 pathtools-0.1.2 sentry-sdk-0.18.0 shortuuid-1.0.1 smmap-3.0.4 subprocess32-3.5.4 wandb-0.10.5 watchdog-0.10.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXhzr-ddTytT",
        "outputId": "17216484-8b5b-40ab-a451-bd140f8a2225",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "!wandb login "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2DUzfTBVGDh"
      },
      "source": [
        "##imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KQyzsfVTSu7",
        "outputId": "f709625a-03f3-46b5-a133-e84c739b5cfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "from pprint import pprint\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import os, sys\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from collections import defaultdict\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import names\n",
        "import nltk\n",
        "nltk.download('names')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import re \n",
        "from nltk.corpus import stopwords\n",
        "#from sklearn.datasets import fetch_rcv1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/names.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LftfGaf7VxA5"
      },
      "source": [
        "##<h1>First DataSets</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMB81FoajP3E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlZaGfDMjP0Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9FSY4FJjPXY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlsdfEhcTa5U"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import pandas as pd\n",
        "def twenty_newsgroup_to_csv(data,name):\n",
        "    newsgroups_train = fetch_20newsgroups(subset= data , remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "    df = pd.DataFrame([newsgroups_train.data, newsgroups_train.target.tolist()]).T\n",
        "    df.columns = ['text', 'target']\n",
        "\n",
        "    targets = pd.DataFrame( newsgroups_train.target_names)\n",
        "    targets.columns=['title']\n",
        "\n",
        "    out = pd.merge(df, targets, left_on='target', right_index=True)\n",
        "    out['date'] = pd.to_datetime('now')\n",
        "    out.to_csv(name+'.csv')\n",
        "\n",
        "twenty_newsgroup_to_csv('train','train')\n",
        "twenty_newsgroup_to_csv('test','test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUh0cOm6VOTn"
      },
      "source": [
        "df = pd.read_csv(\"train.csv\")\n",
        "df_test = pd.read_csv(\"test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTKU_zQ0VQQF"
      },
      "source": [
        "df.dropna(subset = [\"text\"], inplace=True)\n",
        "df_test.dropna(subset = [\"text\"], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfCWwSQaVR2U"
      },
      "source": [
        "all_names = names.words()\n",
        "WNL = WordNetLemmatizer()\n",
        "def clean(data):\n",
        "    cleaned = defaultdict(list)\n",
        "    count = 0\n",
        "    for group in data:\n",
        "        for words in group.split():\n",
        "            if words.isalpha() and words not in all_names:\n",
        "                cleaned[count].append(WNL.lemmatize(words.lower()))\n",
        "        cleaned[count] = ' '.join(cleaned[count])\n",
        "        count +=1 \n",
        "    return(list(cleaned.values()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-caJuK8-VT-e"
      },
      "source": [
        "df['text'] = clean(df['text'])\n",
        "df_test['text'] = clean(df_test['text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecqTmBE_VYB3",
        "outputId": "6cc47fc7-50f3-4d23-a577-fc22be24df79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(len(df))\n",
        "print(len(df_test))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11096\n",
            "7370\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Cfx_qrTc4uZ"
      },
      "source": [
        "df.drop(labels=['target','date'],axis=1,inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mSVxTOLdYgF"
      },
      "source": [
        "df_test.drop(labels=['target','date'],axis=1,inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC8WTXSKWG4Y"
      },
      "source": [
        "##<h1>Second Dataset</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnQjj487WGV1",
        "outputId": "92684f61-7975-4414-97f3-8275a9eb0eec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "nltk.download('reuters')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords, reuters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qNHmTA4WGZt"
      },
      "source": [
        "documents = reuters.fileids()\n",
        " \n",
        "train_docs_id = list(filter(lambda doc: doc.startswith(\"train\"),\n",
        "                            documents))\n",
        "test_docs_id = list(filter(lambda doc: doc.startswith(\"test\"),\n",
        "                           documents))\n",
        " \n",
        "train_docs = [reuters.raw(doc_id) for doc_id in train_docs_id]\n",
        "test_docs = [reuters.raw(doc_id) for doc_id in test_docs_id]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWlWSSVnWvni"
      },
      "source": [
        "docs_pdf_train = pd.DataFrame(train_docs) \n",
        "docs_pdf_test = pd.DataFrame(test_docs) \n",
        "docs_pdf_train['text'] = pd.DataFrame(train_docs) \n",
        "docs_pdf_test['text'] = pd.DataFrame(test_docs) \n",
        "docs_pdf_train.drop([docs_pdf_train.columns[0]], axis ='columns',inplace=True)\n",
        "docs_pdf_test.drop([docs_pdf_test.columns[0]], axis ='columns',inplace=True)\n",
        "docs_pdf_train.dropna(inplace=True)\n",
        "docs_pdf_test.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9fJXsNgWxXl"
      },
      "source": [
        "docs_pdf_train.dropna(subset = [\"text\"], inplace=True)\n",
        "docs_pdf_train.replace(r'-', ' ', regex=True,inplace=True)\n",
        "docs_pdf_train.replace(r'\\t', ' ', regex=True,inplace=True)\n",
        "docs_pdf_train.replace(r'\\n', ' ', regex=True,inplace=True)\n",
        "docs_pdf_train.replace(r'   ', ' ', regex=True,inplace=True)\n",
        "docs_pdf_test.replace(r'-', ' ', regex=True,inplace=True)\n",
        "docs_pdf_test.replace(r'\\t', ' ', regex=True,inplace=True)\n",
        "docs_pdf_test.replace(r'\\n', ' ', regex=True,inplace=True)\n",
        "docs_pdf_test.replace(r'   ', ' ', regex=True,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhPS757oWzAE"
      },
      "source": [
        "docs_pdf_train['text'] = clean(docs_pdf_train['text'])\n",
        "docs_pdf_test['text'] = clean(docs_pdf_test['text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz_dt1BFW-wj"
      },
      "source": [
        "train_labels = [reuters.categories(doc_id)for doc_id in train_docs_id]\n",
        "test_labels = [reuters.categories(doc_id)for doc_id in test_docs_id]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm-V3oLvXf0X"
      },
      "source": [
        "achedStopWords = stopwords.words(\"english\")\n",
        " \n",
        "def tokenize(text):\n",
        "  min_length = 3\n",
        "  words = map(lambda word: word.lower(), word_tokenize(text))\n",
        "  words = [word for word in words if word not in achedStopWords]\n",
        "  tokens = (list(map(lambda token: PorterStemmer().stem(token),\n",
        "                                   words)))\n",
        "  p = re.compile('[a-zA-Z]+');\n",
        "  filtered_tokens =list(filter (lambda token: p.match(token) and\n",
        "                               len(token) >= min_length,\n",
        "                               tokens))\n",
        "  return filtered_tokens\n",
        "\n",
        "def word_tokenizer():\n",
        "  tokenize_docs = []\n",
        "  docs_tokens = docs_pdf_train['text'].tolist()\n",
        "  length = len(docs_tokens)\n",
        "  for i in range(length):\n",
        "    tokenize_docs.append(tokenize(docs_tokens[i]))\n",
        "  return tokenize_docs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGBstEu1Xlg7"
      },
      "source": [
        "tokenize_docs = word_tokenizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZbeJ_w7XnJV"
      },
      "source": [
        "def word_tokenizer_test():\n",
        "  tokenize_docs = []\n",
        "  docs_tokens = docs_pdf_test['text'].tolist()\n",
        "  length = len(docs_tokens)\n",
        "  for i in range(length):\n",
        "    tokenize_docs.append(tokenize(docs_tokens[i]))\n",
        "  return tokenize_docs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qrk2e6C-Yigy"
      },
      "source": [
        "tokenize_docs_test = word_tokenizer_test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX5V-zHeZBRO"
      },
      "source": [
        "df_train_2=pd.DataFrame(docs_pdf_train,columns=['text'])\n",
        "df_train_2['target']=''\n",
        "df_train_2['target']=train_labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlA8Zg9lZS8b",
        "outputId": "df9c038e-8bd7-46c0-87ac-9e2ad78f8aba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "df_test_2=pd.DataFrame(docs_pdf_test,columns=['text'])\n",
        "df_test_2['target']=''\n",
        "df_test_2['target']=test_labels\n",
        "df_test_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>asian exporter fear damage from japan rift mou...</td>\n",
              "      <td>[trade]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>china daily say vermin eat pct grain stock a s...</td>\n",
              "      <td>[grain]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>japan to revise long term energy demand downwa...</td>\n",
              "      <td>[crude, nat-gas]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>thai trade deficit widens in first quarter tra...</td>\n",
              "      <td>[corn, grain, rice, rubber, sugar, tin, trade]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>indonesia see cpo price rising sharply indones...</td>\n",
              "      <td>[palm-oil, veg-oil]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3014</th>\n",
              "      <td>chase corp make offer for entregrowth corp ltd...</td>\n",
              "      <td>[acq]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3015</th>\n",
              "      <td>tokyo dealer see dollar poised to breach yen f...</td>\n",
              "      <td>[dlr, money-fx, yen]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3016</th>\n",
              "      <td>conference cut gulf war risk charge the pakist...</td>\n",
              "      <td>[ship]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3017</th>\n",
              "      <td>soviet industrial slower in the soviet industr...</td>\n",
              "      <td>[ipi]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3018</th>\n",
              "      <td>six killed in south african gold mine accident...</td>\n",
              "      <td>[gold]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3019 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text                                          target\n",
              "0     asian exporter fear damage from japan rift mou...                                         [trade]\n",
              "1     china daily say vermin eat pct grain stock a s...                                         [grain]\n",
              "2     japan to revise long term energy demand downwa...                                [crude, nat-gas]\n",
              "3     thai trade deficit widens in first quarter tra...  [corn, grain, rice, rubber, sugar, tin, trade]\n",
              "4     indonesia see cpo price rising sharply indones...                             [palm-oil, veg-oil]\n",
              "...                                                 ...                                             ...\n",
              "3014  chase corp make offer for entregrowth corp ltd...                                           [acq]\n",
              "3015  tokyo dealer see dollar poised to breach yen f...                            [dlr, money-fx, yen]\n",
              "3016  conference cut gulf war risk charge the pakist...                                          [ship]\n",
              "3017  soviet industrial slower in the soviet industr...                                           [ipi]\n",
              "3018  six killed in south african gold mine accident...                                          [gold]\n",
              "\n",
              "[3019 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H80bi5mJdij8"
      },
      "source": [
        "df_train_2.rename(columns={'target':'title'},inplace=True)\n",
        "df_test_2.rename(columns={'target':'title'},inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtSPEEMJbkT2"
      },
      "source": [
        "frames_train=[df,df_train_2]\n",
        "frames_test=[df_test,df_test_2]\n",
        "all_dataframes_train=pd.concat(frames_train,keys=['x','y'])\n",
        "all_dataframes_test=pd.concat(frames_test,keys=['x','y'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hD4urXUcO-j"
      },
      "source": [
        "all_dataframes_train.drop(labels='Unnamed: 0',inplace=True,axis=1)\n",
        "all_dataframes_test.drop(labels='Unnamed: 0',inplace=True,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LC1-CTjwf73w"
      },
      "source": [
        "##Bert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByKWd3XifaR-",
        "outputId": "38cbe426-398a-4d46-f1a5-f26ba254fe0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        }
      },
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "wandb.init(project=\"nlp-task\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DEBUG:git.cmd:Popen(['git', 'version'], cwd=/content, universal_newlines=False, shell=None, istream=None)\n",
            "DEBUG:git.cmd:Popen(['git', 'version'], cwd=/content, universal_newlines=False, shell=None, istream=None)\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
            "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 None\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 172.28.0.2:9000\n",
            "DEBUG:urllib3.connectionpool:http://172.28.0.2:9000 \"GET /api/sessions?token= HTTP/1.1\" 200 508\n",
            "INFO:wandb:setting login settings: {}\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malymostafa\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.5<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">logical-puddle-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/alymostafa/nlp-task\" target=\"_blank\">https://wandb.ai/alymostafa/nlp-task</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/alymostafa/nlp-task/runs/387blejf\" target=\"_blank\">https://wandb.ai/alymostafa/nlp-task/runs/387blejf</a><br/>\n",
              "                Run data is saved locally in <code>wandb/run-20201010_202458-387blejf</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f4d27a4a8d0>"
            ],
            "text/html": [
              "<h1>Run(387blejf)</h1><p></p><iframe src=\"https://wandb.ai/alymostafa/nlp-task/runs/387blejf\" style=\"border:none;width:100%;height:400px\"></iframe>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5v3uYAsgKhg",
        "outputId": "5d9fe0dc-e023-4b7f-c7e8-7be38c0aabe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install 'kashgari>=2.0.0'\t"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kashgari>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/81/c638e3b166bcaaf4e1a86502dcca5912b15bc51db4b5235031df3b55565e/kashgari-2.0.0-py3-none-any.whl (85kB)\n",
            "\r\u001b[K     |███▉                            | 10kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 20kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 30kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 40kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 51kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 61kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 81kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kashgari>=2.0.0) (4.41.1)\n",
            "Requirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from kashgari>=2.0.0) (2.3.0)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from kashgari>=2.0.0) (1.1.2)\n",
            "Collecting bert4keras>=0.7.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/ef/1b0f236ba7b98197ee0878b445535ffa9e49a3166259431a6c2c2095fa01/bert4keras-0.8.8.tar.gz (40kB)\n",
            "\u001b[K     |████████████████████████████████| 40kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-addons in /usr/local/lib/python3.6/dist-packages (from kashgari>=2.0.0) (0.8.3)\n",
            "Collecting gensim>=3.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/e0/fa6326251692056dc880a64eb22117e03269906ba55a6864864d24ec8b4e/gensim-3.8.3-cp36-cp36m-manylinux1_x86_64.whl (24.2MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2MB 110kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.6/dist-packages (from kashgari>=2.0.0) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from kashgari>=2.0.0) (0.22.2.post1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->kashgari>=2.0.0) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->kashgari>=2.0.0) (2.3.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->kashgari>=2.0.0) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->kashgari>=2.0.0) (3.12.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->kashgari>=2.0.0) (0.35.1)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->kashgari>=2.0.0) (2.10.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->kashgari>=2.0.0) (1.6.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->kashgari>=2.0.0) (1.32.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->kashgari>=2.0.0) (0.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->kashgari>=2.0.0) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->kashgari>=2.0.0) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->kashgari>=2.0.0) (2.3.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->kashgari>=2.0.0) (1.4.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->kashgari>=2.0.0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->kashgari>=2.0.0) (1.15.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->kashgari>=2.0.0) (0.3.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.1->kashgari>=2.0.0) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.1->kashgari>=2.0.0) (2.8.1)\n",
            "Collecting keras<=2.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 48.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons->kashgari>=2.0.0) (2.7.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.8.1->kashgari>=2.0.0) (2.2.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.1->kashgari>=2.0.0) (0.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow>=2.1.0->kashgari>=2.0.0) (50.3.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (0.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (1.7.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (1.17.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (1.0.1)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras>=0.7.9->kashgari>=2.0.0) (3.13)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (4.6)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (2020.6.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (3.2.0)\n",
            "Building wheels for collected packages: bert4keras\n",
            "  Building wheel for bert4keras (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert4keras: filename=bert4keras-0.8.8-cp36-none-any.whl size=39383 sha256=9555bc175406af7cb0418b73e00df670a0e7838b003521af8afab293554be31d\n",
            "  Stored in directory: /root/.cache/pip/wheels/6f/07/52/94c66529c3cee3757d96608bb593adbe623b6f29881bec342b\n",
            "Successfully built bert4keras\n",
            "Installing collected packages: keras-applications, keras, bert4keras, gensim, kashgari\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "  Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed bert4keras-0.8.8 gensim-3.8.3 kashgari-2.0.0 keras-2.3.1 keras-applications-1.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypzt10uwf-PA"
      },
      "source": [
        "import logging\n",
        "from kashgari.embeddings import BertEmbedding\n",
        "from kashgari.tasks.classification import BiGRU_Model\n",
        "from kashgari.tasks.classification import BiLSTM_Model\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSVnaPskgF9U"
      },
      "source": [
        "logging.basicConfig(level='DEBUG')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjsemvPngPWn",
        "outputId": "f7dd7da7-734f-4a6d-e10b-6ef345c285ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-10 20:21:45--  https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.195.128, 74.125.28.128, 74.125.142.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.195.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 407727028 (389M) [application/zip]\n",
            "Saving to: ‘uncased_L-12_H-768_A-12.zip’\n",
            "\n",
            "uncased_L-12_H-768_ 100%[===================>] 388.84M   140MB/s    in 2.8s    \n",
            "\n",
            "2020-10-10 20:21:48 (140 MB/s) - ‘uncased_L-12_H-768_A-12.zip’ saved [407727028/407727028]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NeVZMiSgSBB",
        "outputId": "89dbf04e-d418-4694-f7b4-852dfc0fbace",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "!unzip '/content/uncased_L-12_H-768_A-12.zip'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/uncased_L-12_H-768_A-12.zip\n",
            "   creating: uncased_L-12_H-768_A-12/\n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: uncased_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_config.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVabElOcgTp4",
        "outputId": "1743650f-f3fc-488a-b824-413ce90f5b16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "bert_embed = BertEmbedding('/content/uncased_L-12_H-768_A-12')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-10 20:21:53,406 [DEBUG] kashgari - ------------------------------------------------\n",
            "2020-10-10 20:21:53,408 [DEBUG] kashgari - Loaded transformer model's vocab\n",
            "2020-10-10 20:21:53,409 [DEBUG] kashgari - config_path       : /content/uncased_L-12_H-768_A-12/bert_config.json\n",
            "2020-10-10 20:21:53,410 [DEBUG] kashgari - vocab_path      : /content/uncased_L-12_H-768_A-12/vocab.txt\n",
            "2020-10-10 20:21:53,411 [DEBUG] kashgari - checkpoint_path : /content/uncased_L-12_H-768_A-12/bert_model.ckpt\n",
            "2020-10-10 20:21:53,413 [DEBUG] kashgari - Top 50 words    : ['[PAD]', '[unused0]', '[unused1]', '[unused2]', '[unused3]', '[unused4]', '[unused5]', '[unused6]', '[unused7]', '[unused8]', '[unused9]', '[unused10]', '[unused11]', '[unused12]', '[unused13]', '[unused14]', '[unused15]', '[unused16]', '[unused17]', '[unused18]', '[unused19]', '[unused20]', '[unused21]', '[unused22]', '[unused23]', '[unused24]', '[unused25]', '[unused26]', '[unused27]', '[unused28]', '[unused29]', '[unused30]', '[unused31]', '[unused32]', '[unused33]', '[unused34]', '[unused35]', '[unused36]', '[unused37]', '[unused38]', '[unused39]', '[unused40]', '[unused41]', '[unused42]', '[unused43]', '[unused44]', '[unused45]', '[unused46]', '[unused47]', '[unused48]']\n",
            "2020-10-10 20:21:53,415 [DEBUG] kashgari - ------------------------------------------------\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EV_emcz0gVvg"
      },
      "source": [
        "model = BiLSTM_Model(bert_embed)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMr2gDSMgi2x",
        "outputId": "a07fa219-bd95-4622-e9c4-bb26469134cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "source": [
        "toknize_train=all_dataframes_train['text'].tolist()\n",
        "toknize_train=[i.split(' ') for i in toknize_train]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-b06369afb0f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtoknize_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_dataframes_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtoknize_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoknize_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'all_dataframes_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XgK9Bi4gju6",
        "outputId": "7d9df6ec-4c74-4675-aab2-c8d1dc6f0621",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "source": [
        "modifed_list_labels=all_dataframes_train['title'][:11096].tolist()\n",
        "modifed_list_labels=[[i] for i in modifed_list_labels]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-4ce75dea4437>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodifed_list_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_dataframes_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m11096\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodifed_list_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodifed_list_labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'all_dataframes_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr7s-vOGoKtg"
      },
      "source": [
        "all_dataframes_train['title'][:11096]=modifed_list_labels\n",
        "train_labels_=all_dataframes_train['title'].tolist()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttWV252whBCw"
      },
      "source": [
        "toknize_test=all_dataframes_test['text'].tolist()\n",
        "toknize_test=[i.split(' ') for i in toknize_test]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFKoNncbibH0"
      },
      "source": [
        "modifed_list_labels_test=all_dataframes_test['title'][:7370].tolist()\n",
        "modifed_list_labels_test=[[i] for i in modifed_list_labels_test]\n",
        "all_dataframes_test['title'][:7370]=modifed_list_labels_test\n",
        "test_labels_=all_dataframes_test['title'].tolist()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80S1L3sHRn5M"
      },
      "source": [
        "##Wikipedia Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnZVPcjkR0GU",
        "outputId": "11fbd214-0541-4df7-e635-64e627be9e41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize \n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english')) "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaNw3Js1R56u"
      },
      "source": [
        "df=pd.read_csv(\"/content/all_dataset_fin.csv\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMScuvFzPuHu",
        "outputId": "c7deab8c-3674-4f01-bd38-4eb73ea845f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        }
      },
      "source": [
        "df[df['title']=='Miscellaneous']"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>116</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['the', 'miscellaneous', 'was', 'a', 's', 'alt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>117</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['nasa', 'test', 'aircraft', 'the', 'mil', 'mi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>118</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['aviation', 'is', 'the', 'practical', 'aspect...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>119</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['animals', 'are', 'multicellular', 'eukaryoti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>120</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['some', 'of', 'the', 'trophies', 'earned', 'b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>121</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['obverse', 'of', 'medal', 'distributed', 'by'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>122</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['farmland', 'in', 'the', 'united', 'states', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>123</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['fields', 'in', 'z', 'horie', 'slovakia', 'a'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>124</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['various', 'foods', 'foods', 'from', 'plant',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>125</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['the', 'nutrition', 'facts', 'table', 'displa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>126</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['foundation', 'may', 'refer', 'to', 'literatu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>127</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['__notoc__', 'a', 'journal', 'through', 'fren...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>128</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['photography', 'is', 'the', 'science', 'art',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>129</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['imaging', 'is', 'the', 'representation', 'or...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>130</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['artwork', 'by', 'david', 'revoy', 'for', 'th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>131</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['a', 'shipping', 'line', 'is', 'a', 'business...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>132</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['sailing', 'employs', 'the', 'wind', 'acting'...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0  ...                                               text\n",
              "116         116  ...  ['the', 'miscellaneous', 'was', 'a', 's', 'alt...\n",
              "117         117  ...  ['nasa', 'test', 'aircraft', 'the', 'mil', 'mi...\n",
              "118         118  ...  ['aviation', 'is', 'the', 'practical', 'aspect...\n",
              "119         119  ...  ['animals', 'are', 'multicellular', 'eukaryoti...\n",
              "120         120  ...  ['some', 'of', 'the', 'trophies', 'earned', 'b...\n",
              "121         121  ...  ['obverse', 'of', 'medal', 'distributed', 'by'...\n",
              "122         122  ...  ['farmland', 'in', 'the', 'united', 'states', ...\n",
              "123         123  ...  ['fields', 'in', 'z', 'horie', 'slovakia', 'a'...\n",
              "124         124  ...  ['various', 'foods', 'foods', 'from', 'plant',...\n",
              "125         125  ...  ['the', 'nutrition', 'facts', 'table', 'displa...\n",
              "126         126  ...  ['foundation', 'may', 'refer', 'to', 'literatu...\n",
              "127         127  ...  ['__notoc__', 'a', 'journal', 'through', 'fren...\n",
              "128         128  ...  ['photography', 'is', 'the', 'science', 'art',...\n",
              "129         129  ...  ['imaging', 'is', 'the', 'representation', 'or...\n",
              "130         130  ...  ['artwork', 'by', 'david', 'revoy', 'for', 'th...\n",
              "131         131  ...  ['a', 'shipping', 'line', 'is', 'a', 'business...\n",
              "132         132  ...  ['sailing', 'employs', 'the', 'wind', 'acting'...\n",
              "\n",
              "[17 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw3fehuj82SI",
        "outputId": "df324a37-c59f-44c8-d1c4-408955b84a48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "df['title'].unique()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Academic_Science', 'Business', 'Community', 'Computing',\n",
              "       'Governmental', 'Miscellaneous', 'Medical'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwN88yEHyVzX"
      },
      "source": [
        "Academic_Science = df[df['title']=='Academic_Science']\n",
        "Business = df[df['title']=='Business']\n",
        "Community = df[df['title']=='Community']\n",
        "Computing = df[df['title']=='Computing']\n",
        "Governmental = df[df['title']=='Governmental']\n",
        "Miscellaneous = df[df['title']=='Miscellaneous']\n",
        "Medical = df[df['title']=='Medical']"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CQXJXcP5uLv"
      },
      "source": [
        "list_Academic_Science = list(Academic_Science['text'])\n",
        "list_Business = list(Business['text'])\n",
        "list_Community = list(Community['text'])\n",
        "list_Computing = list(Computing['text'])\n",
        "list_Governmental = list(Governmental['text'])\n",
        "list_Miscellaneous = list(Miscellaneous['text'])\n",
        "list_Medical = list(Medical['text'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ-fgw_U5uI0"
      },
      "source": [
        "import ast\n",
        "list_Academic_Science=[ast.literal_eval(i) for i in list_Academic_Science]\n",
        "list_Business=[ast.literal_eval(i) for i in list_Business]\n",
        "list_Community=[ast.literal_eval(i) for i in list_Community]\n",
        "list_Computing=[ast.literal_eval(i) for i in list_Computing]\n",
        "list_Governmental=[ast.literal_eval(i) for i in list_Governmental]\n",
        "list_Miscellaneous=[ast.literal_eval(i) for i in list_Miscellaneous]\n",
        "list_Medical=[ast.literal_eval(i) for i in list_Medical]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "145d1bDMl_qy"
      },
      "source": [
        "list_Academic_Science_filtered_list=[]\n",
        "list_Academic_Science_filtered= [] \n",
        "for w in list_Academic_Science:\n",
        "  for j in w:\n",
        "    if j not in stop_words: \n",
        "      list_Academic_Science_filtered.append(j)\n",
        "  list_Academic_Science_filtered_list.append(list_Academic_Science_filtered)\n",
        "\n",
        "\n",
        "list_Business_filtered_list=[]\n",
        "list_Business_filtered= [] \n",
        "for w in list_Business:\n",
        "  for j in w:\n",
        "    if j not in stop_words: \n",
        "      list_Business_filtered.append(j)\n",
        "  list_Business_filtered_list.append(list_Business_filtered)\n",
        "\n",
        "\n",
        "list_Community_filtered_list=[]\n",
        "list_Community_filtered= [] \n",
        "for w in list_Community:\n",
        "  for j in w:\n",
        "    if j not in stop_words: \n",
        "      list_Community_filtered.append(j)\n",
        "  list_Community_filtered_list.append(list_Community_filtered)\n",
        "\n",
        "list_Computing_filtered_list=[]\n",
        "list_Computing_filtered= [] \n",
        "for w in list_Computing:\n",
        "  for j in w:\n",
        "    if j not in stop_words: \n",
        "      list_Computing_filtered.append(j)\n",
        "  list_Computing_filtered_list.append(list_Computing_filtered)\n",
        "\n",
        "\n",
        "list_Governmental_filtered_list=[]\n",
        "list_Governmental_filtered= [] \n",
        "for w in list_Governmental:\n",
        "  for j in w:\n",
        "    if j not in stop_words: \n",
        "      list_Governmental_filtered.append(j)\n",
        "  list_Governmental_filtered_list.append(list_Governmental_filtered)\n",
        "\n",
        "\n",
        "list_Miscellaneous_filtered_list=[]\n",
        "list_Miscellaneous_filtered= [] \n",
        "for w in list_Miscellaneous:\n",
        "  for j in w:\n",
        "    if j not in stop_words: \n",
        "      list_Miscellaneous_filtered.append(j)\n",
        "  list_Miscellaneous_filtered_list.append(list_Miscellaneous_filtered)\n",
        "\n",
        "list_Medical_filtered_list=[]\n",
        "list_Medical_filtered= [] \n",
        "for w in list_Medical:\n",
        "  for j in w:\n",
        "    if j not in stop_words: \n",
        "      list_Medical_filtered.append(j)\n",
        "  list_Medical_filtered_list.append(list_Medical_filtered)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41knx3Is5uFa"
      },
      "source": [
        "count = 0\n",
        "list_list_Aca=[]\n",
        "list_Aca= [] \n",
        "for w in list_Academic_Science_filtered_list:\n",
        "  for j in w:\n",
        "    list_Aca.append(j)\n",
        "    count = count + 1\n",
        "    if count == 40:\n",
        "      list_list_Aca.append(list_Aca)\n",
        "      count = 0\n",
        "      list_Aca = []\n",
        "\n",
        "\n",
        "count = 0\n",
        "list_list_bus=[]\n",
        "list_bus= [] \n",
        "for w in list_Business_filtered_list:\n",
        "  for j in w:\n",
        "    list_bus.append(j)\n",
        "    count = count + 1\n",
        "    if count == 40:\n",
        "      list_list_bus.append(list_bus)\n",
        "      count = 0\n",
        "      list_bus = []\n",
        "\n",
        "\n",
        "count = 0\n",
        "list_list_comm=[]\n",
        "list_comm= [] \n",
        "for w in list_Community_filtered_list:\n",
        "  for j in w:\n",
        "    list_comm.append(j)\n",
        "    count = count + 1\n",
        "    if count == 40:\n",
        "      list_list_comm.append(list_comm)\n",
        "      count = 0\n",
        "      list_comm = []\n",
        "\n",
        "\n",
        "count = 0\n",
        "list_list_comp=[]\n",
        "list_comp= [] \n",
        "for w in list_Computing_filtered_list:\n",
        "  for j in w:\n",
        "    list_comp.append(j)\n",
        "    count = count + 1\n",
        "    if count == 40:\n",
        "      list_list_comp.append(list_comp)\n",
        "      count = 0\n",
        "      list_comp = []\n",
        "\n",
        "count = 0\n",
        "list_list_cov=[]\n",
        "list_cov= [] \n",
        "for w in list_Governmental_filtered_list:\n",
        "  for j in w:\n",
        "    list_cov.append(j)\n",
        "    count = count + 1\n",
        "    if count == 40:\n",
        "      list_list_cov.append(list_cov)\n",
        "      count = 0\n",
        "      list_cov = []\n",
        "\n",
        "\n",
        "count = 0\n",
        "list_list_mis=[]\n",
        "list_mis= [] \n",
        "for w in list_Miscellaneous_filtered_list:\n",
        "  for j in w:\n",
        "    list_mis.append(j)\n",
        "    count = count + 1\n",
        "    if count == 40:\n",
        "      list_list_mis.append(list_mis)\n",
        "      count = 0\n",
        "      list_mis = []\n",
        "\n",
        "\n",
        "count = 0\n",
        "list_list_med=[]\n",
        "list_med= [] \n",
        "for w in list_Medical_filtered_list:\n",
        "  for j in w:\n",
        "    list_med.append(j)\n",
        "    count = count + 1\n",
        "    if count == 40:\n",
        "      list_list_med.append(list_med)\n",
        "      count = 0\n",
        "      list_med = []\n",
        "\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hseEpXet80o8"
      },
      "source": [
        "df_aca = pd.DataFrame()\n",
        "df_aca['text'] = list_list_Aca\n",
        "df_aca['title'] = \"acadamic_science\"\n",
        "\n",
        "df_bus = pd.DataFrame()\n",
        "df_bus['text'] = list_list_bus\n",
        "df_bus['title'] = \"Business\"\n",
        "\n",
        "df_comm = pd.DataFrame()\n",
        "df_comm['text'] = list_list_comm\n",
        "df_comm['title'] = \"community\"\n",
        "\n",
        "df_comp = pd.DataFrame()\n",
        "df_comp['text'] = list_list_comp\n",
        "df_comp['title'] = \"computing\"\n",
        "\n",
        "df_gov = pd.DataFrame()\n",
        "df_gov['text'] = list_list_cov\n",
        "df_gov['title'] = \"govermnetal\"\n",
        "\n",
        "df_mis = pd.DataFrame()\n",
        "df_mis['text'] = list_Miscellaneous\n",
        "df_mis['title'] = \"Miscellaneous\"\n",
        "\n",
        "df_med = pd.DataFrame()\n",
        "df_med['text'] = list_list_med\n",
        "df_med['title'] = \"medical\""
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ml-bOJYb80iV"
      },
      "source": [
        "df_all_cat = pd.concat([df_aca,df_bus,df_comm,df_comp,df_gov,df_mis,df_med],ignore_index = True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_olCcLFG8p3",
        "outputId": "8c7cf676-fee4-42b1-a1a6-f97098acec22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "df_all_cat"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[academic, degree, qualification, awarded, stu...</td>\n",
              "      <td>acadamic_science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[qualifications, titled, degrees, e, g, associ...</td>\n",
              "      <td>acadamic_science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[university, done, degrees, awarded, european,...</td>\n",
              "      <td>acadamic_science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[docendi, medieval, university, roots, traced,...</td>\n",
              "      <td>acadamic_science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[free, charge, able, applicants, however, stil...</td>\n",
              "      <td>acadamic_science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304326</th>\n",
              "      <td>[surgery, role, paraveterinary, workers, less,...</td>\n",
              "      <td>medical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304327</th>\n",
              "      <td>[disorders, including, osteopaths, chiropracto...</td>\n",
              "      <td>medical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304328</th>\n",
              "      <td>[diagnosis, treatment, diseases, animals, basi...</td>\n",
              "      <td>medical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304329</th>\n",
              "      <td>[medicine, randomized, controlled, trials, fun...</td>\n",
              "      <td>medical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304330</th>\n",
              "      <td>[controlled, trials, animal, drug, animal, sci...</td>\n",
              "      <td>medical</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>304331 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text             title\n",
              "0       [academic, degree, qualification, awarded, stu...  acadamic_science\n",
              "1       [qualifications, titled, degrees, e, g, associ...  acadamic_science\n",
              "2       [university, done, degrees, awarded, european,...  acadamic_science\n",
              "3       [docendi, medieval, university, roots, traced,...  acadamic_science\n",
              "4       [free, charge, able, applicants, however, stil...  acadamic_science\n",
              "...                                                   ...               ...\n",
              "304326  [surgery, role, paraveterinary, workers, less,...           medical\n",
              "304327  [disorders, including, osteopaths, chiropracto...           medical\n",
              "304328  [diagnosis, treatment, diseases, animals, basi...           medical\n",
              "304329  [medicine, randomized, controlled, trials, fun...           medical\n",
              "304330  [controlled, trials, animal, drug, animal, sci...           medical\n",
              "\n",
              "[304331 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Xd5mQBnyrTZ"
      },
      "source": [
        "msk = np.random.rand(len(df_all_cat)) < 0.8\n",
        "train_df = df_all_cat[msk]\n",
        "test_val_df = df_all_cat[~msk]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oH6aNx04yrQ6"
      },
      "source": [
        "msk = np.random.rand(len(test_val_df)) < 0.5\n",
        "test_df = test_val_df[msk]\n",
        "validate_df = test_val_df[~msk]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joclRMGcOt7b",
        "outputId": "d5546ef7-3af2-4aaf-bfd6-d639cde1301b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        }
      },
      "source": [
        "df[df['title']=='Miscellaneous']"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>116</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['the', 'miscellaneous', 'was', 'a', 's', 'alt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>117</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['nasa', 'test', 'aircraft', 'the', 'mil', 'mi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>118</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['aviation', 'is', 'the', 'practical', 'aspect...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>119</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['animals', 'are', 'multicellular', 'eukaryoti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>120</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['some', 'of', 'the', 'trophies', 'earned', 'b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>121</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['obverse', 'of', 'medal', 'distributed', 'by'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>122</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['farmland', 'in', 'the', 'united', 'states', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>123</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['fields', 'in', 'z', 'horie', 'slovakia', 'a'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>124</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['various', 'foods', 'foods', 'from', 'plant',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>125</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['the', 'nutrition', 'facts', 'table', 'displa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>126</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['foundation', 'may', 'refer', 'to', 'literatu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>127</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['__notoc__', 'a', 'journal', 'through', 'fren...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>128</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['photography', 'is', 'the', 'science', 'art',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>129</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['imaging', 'is', 'the', 'representation', 'or...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>130</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['artwork', 'by', 'david', 'revoy', 'for', 'th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>131</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['a', 'shipping', 'line', 'is', 'a', 'business...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>132</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['sailing', 'employs', 'the', 'wind', 'acting'...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0  ...                                               text\n",
              "116         116  ...  ['the', 'miscellaneous', 'was', 'a', 's', 'alt...\n",
              "117         117  ...  ['nasa', 'test', 'aircraft', 'the', 'mil', 'mi...\n",
              "118         118  ...  ['aviation', 'is', 'the', 'practical', 'aspect...\n",
              "119         119  ...  ['animals', 'are', 'multicellular', 'eukaryoti...\n",
              "120         120  ...  ['some', 'of', 'the', 'trophies', 'earned', 'b...\n",
              "121         121  ...  ['obverse', 'of', 'medal', 'distributed', 'by'...\n",
              "122         122  ...  ['farmland', 'in', 'the', 'united', 'states', ...\n",
              "123         123  ...  ['fields', 'in', 'z', 'horie', 'slovakia', 'a'...\n",
              "124         124  ...  ['various', 'foods', 'foods', 'from', 'plant',...\n",
              "125         125  ...  ['the', 'nutrition', 'facts', 'table', 'displa...\n",
              "126         126  ...  ['foundation', 'may', 'refer', 'to', 'literatu...\n",
              "127         127  ...  ['__notoc__', 'a', 'journal', 'through', 'fren...\n",
              "128         128  ...  ['photography', 'is', 'the', 'science', 'art',...\n",
              "129         129  ...  ['imaging', 'is', 'the', 'representation', 'or...\n",
              "130         130  ...  ['artwork', 'by', 'david', 'revoy', 'for', 'th...\n",
              "131         131  ...  ['a', 'shipping', 'line', 'is', 'a', 'business...\n",
              "132         132  ...  ['sailing', 'employs', 'the', 'wind', 'acting'...\n",
              "\n",
              "[17 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4TFEsh5yrL8",
        "outputId": "a0af076d-a1cf-46c8-90a2-f66a8b109fdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print(f'train data count: {len(train_df)}')\n",
        "print(f'test data count: {len(test_df)}')\n",
        "print(f'validate data count: {len(validate_df)}')\n",
        "train_x, train_y = list(train_df['text']), list(train_df['title'])\n",
        "test_x, test_y = list(test_df['text']), list(test_df['title'])\n",
        "validate_x, validate_y = list(validate_df['text']), list(validate_df['title'])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train data count: 243379\n",
            "test data count: 30561\n",
            "validate data count: 30391\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tAdofSUzXOl",
        "outputId": "df3a8b49-c59a-4b1a-fb39-1b6631a12394",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(train_x,train_y,validate_x,validate_y,epochs=50, callbacks=[WandbCallback()])\n",
        "model.save(os.path.join(wandb.run.dir, \"model.h5\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing text vocab dict: 100%|██████████| 243379/243379 [00:02<00:00, 105396.80it/s]\n",
            "Preparing text vocab dict: 100%|██████████| 30391/30391 [00:00<00:00, 92617.50it/s]\n",
            "2020-10-10 20:26:19,789 [DEBUG] kashgari - --- Build vocab dict finished, Total: 34909 ---\n",
            "2020-10-10 20:26:19,791 [DEBUG] kashgari - Top-10: ['[PAD]', '[UNK]', '[CLS]', '[SEP]', 'also', 'may', 'used', 'many', 'one', 'study']\n",
            "Preparing classification label vocab dict: 100%|██████████| 243379/243379 [00:00<00:00, 1735296.49it/s]\n",
            "Preparing classification label vocab dict: 100%|██████████| 30391/30391 [00:00<00:00, 1436077.30it/s]\n",
            "Calculating sequence length: 100%|██████████| 243379/243379 [00:00<00:00, 1942922.23it/s]\n",
            "Calculating sequence length: 100%|██████████| 30391/30391 [00:00<00:00, 1413167.18it/s]\n",
            "2020-10-10 20:26:28,449 [DEBUG] kashgari - Calculated sequence length = 40\n",
            "2020-10-10 20:26:29,868 [DEBUG] kashgari - Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Input-Token (InputLayer)        [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Input-Segment (InputLayer)      [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token (Embedding)     (None, None, 768)    23440896    Input-Token[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Segment (Embedding)   (None, None, 768)    1536        Input-Segment[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token-Segment (Add)   (None, None, 768)    0           Embedding-Token[0][0]            \n",
            "                                                                 Embedding-Segment[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Position (PositionEmb (None, None, 768)    393216      Embedding-Token-Segment[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Norm (LayerNormalizat (None, None, 768)    1536        Embedding-Position[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Dropout (Dropout)     (None, None, 768)    0           Embedding-Norm[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-0-MultiHeadSelfAtte (None, None, 768)    2362368     Embedding-Dropout[0][0]          \n",
            "                                                                 Embedding-Dropout[0][0]          \n",
            "                                                                 Embedding-Dropout[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Embedding-Dropout[0][0]          \n",
            "                                                                 Transformer-0-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-0-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-0-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-0-FeedForward (Feed (None, None, 768)    4722432     Transformer-0-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-0-FeedForward-Dropo (None, None, 768)    0           Transformer-0-FeedForward[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-0-FeedForward-Add ( (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent\n",
            "                                                                 Transformer-0-FeedForward-Dropout\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-0-FeedForward-Norm  (None, None, 768)    1536        Transformer-0-FeedForward-Add[0][\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-1-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-0-FeedForward-Norm[0]\n",
            "                                                                 Transformer-0-FeedForward-Norm[0]\n",
            "                                                                 Transformer-0-FeedForward-Norm[0]\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-FeedForward-Norm[0]\n",
            "                                                                 Transformer-1-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-1-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-1-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-1-FeedForward (Feed (None, None, 768)    4722432     Transformer-1-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-1-FeedForward-Dropo (None, None, 768)    0           Transformer-1-FeedForward[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-1-FeedForward-Add ( (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent\n",
            "                                                                 Transformer-1-FeedForward-Dropout\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-1-FeedForward-Norm  (None, None, 768)    1536        Transformer-1-FeedForward-Add[0][\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-2-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-1-FeedForward-Norm[0]\n",
            "                                                                 Transformer-1-FeedForward-Norm[0]\n",
            "                                                                 Transformer-1-FeedForward-Norm[0]\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-FeedForward-Norm[0]\n",
            "                                                                 Transformer-2-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-2-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-2-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-2-FeedForward (Feed (None, None, 768)    4722432     Transformer-2-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-2-FeedForward-Dropo (None, None, 768)    0           Transformer-2-FeedForward[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-2-FeedForward-Add ( (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent\n",
            "                                                                 Transformer-2-FeedForward-Dropout\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-2-FeedForward-Norm  (None, None, 768)    1536        Transformer-2-FeedForward-Add[0][\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-3-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-2-FeedForward-Norm[0]\n",
            "                                                                 Transformer-2-FeedForward-Norm[0]\n",
            "                                                                 Transformer-2-FeedForward-Norm[0]\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-FeedForward-Norm[0]\n",
            "                                                                 Transformer-3-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-3-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-3-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-3-FeedForward (Feed (None, None, 768)    4722432     Transformer-3-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-3-FeedForward-Dropo (None, None, 768)    0           Transformer-3-FeedForward[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-3-FeedForward-Add ( (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent\n",
            "                                                                 Transformer-3-FeedForward-Dropout\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-3-FeedForward-Norm  (None, None, 768)    1536        Transformer-3-FeedForward-Add[0][\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-4-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-3-FeedForward-Norm[0]\n",
            "                                                                 Transformer-3-FeedForward-Norm[0]\n",
            "                                                                 Transformer-3-FeedForward-Norm[0]\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-4-MultiHeadSelfAtte (None, None, 768)    0           Transformer-4-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-4-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-FeedForward-Norm[0]\n",
            "                                                                 Transformer-4-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-4-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-4-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-4-FeedForward (Feed (None, None, 768)    4722432     Transformer-4-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-4-FeedForward-Dropo (None, None, 768)    0           Transformer-4-FeedForward[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-4-FeedForward-Add ( (None, None, 768)    0           Transformer-4-MultiHeadSelfAttent\n",
            "                                                                 Transformer-4-FeedForward-Dropout\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-4-FeedForward-Norm  (None, None, 768)    1536        Transformer-4-FeedForward-Add[0][\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-5-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-4-FeedForward-Norm[0]\n",
            "                                                                 Transformer-4-FeedForward-Norm[0]\n",
            "                                                                 Transformer-4-FeedForward-Norm[0]\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-5-MultiHeadSelfAtte (None, None, 768)    0           Transformer-5-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-5-MultiHeadSelfAtte (None, None, 768)    0           Transformer-4-FeedForward-Norm[0]\n",
            "                                                                 Transformer-5-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-5-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-5-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-5-FeedForward (Feed (None, None, 768)    4722432     Transformer-5-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-5-FeedForward-Dropo (None, None, 768)    0           Transformer-5-FeedForward[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-5-FeedForward-Add ( (None, None, 768)    0           Transformer-5-MultiHeadSelfAttent\n",
            "                                                                 Transformer-5-FeedForward-Dropout\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-5-FeedForward-Norm  (None, None, 768)    1536        Transformer-5-FeedForward-Add[0][\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-6-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-5-FeedForward-Norm[0]\n",
            "                                                                 Transformer-5-FeedForward-Norm[0]\n",
            "                                                                 Transformer-5-FeedForward-Norm[0]\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-6-MultiHeadSelfAtte (None, None, 768)    0           Transformer-6-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-6-MultiHeadSelfAtte (None, None, 768)    0           Transformer-5-FeedForward-Norm[0]\n",
            "                                                                 Transformer-6-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-6-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-6-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-6-FeedForward (Feed (None, None, 768)    4722432     Transformer-6-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-6-FeedForward-Dropo (None, None, 768)    0           Transformer-6-FeedForward[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-6-FeedForward-Add ( (None, None, 768)    0           Transformer-6-MultiHeadSelfAttent\n",
            "                                                                 Transformer-6-FeedForward-Dropout\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-6-FeedForward-Norm  (None, None, 768)    1536        Transformer-6-FeedForward-Add[0][\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-7-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-6-FeedForward-Norm[0]\n",
            "                                                                 Transformer-6-FeedForward-Norm[0]\n",
            "                                                                 Transformer-6-FeedForward-Norm[0]\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-7-MultiHeadSelfAtte (None, None, 768)    0           Transformer-7-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-7-MultiHeadSelfAtte (None, None, 768)    0           Transformer-6-FeedForward-Norm[0]\n",
            "                                                                 Transformer-7-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-7-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-7-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-7-FeedForward (Feed (None, None, 768)    4722432     Transformer-7-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-7-FeedForward-Dropo (None, None, 768)    0           Transformer-7-FeedForward[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-7-FeedForward-Add ( (None, None, 768)    0           Transformer-7-MultiHeadSelfAttent\n",
            "                                                                 Transformer-7-FeedForward-Dropout\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-7-FeedForward-Norm  (None, None, 768)    1536        Transformer-7-FeedForward-Add[0][\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-8-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-7-FeedForward-Norm[0]\n",
            "                                                                 Transformer-7-FeedForward-Norm[0]\n",
            "                                                                 Transformer-7-FeedForward-Norm[0]\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-8-MultiHeadSelfAtte (None, None, 768)    0           Transformer-8-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-8-MultiHeadSelfAtte (None, None, 768)    0           Transformer-7-FeedForward-Norm[0]\n",
            "                                                                 Transformer-8-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-8-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-8-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-8-FeedForward (Feed (None, None, 768)    4722432     Transformer-8-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-8-FeedForward-Dropo (None, None, 768)    0           Transformer-8-FeedForward[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-8-FeedForward-Add ( (None, None, 768)    0           Transformer-8-MultiHeadSelfAttent\n",
            "                                                                 Transformer-8-FeedForward-Dropout\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-8-FeedForward-Norm  (None, None, 768)    1536        Transformer-8-FeedForward-Add[0][\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-9-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-8-FeedForward-Norm[0]\n",
            "                                                                 Transformer-8-FeedForward-Norm[0]\n",
            "                                                                 Transformer-8-FeedForward-Norm[0]\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-9-MultiHeadSelfAtte (None, None, 768)    0           Transformer-9-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-9-MultiHeadSelfAtte (None, None, 768)    0           Transformer-8-FeedForward-Norm[0]\n",
            "                                                                 Transformer-9-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-9-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-9-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-9-FeedForward (Feed (None, None, 768)    4722432     Transformer-9-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-9-FeedForward-Dropo (None, None, 768)    0           Transformer-9-FeedForward[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-9-FeedForward-Add ( (None, None, 768)    0           Transformer-9-MultiHeadSelfAttent\n",
            "                                                                 Transformer-9-FeedForward-Dropout\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-9-FeedForward-Norm  (None, None, 768)    1536        Transformer-9-FeedForward-Add[0][\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-10-MultiHeadSelfAtt (None, None, 768)    2362368     Transformer-9-FeedForward-Norm[0]\n",
            "                                                                 Transformer-9-FeedForward-Norm[0]\n",
            "                                                                 Transformer-9-FeedForward-Norm[0]\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-10-MultiHeadSelfAtt (None, None, 768)    0           Transformer-10-MultiHeadSelfAtten\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-10-MultiHeadSelfAtt (None, None, 768)    0           Transformer-9-FeedForward-Norm[0]\n",
            "                                                                 Transformer-10-MultiHeadSelfAtten\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-10-MultiHeadSelfAtt (None, None, 768)    1536        Transformer-10-MultiHeadSelfAtten\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-10-FeedForward (Fee (None, None, 768)    4722432     Transformer-10-MultiHeadSelfAtten\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-10-FeedForward-Drop (None, None, 768)    0           Transformer-10-FeedForward[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-10-FeedForward-Add  (None, None, 768)    0           Transformer-10-MultiHeadSelfAtten\n",
            "                                                                 Transformer-10-FeedForward-Dropou\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-10-FeedForward-Norm (None, None, 768)    1536        Transformer-10-FeedForward-Add[0]\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-11-MultiHeadSelfAtt (None, None, 768)    2362368     Transformer-10-FeedForward-Norm[0\n",
            "                                                                 Transformer-10-FeedForward-Norm[0\n",
            "                                                                 Transformer-10-FeedForward-Norm[0\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-11-MultiHeadSelfAtt (None, None, 768)    0           Transformer-11-MultiHeadSelfAtten\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-11-MultiHeadSelfAtt (None, None, 768)    0           Transformer-10-FeedForward-Norm[0\n",
            "                                                                 Transformer-11-MultiHeadSelfAtten\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-11-MultiHeadSelfAtt (None, None, 768)    1536        Transformer-11-MultiHeadSelfAtten\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-11-FeedForward (Fee (None, None, 768)    4722432     Transformer-11-MultiHeadSelfAtten\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-11-FeedForward-Drop (None, None, 768)    0           Transformer-11-FeedForward[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-11-FeedForward-Add  (None, None, 768)    0           Transformer-11-MultiHeadSelfAtten\n",
            "                                                                 Transformer-11-FeedForward-Dropou\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-11-FeedForward-Norm (None, None, 768)    1536        Transformer-11-FeedForward-Add[0]\n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 256)          918528      Transformer-11-FeedForward-Norm[0\n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 7)            1799        bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 7)            0           dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 109,811,975\n",
            "Trainable params: 920,327\n",
            "Non-trainable params: 108,891,648\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "3802/3802 [==============================] - 848s 223ms/step - loss: 0.0552 - accuracy: 0.9823 - val_loss: 9.1803 - val_accuracy: 0.1925\n",
            "Epoch 2/50\n",
            "3802/3802 [==============================] - 847s 223ms/step - loss: 0.0763 - accuracy: 0.9794 - val_loss: 9.2232 - val_accuracy: 0.1926\n",
            "Epoch 3/50\n",
            "3802/3802 [==============================] - 847s 223ms/step - loss: 0.0730 - accuracy: 0.9825 - val_loss: 8.7464 - val_accuracy: 0.1925\n",
            "Epoch 4/50\n",
            "3802/3802 [==============================] - 847s 223ms/step - loss: 0.0609 - accuracy: 0.9851 - val_loss: 9.3592 - val_accuracy: 0.1926\n",
            "Epoch 5/50\n",
            "3802/3802 [==============================] - 850s 223ms/step - loss: 0.0601 - accuracy: 0.9856 - val_loss: 8.5919 - val_accuracy: 0.1925\n",
            "Epoch 6/50\n",
            "3802/3802 [==============================] - 850s 224ms/step - loss: 0.0606 - accuracy: 0.9858 - val_loss: 10.2568 - val_accuracy: 0.1926\n",
            "Epoch 7/50\n",
            "3802/3802 [==============================] - 851s 224ms/step - loss: 0.0626 - accuracy: 0.9864 - val_loss: 8.5019 - val_accuracy: 0.1926\n",
            "Epoch 8/50\n",
            "3802/3802 [==============================] - 850s 223ms/step - loss: 0.0549 - accuracy: 0.9872 - val_loss: 8.6376 - val_accuracy: 0.1927\n",
            "Epoch 9/50\n",
            "3802/3802 [==============================] - 845s 222ms/step - loss: 0.0484 - accuracy: 0.9881 - val_loss: 9.0121 - val_accuracy: 0.1927\n",
            "Epoch 10/50\n",
            "3802/3802 [==============================] - 845s 222ms/step - loss: 0.0562 - accuracy: 0.9877 - val_loss: 9.1772 - val_accuracy: 0.1929\n",
            "Epoch 11/50\n",
            "3802/3802 [==============================] - 844s 222ms/step - loss: 0.0569 - accuracy: 0.9872 - val_loss: 8.2522 - val_accuracy: 0.1941\n",
            "Epoch 12/50\n",
            "3802/3802 [==============================] - 835s 220ms/step - loss: 0.0465 - accuracy: 0.9888 - val_loss: 9.3181 - val_accuracy: 0.1950\n",
            "Epoch 13/50\n",
            "3802/3802 [==============================] - 834s 219ms/step - loss: 0.0471 - accuracy: 0.9891 - val_loss: 8.4976 - val_accuracy: 0.1954\n",
            "Epoch 14/50\n",
            "3802/3802 [==============================] - 835s 220ms/step - loss: 0.0503 - accuracy: 0.9886 - val_loss: 8.7560 - val_accuracy: 0.1937\n",
            "Epoch 15/50\n",
            "3802/3802 [==============================] - 840s 221ms/step - loss: 0.0551 - accuracy: 0.9878 - val_loss: 9.2885 - val_accuracy: 0.1953\n",
            "Epoch 16/50\n",
            "3802/3802 [==============================] - 841s 221ms/step - loss: 0.0525 - accuracy: 0.9881 - val_loss: 9.5729 - val_accuracy: 0.1944\n",
            "Epoch 17/50\n",
            "3802/3802 [==============================] - 847s 223ms/step - loss: 0.0574 - accuracy: 0.9881 - val_loss: 7.7478 - val_accuracy: 0.1941\n",
            "Epoch 18/50\n",
            "3802/3802 [==============================] - 845s 222ms/step - loss: 0.0491 - accuracy: 0.9889 - val_loss: 9.1044 - val_accuracy: 0.1951\n",
            "Epoch 19/50\n",
            "3802/3802 [==============================] - 840s 221ms/step - loss: 0.0505 - accuracy: 0.9891 - val_loss: 8.3275 - val_accuracy: 0.2001\n",
            "Epoch 20/50\n",
            "3802/3802 [==============================] - 841s 221ms/step - loss: 0.0495 - accuracy: 0.9892 - val_loss: 7.7927 - val_accuracy: 0.1965\n",
            "Epoch 21/50\n",
            "3802/3802 [==============================] - 842s 221ms/step - loss: 0.0564 - accuracy: 0.9870 - val_loss: 7.7991 - val_accuracy: 0.1980\n",
            "Epoch 22/50\n",
            "3802/3802 [==============================] - 838s 220ms/step - loss: 0.0470 - accuracy: 0.9884 - val_loss: 8.2623 - val_accuracy: 0.1952\n",
            "Epoch 23/50\n",
            "3802/3802 [==============================] - 839s 221ms/step - loss: 0.0455 - accuracy: 0.9891 - val_loss: 7.4400 - val_accuracy: 0.2001\n",
            "Epoch 24/50\n",
            "3802/3802 [==============================] - 837s 220ms/step - loss: 0.0505 - accuracy: 0.9881 - val_loss: 8.7347 - val_accuracy: 0.1955\n",
            "Epoch 25/50\n",
            "3802/3802 [==============================] - 836s 220ms/step - loss: 0.0495 - accuracy: 0.9885 - val_loss: 8.3632 - val_accuracy: 0.2049\n",
            "Epoch 26/50\n",
            "3802/3802 [==============================] - 836s 220ms/step - loss: 0.0514 - accuracy: 0.9882 - val_loss: 8.2797 - val_accuracy: 0.2028\n",
            "Epoch 27/50\n",
            "3802/3802 [==============================] - 837s 220ms/step - loss: 0.0502 - accuracy: 0.9885 - val_loss: 7.8899 - val_accuracy: 0.2041\n",
            "Epoch 28/50\n",
            "3802/3802 [==============================] - 835s 220ms/step - loss: 0.0485 - accuracy: 0.9889 - val_loss: 7.8439 - val_accuracy: 0.2042\n",
            "Epoch 29/50\n",
            "3802/3802 [==============================] - 835s 220ms/step - loss: 0.0504 - accuracy: 0.9882 - val_loss: 8.7984 - val_accuracy: 0.2003\n",
            "Epoch 30/50\n",
            "3802/3802 [==============================] - 834s 219ms/step - loss: 0.0474 - accuracy: 0.9894 - val_loss: 8.0473 - val_accuracy: 0.2033\n",
            "Epoch 31/50\n",
            "3802/3802 [==============================] - 834s 219ms/step - loss: 0.0508 - accuracy: 0.9888 - val_loss: 7.7762 - val_accuracy: 0.2100\n",
            "Epoch 32/50\n",
            "3802/3802 [==============================] - 834s 219ms/step - loss: 0.0462 - accuracy: 0.9895 - val_loss: 7.7700 - val_accuracy: 0.2032\n",
            "Epoch 33/50\n",
            "3802/3802 [==============================] - 837s 220ms/step - loss: 0.0425 - accuracy: 0.9899 - val_loss: 8.2297 - val_accuracy: 0.2039\n",
            "Epoch 34/50\n",
            "3802/3802 [==============================] - 837s 220ms/step - loss: 0.0422 - accuracy: 0.9902 - val_loss: 7.7421 - val_accuracy: 0.2034\n",
            "Epoch 35/50\n",
            "3802/3802 [==============================] - 836s 220ms/step - loss: 0.0421 - accuracy: 0.9900 - val_loss: 7.7364 - val_accuracy: 0.2082\n",
            "Epoch 36/50\n",
            "3802/3802 [==============================] - 834s 219ms/step - loss: 0.0509 - accuracy: 0.9889 - val_loss: 7.6707 - val_accuracy: 0.2103\n",
            "Epoch 37/50\n",
            "3802/3802 [==============================] - 835s 220ms/step - loss: 0.0429 - accuracy: 0.9900 - val_loss: 8.1180 - val_accuracy: 0.2064\n",
            "Epoch 38/50\n",
            "3802/3802 [==============================] - 834s 219ms/step - loss: 0.0475 - accuracy: 0.9895 - val_loss: 7.9490 - val_accuracy: 0.2027\n",
            "Epoch 39/50\n",
            "3802/3802 [==============================] - 834s 219ms/step - loss: 0.0435 - accuracy: 0.9900 - val_loss: 8.1213 - val_accuracy: 0.2029\n",
            "Epoch 40/50\n",
            "3802/3802 [==============================] - 840s 221ms/step - loss: 0.0450 - accuracy: 0.9898 - val_loss: 8.2857 - val_accuracy: 0.2107\n",
            "Epoch 41/50\n",
            "3802/3802 [==============================] - 841s 221ms/step - loss: 0.0446 - accuracy: 0.9900 - val_loss: 7.2218 - val_accuracy: 0.2008\n",
            "Epoch 42/50\n",
            "3802/3802 [==============================] - 838s 220ms/step - loss: 0.0390 - accuracy: 0.9905 - val_loss: 7.1927 - val_accuracy: 0.2086\n",
            "Epoch 43/50\n",
            "2970/3802 [======================>.......] - ETA: 2:45 - loss: 0.0433 - accuracy: 0.9900"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1tAWfbRQO3r",
        "outputId": "5185e2d0-2083-44c2-d6b8-96d3706fe326",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.evaluate(test_x,test_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-10 16:04:10,513 [WARNING] kashgari - Sequence length is None, will use the max embedding seq length, which is 512\n",
            "2020-10-10 16:04:10,542 [DEBUG] kashgari - predict input shape (2, 790, 512) x: \n",
            "(array([[ 101, 1998, 2353, ...,    0,    0,    0],\n",
            "       [ 101, 2968, 3802, ...,    0,    0,    0],\n",
            "       [ 101, 1996, 2034, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [ 101,  100, 2542, ...,    0,    0,    0],\n",
            "       [ 101, 1997, 1996, ...,    0,    0,    0],\n",
            "       [ 101, 2554, 2001, ...,    0,    0,    0]], dtype=int32), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32))\n",
            "2020-10-10 16:04:46,655 [DEBUG] kashgari - predict output shape (790, 7)\n",
            "2020-10-10 16:04:46,658 [DEBUG] kashgari - predict output argmax: [0 3 5 0 1 0 0 1 1 4 0 0 0 1 1 1 0 0 0 0 5 0 0 3 4 5 5 0 4 0 0 0 5 0 2 2 1\n",
            " 2 5 2 2 0 2 0 0 2 0 2 0 2 2 2 5 5 0 0 0 0 6 4 0 0 4 0 1 5 0 1 1 1 0 0 5 5\n",
            " 5 1 2 1 4 4 0 1 0 0 1 1 1 2 2 5 2 1 1 0 0 0 0 0 4 0 0 0 0 0 0 4 2 0 2 0 2\n",
            " 2 0 0 0 0 0 0 4 2 0 2 0 0 2 0 4 4 5 2 4 3 1 3 4 2 0 4 3 5 5 4 2 2 2 2 1 1\n",
            " 2 1 2 5 0 0 2 0 0 0 0 0 0 0 0 0 5 0 5 0 1 0 0 2 0 2 2 2 2 2 2 2 0 0 2 0 0\n",
            " 5 5 0 5 5 5 0 4 0 4 0 0 0 0 4 0 0 0 0 0 0 0 0 4 1 1 1 0 0 5 5 0 0 2 1 2 1\n",
            " 2 2 1 5 2 1 1 1 1 1 2 1 2 2 0 1 2 1 1 2 4 4 4 5 4 0 2 4 5 0 2 0 2 2 0 0 2\n",
            " 2 1 2 0 1 0 5 1 1 1 0 5 0 0 4 3 3 3 3 3 3 5 3 3 3 3 3 2 5 3 5 1 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 1 3 3 3 3 3 3 3 3 3 3 3 3 1 1 3 4 3 3 3 4 5 3 3 3 5 3\n",
            " 3 3 3 3 2 2 2 2 3 3 3 3 3 3 4 3 4 4 3 2 3 3 2 5 2 2 2 2 2 2 2 2 2 2 4 2 2\n",
            " 2 2 2 2 2 2 2 2 4 4 2 2 4 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 0 2 2 2\n",
            " 2 2 4 2 1 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 1 2 2 5 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 4 2 2 1 2 2 2 2 1 2 2 2 2 4 2 5 5 5 5 5 5 5\n",
            " 5 5 5 0 0 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 2 2 5 5 5 5 5 4 4 4 4 4 4 4 4 4 4 1 4 4 4\n",
            " 4 4 4 4 1 4 1 4 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 2 4 4 4 4 4\n",
            " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 4 4 4\n",
            " 4 4 4 4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 1 5 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
            " 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                  precision    recall  f1-score   support\n",
            "\n",
            "        Business     0.9104    0.7262    0.8079        84\n",
            "   Miscellaneous     0.0000    0.0000    0.0000         1\n",
            "acadamic_science     0.9402    0.4029    0.5641       273\n",
            "       community     0.5952    0.8547    0.7018       117\n",
            "       computing     0.6176    0.9403    0.7456        67\n",
            "     govermnetal     0.6744    0.9355    0.7838        93\n",
            "         medical     0.7087    0.9419    0.8089       155\n",
            "\n",
            "        accuracy                         0.7177       790\n",
            "       macro avg     0.6352    0.6859    0.6303       790\n",
            "    weighted avg     0.7807    0.7177    0.6990       790\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'detail': {'Business': {'f1-score': 0.8079470198675497,\n",
              "   'precision': 0.9104477611940298,\n",
              "   'recall': 0.7261904761904762,\n",
              "   'support': 84},\n",
              "  'Miscellaneous': {'f1-score': 0.0,\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'support': 1},\n",
              "  'acadamic_science': {'f1-score': 0.5641025641025641,\n",
              "   'precision': 0.9401709401709402,\n",
              "   'recall': 0.40293040293040294,\n",
              "   'support': 273},\n",
              "  'accuracy': 0.7177215189873418,\n",
              "  'community': {'f1-score': 0.7017543859649124,\n",
              "   'precision': 0.5952380952380952,\n",
              "   'recall': 0.8547008547008547,\n",
              "   'support': 117},\n",
              "  'computing': {'f1-score': 0.7455621301775149,\n",
              "   'precision': 0.6176470588235294,\n",
              "   'recall': 0.9402985074626866,\n",
              "   'support': 67},\n",
              "  'govermnetal': {'f1-score': 0.7837837837837838,\n",
              "   'precision': 0.6744186046511628,\n",
              "   'recall': 0.9354838709677419,\n",
              "   'support': 93},\n",
              "  'macro avg': {'f1-score': 0.6302877356891861,\n",
              "   'precision': 0.6352371891650611,\n",
              "   'recall': 0.68593422801759,\n",
              "   'support': 790},\n",
              "  'medical': {'f1-score': 0.8088642659279778,\n",
              "   'precision': 0.7087378640776699,\n",
              "   'recall': 0.9419354838709677,\n",
              "   'support': 155},\n",
              "  'weighted avg': {'f1-score': 0.698976365391634,\n",
              "   'precision': 0.7806896048805011,\n",
              "   'recall': 0.7177215189873418,\n",
              "   'support': 790}},\n",
              " 'f1-score': 0.698976365391634,\n",
              " 'precision': 0.7806896048805011,\n",
              " 'recall': 0.7177215189873418,\n",
              " 'support': 790}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLlggrsqSSFB"
      },
      "source": [
        "def predict(docs):\n",
        "  tokenize_docs = []\n",
        "  df=pd.DataFrame([docs],columns=['text'])\n",
        "  docs_tokens = df['text'].tolist()\n",
        "  length = len(docs_tokens)\n",
        "  for i in range(length):\n",
        "    tokenize_docs.append(tokenize(docs_tokens[i]))\n",
        "  return tokenize_docs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNh5BUVDSVPf"
      },
      "source": [
        "x = predict('Artificial intelligence (AI), sometimes called machine intelligence, is intelligence demonstrated by machines, unlike the natural intelligence displayed by humans and animals. Leading AI textbooks define the field as the study of \"intelligent agents\": any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals.[3] Colloquially, the term \"artificial intelligence\" is often used to describe machines (or computers) that mimic \"cognitive\" functions that humans associate with the human mind, such as learning and problem solving.[4]As machines become increasingly capable, tasks considered to require intelligence are often removed from the definition of AI, a phenomenon known as the AI effect.[5] A quip in Teslers Theorem says \"AI is whatever hasnt been done yet.[6] For instance, optical character recognition is frequently excluded from things considered to be AI,[7] having become a routine technology.[8] Modern machine capabilities generally classified as AI include successfully understanding human speech,computing')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXYVnH4iXwTI",
        "outputId": "988547ea-0be9-4965-9cd8-330cad5b43c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(x[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2gZk5o1Q0mm",
        "outputId": "4b3162c6-c5d9-491d-8f95-87c3e82234bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "source": [
        "model.predict(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-10 16:39:16,540 [DEBUG] kashgari - predict input shape (2, 1, 97) x: \n",
            "(array([[  101,   100,   100,   100,  2655,   100,   100,   100,   100,\n",
            "          100,   100,   100,   100,  4653,  2529,   100,  2599, 16432,\n",
            "          100,  2492,   100,   100,  4005,   100,   100,   100,  2202,\n",
            "         2895, 20446,   100,  3112,   100,  3125,   100,  2744,   100,\n",
            "          100,  2411,  2224,   100,   100,   100, 23150,   100,  3853,\n",
            "         2529,   100,  2529,  2568,  4553,  3291,   100,   100,   100,\n",
            "          100,   100,  4708,   100,   100,   100,  2411,   100,   100,\n",
            "         9575,  2124,  3466,   100,   100,  9872,  2360,   100,   100,\n",
            "         2589,  2664,   100, 22816,   100,   100,  6976,   100,  2518,\n",
            "          100,   100,   100,   100,  2715,   100,   100,   100,   100,\n",
            "          100,  3112,  3305,  2529,  4613,   100,   102]], dtype=int32), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32))\n",
            "2020-10-10 16:39:16,617 [DEBUG] kashgari - predict output shape (1, 7)\n",
            "2020-10-10 16:39:16,618 [DEBUG] kashgari - predict output argmax: [1]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['medical']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vs_OFRzYyrJa",
        "outputId": "acf9011c-5219-4f6a-cf73-9533e4c4c9d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "train_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Academic_Science</td>\n",
              "      <td>['an', 'academic', 'degree', 'is', 'a', 'quali...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Academic_Science</td>\n",
              "      <td>['an', 'alumnus', 'masculine', 'plural', 'alum...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Academic_Science</td>\n",
              "      <td>['an', 'example', 'of', 'an', 'amateur', 'radi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Academic_Science</td>\n",
              "      <td>['anthropology', 'is', 'the', 'study', 'of', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Academic_Science</td>\n",
              "      <td>['roman', 'ruins', 'lausanne', 'switzerland', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>154</td>\n",
              "      <td>Medical</td>\n",
              "      <td>['rehabilitation', 'psychology', 'is', 'a', 's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>155</td>\n",
              "      <td>Medical</td>\n",
              "      <td>['surgeons', 'repairing', 'a', 'ruptured', 'ac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>156</td>\n",
              "      <td>Medical</td>\n",
              "      <td>['a', 'syndrome', 'is', 'a', 'set', 'of', 'med...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>157</td>\n",
              "      <td>Medical</td>\n",
              "      <td>['therapy', 'often', 'abbreviated', 'tx', 'tx'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>159</td>\n",
              "      <td>Medical</td>\n",
              "      <td>['a', 'veterinary', 'technician', 'in', 'ethio...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>133 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0  ...                                               text\n",
              "0             0  ...  ['an', 'academic', 'degree', 'is', 'a', 'quali...\n",
              "1             1  ...  ['an', 'alumnus', 'masculine', 'plural', 'alum...\n",
              "2             2  ...  ['an', 'example', 'of', 'an', 'amateur', 'radi...\n",
              "3             3  ...  ['anthropology', 'is', 'the', 'study', 'of', '...\n",
              "4             4  ...  ['roman', 'ruins', 'lausanne', 'switzerland', ...\n",
              "..          ...  ...                                                ...\n",
              "154         154  ...  ['rehabilitation', 'psychology', 'is', 'a', 's...\n",
              "155         155  ...  ['surgeons', 'repairing', 'a', 'ruptured', 'ac...\n",
              "156         156  ...  ['a', 'syndrome', 'is', 'a', 'set', 'of', 'med...\n",
              "157         157  ...  ['therapy', 'often', 'abbreviated', 'tx', 'tx'...\n",
              "159         159  ...  ['a', 'veterinary', 'technician', 'in', 'ethio...\n",
              "\n",
              "[133 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olNF8iDoZkTk"
      },
      "source": [
        "import ast\n",
        "X_train=[ast.literal_eval(i) for i in X_train]\n",
        "X_test=[ast.literal_eval(i) for i in X_test]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ni0w1Hgxgpn0"
      },
      "source": [
        ""
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uGkEZHH5gra"
      },
      "source": [
        "X_train_filtered_list=[]\n",
        "X_train_filtered= [] \n",
        "for w in X_train:\n",
        "  for j in w:\n",
        "    if j not in stop_words: \n",
        "      X_train_filtered.append(j)\n",
        "  X_train_filtered_list.append(X_train_filtered)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qv2Q7jANkbHM"
      },
      "source": [
        "X_train_filtered_list=[]\n",
        "X_train_filtered= [] \n",
        "for w in X_train:\n",
        "  for j in w:\n",
        "    if j not in stop_words: \n",
        "      X_train_filtered.append(j)\n",
        "  X_train_filtered_list.append(X_train_filtered)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JcnUrz8k8yI"
      },
      "source": [
        "X_test_filtered_list=[]\n",
        "X_test_filtered= [] \n",
        "for w in X_test:\n",
        "  for j in w:\n",
        "    if j not in stop_words: \n",
        "      X_test_filtered.append(j)\n",
        "  X_test_filtered_list.append(X_test_filtered)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbRzaUCoyHnK"
      },
      "source": [
        "X_test_filtered_list[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jro7aZ4AgYio"
      },
      "source": [
        "model.fit(X_train_filtered_list,y_train,X_test_filtered_list,y_test,epochs=35,batch_size=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfzSX05vr-l4"
      },
      "source": [
        "model.save(\"LSTM\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTymvzVAadFa"
      },
      "source": [
        "!mkdir '/content/LSTM' \n",
        "!cp  '/content/drive/My Drive/Model_weights/embed_model_weights.h5' '/content/LSTM'\n",
        "!cp  '/content/drive/My Drive/Model_weights/model_config.json' '/content/LSTM'\n",
        "!cp  '/content/drive/My Drive/Model_weights/model_weights.h5' '/content/LSTM'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKd8k3nxyu1G",
        "outputId": "82eeaceb-fbbd-48a6-adf5-a8dd549e63f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "\n",
        "loaded_model = BiLSTM_Model.load_model('/content/LSTM/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-09-01 17:51:13,866 [DEBUG] kashgari - ------------------------------------------------\n",
            "2020-09-01 17:51:13,867 [DEBUG] kashgari - Loaded transformer model's vocab\n",
            "2020-09-01 17:51:13,868 [DEBUG] kashgari - config_path       : /content/uncased_L-12_H-768_A-12/bert_config.json\n",
            "2020-09-01 17:51:13,870 [DEBUG] kashgari - vocab_path      : /content/uncased_L-12_H-768_A-12/vocab.txt\n",
            "2020-09-01 17:51:13,871 [DEBUG] kashgari - checkpoint_path : /content/uncased_L-12_H-768_A-12/bert_model.ckpt\n",
            "2020-09-01 17:51:13,872 [DEBUG] kashgari - Top 50 words    : ['[PAD]', '[unused0]', '[unused1]', '[unused2]', '[unused3]', '[unused4]', '[unused5]', '[unused6]', '[unused7]', '[unused8]', '[unused9]', '[unused10]', '[unused11]', '[unused12]', '[unused13]', '[unused14]', '[unused15]', '[unused16]', '[unused17]', '[unused18]', '[unused19]', '[unused20]', '[unused21]', '[unused22]', '[unused23]', '[unused24]', '[unused25]', '[unused26]', '[unused27]', '[unused28]', '[unused29]', '[unused30]', '[unused31]', '[unused32]', '[unused33]', '[unused34]', '[unused35]', '[unused36]', '[unused37]', '[unused38]', '[unused39]', '[unused40]', '[unused41]', '[unused42]', '[unused43]', '[unused44]', '[unused45]', '[unused46]', '[unused47]', '[unused48]']\n",
            "2020-09-01 17:51:13,873 [DEBUG] kashgari - ------------------------------------------------\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x_qJMLXYjBs"
      },
      "source": [
        "def predict(docs):\n",
        "  tokenize_docs = []\n",
        "  df=pd.DataFrame([docs],columns=['text'])\n",
        "  docs_tokens = df['text'].tolist()\n",
        "  length = len(docs_tokens)\n",
        "  for i in range(length):\n",
        "    tokenize_docs.append(tokenize(docs_tokens[i]))\n",
        "  return tokenize_docs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ge6kaDKzZ7MP",
        "outputId": "0ea9960c-1148-4e0d-b310-1fec7e8e6873",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "loaded_model.predict([nltk_tokens])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-09-01 18:08:44,835 [DEBUG] kashgari - predict input shape (2, 1, 62) x: \n",
            "(array([[  101,   100, 13058,   100,  5658,   100, 14931,  1058, 14931,\n",
            "         5658,  1058,  5096,   100,  1058,   100,   100,   100,   100,\n",
            "         1058,   100,  3157,   100,   100, 14931,  1058, 14931,  5658,\n",
            "          100,  1058,   100,  5096,   100,  1058,   100,   100,   100,\n",
            "          100,  1058,   100,   100,  2566,  3745, 11138,   100,  1997,\n",
            "         2048,   100,  3745,  1999,  3988,  2270,  3157,   100,  2765,\n",
            "         2421,  9313,  5114,  1997,   100,  2030, 14931,   102]],\n",
            "      dtype=int32), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "      dtype=int32))\n",
            "2020-09-01 18:08:44,907 [DEBUG] kashgari - predict output shape (1, 110)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['earn']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkFtf1vr3CZY",
        "outputId": "e6104158-be12-49a5-a69d-e415fd044faf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "loaded_model.evaluate(toknize_test,test_labels_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-09-01 18:10:17,533 [DEBUG] kashgari - predict input shape (2, 10389, 512) x: \n",
            "(array([[ 101, 1045, 2572, ...,    0,    0,    0],\n",
            "       [ 101, 1045, 2031, ...,    0,    0,    0],\n",
            "       [ 101, 1045, 2342, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [ 101, 3034, 3013, ...,    0,    0,    0],\n",
            "       [ 101, 3354, 3919, ...,    0,    0,    0],\n",
            "       [ 101, 2416, 2730, ...,    0,    0,    0]], dtype=int32), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32))\n",
            "2020-09-01 18:17:21,525 [DEBUG] kashgari - predict output shape (10389, 110)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                      precision    recall  f1-score   support\n",
            "                earn     0.9709    0.9825    0.9767      1087\n",
            "                 acq     0.9677    0.9583    0.9630       719\n",
            "      comp.windows.x     0.4296    0.5964    0.4995       394\n",
            "    rec.sport.hockey     0.9121    0.7143    0.8011       392\n",
            "soc.religion.christian     0.5245    0.8010    0.6339       387\n",
            "     rec.motorcycles     0.9403    0.3214    0.4791       392\n",
            "comp.sys.ibm.pc.hardware     0.5000    0.0052    0.0102       387\n",
            "        misc.forsale     0.8287    0.6108    0.7033       388\n",
            "             sci.med     0.9623    0.5312    0.6846       384\n",
            "  rec.sport.baseball     0.7622    0.6909    0.7248       385\n",
            "           sci.crypt     0.4503    0.6518    0.5326       382\n",
            "           sci.space     0.9820    0.4282    0.5964       383\n",
            "     sci.electronics     0.5520    0.3603    0.4360       383\n",
            "comp.os.ms-windows.misc     1.0000    0.0026    0.0052       382\n",
            "       comp.graphics     0.7683    0.1641    0.2704       384\n",
            "           rec.autos     0.8696    0.4762    0.6154       378\n",
            "comp.sys.mac.hardware     0.8485    0.0749    0.1376       374\n",
            "talk.politics.mideast     0.7402    0.7105    0.7250       373\n",
            "  talk.politics.guns     0.6716    0.1264    0.2128       356\n",
            "         alt.atheism     0.0000    0.0000    0.0000       313\n",
            "  talk.politics.misc     0.4337    0.3941    0.4130       307\n",
            "            money-fx     0.7826    0.8045    0.7934       179\n",
            "  talk.religion.misc     0.0000    0.0000    0.0000       246\n",
            "               grain     0.9493    0.8792    0.9129       149\n",
            "               crude     0.7637    0.9577    0.8498       189\n",
            "               trade     0.8053    0.7778    0.7913       117\n",
            "            interest     0.7801    0.8397    0.8088       131\n",
            "                ship     0.7973    0.6629    0.7239        89\n",
            "               wheat     0.9259    0.7042    0.8000        71\n",
            "                corn     0.8000    0.7857    0.7928        56\n",
            "                 dlr     0.8333    0.4545    0.5882        44\n",
            "        money-supply     0.7500    0.8824    0.8108        34\n",
            "             oilseed     0.7000    0.2979    0.4179        47\n",
            "               sugar     0.9615    0.6944    0.8065        36\n",
            "              coffee     0.9615    0.8929    0.9259        28\n",
            "                 gnp     0.8333    0.7143    0.7692        35\n",
            "             veg-oil     0.8421    0.4324    0.5714        37\n",
            "                gold     0.8095    0.5667    0.6667        30\n",
            "             soybean     0.5000    0.0909    0.1538        33\n",
            "             nat-gas     0.7059    0.4000    0.5106        30\n",
            "                 bop     0.6500    0.4333    0.5200        30\n",
            "           livestock     0.6667    0.6667    0.6667        24\n",
            "                 cpi     0.9286    0.4643    0.6190        28\n",
            "               cocoa     1.0000    0.9444    0.9714        18\n",
            "            reserves     0.9091    0.5556    0.6897        18\n",
            "             carcass     0.7143    0.5556    0.6250        18\n",
            "                jobs     1.0000    0.5714    0.7273        21\n",
            "              copper     1.0000    0.4444    0.6154        18\n",
            "              cotton     0.8571    0.3000    0.4444        20\n",
            "                 yen     0.7500    0.2143    0.3333        14\n",
            "                rice     0.8889    0.3333    0.4848        24\n",
            "                alum     0.9091    0.4348    0.5882        23\n",
            "                 gas     0.8571    0.7059    0.7742        17\n",
            "          iron-steel     0.8571    0.4286    0.5714        14\n",
            "                 ipi     0.9231    1.0000    0.9600        12\n",
            "              barley     0.6250    0.3571    0.4545        14\n",
            "           meal-feed     0.0000    0.0000    0.0000        19\n",
            "              rubber     1.0000    0.5833    0.7368        12\n",
            "            palm-oil     0.7143    0.5000    0.5882        10\n",
            "             sorghum     1.0000    0.1000    0.1818        10\n",
            "                zinc     0.8889    0.6154    0.7273        13\n",
            "            pet-chem     0.0000    0.0000    0.0000        12\n",
            "                 tin     1.0000    0.4167    0.5882        12\n",
            "                lead     0.8571    0.4286    0.5714        14\n",
            "              silver     0.0000    0.0000    0.0000         8\n",
            "                 wpi     1.0000    0.7000    0.8235        10\n",
            "     strategic-metal     0.0000    0.0000    0.0000        11\n",
            "            rapeseed     1.0000    0.4444    0.6154         9\n",
            "              orange     1.0000    0.5455    0.7059        11\n",
            "            soy-meal     0.0000    0.0000    0.0000        13\n",
            "             soy-oil     0.0000    0.0000    0.0000        11\n",
            "              retail     1.0000    0.5000    0.6667         2\n",
            "                fuel     0.6667    0.2000    0.3077        10\n",
            "                 hog     0.5000    0.3333    0.4000         6\n",
            "             housing     1.0000    0.5000    0.6667         4\n",
            "                heat     0.6667    0.4000    0.5000         5\n",
            "              income     1.0000    0.2857    0.4444         7\n",
            "             sunseed     0.0000    0.0000    0.0000         5\n",
            "              lumber     1.0000    0.1667    0.2857         6\n",
            "                 lei     1.0000    0.6667    0.8000         3\n",
            "                 dmk     0.0000    0.0000    0.0000         4\n",
            "                 oat     1.0000    0.1667    0.2857         6\n",
            "                 tea     0.0000    0.0000    0.0000         4\n",
            "            platinum     0.0000    0.0000    0.0000         7\n",
            "              nickel     0.0000    0.0000    0.0000         1\n",
            "           groundnut     0.0000    0.0000    0.0000         4\n",
            "            rape-oil     0.0000    0.0000    0.0000         3\n",
            "            l-cattle     0.0000    0.0000    0.0000         2\n",
            "             sun-oil     0.0000    0.0000    0.0000         2\n",
            "         coconut-oil     0.0000    0.0000    0.0000         3\n",
            "             propane     0.0000    0.0000    0.0000         3\n",
            "             coconut     0.0000    0.0000    0.0000         2\n",
            "         instal-debt     0.0000    0.0000    0.0000         1\n",
            "              potato     0.0000    0.0000    0.0000         3\n",
            "             naphtha     0.0000    0.0000    0.0000         4\n",
            "                 jet     0.0000    0.0000    0.0000         1\n",
            "               nzdlr     0.0000    0.0000    0.0000         2\n",
            "                 cpu     0.0000    0.0000    0.0000         1\n",
            "                 dfl     0.0000    0.0000    0.0000         1\n",
            "          palmkernel     0.0000    0.0000    0.0000         1\n",
            "                 nkr     0.0000    0.0000    0.0000         2\n",
            "          copra-cake     0.0000    0.0000    0.0000         1\n",
            "           palladium     0.0000    0.0000    0.0000         1\n",
            "          cotton-oil     0.0000    0.0000    0.0000         2\n",
            "                rand     0.0000    0.0000    0.0000         1\n",
            "          castor-oil     0.0000    0.0000    0.0000         1\n",
            "            sun-meal     0.0000    0.0000    0.0000         1\n",
            "       groundnut-oil     0.0000    0.0000    0.0000         1\n",
            "             lin-oil     0.0000    0.0000    0.0000         1\n",
            "                 rye     0.0000    0.0000    0.0000         1\n",
            "           macro avg     0.7415    0.5302    0.5646     11114\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'detail': {'acq': {'f1': 0.962962962962963,\n",
              "   'precision': 0.9676966292134831,\n",
              "   'recall': 0.9582753824756607,\n",
              "   'support': 719},\n",
              "  'alt.atheism': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 313},\n",
              "  'alum': {'f1': 0.5882352941176471,\n",
              "   'precision': 0.9090909090909091,\n",
              "   'recall': 0.43478260869565216,\n",
              "   'support': 23},\n",
              "  'barley': {'f1': 0.45454545454545453,\n",
              "   'precision': 0.625,\n",
              "   'recall': 0.35714285714285715,\n",
              "   'support': 14},\n",
              "  'bop': {'f1': 0.5199999999999999,\n",
              "   'precision': 0.65,\n",
              "   'recall': 0.43333333333333335,\n",
              "   'support': 30},\n",
              "  'carcass': {'f1': 0.6250000000000001,\n",
              "   'precision': 0.7142857142857143,\n",
              "   'recall': 0.5555555555555556,\n",
              "   'support': 18},\n",
              "  'castor-oil': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 1},\n",
              "  'cocoa': {'f1': 0.9714285714285714,\n",
              "   'precision': 1.0,\n",
              "   'recall': 0.9444444444444444,\n",
              "   'support': 18},\n",
              "  'coconut': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 2},\n",
              "  'coconut-oil': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 3},\n",
              "  'coffee': {'f1': 0.9259259259259259,\n",
              "   'precision': 0.9615384615384616,\n",
              "   'recall': 0.8928571428571429,\n",
              "   'support': 28},\n",
              "  'comp.graphics': {'f1': 0.27038626609442057,\n",
              "   'precision': 0.7682926829268293,\n",
              "   'recall': 0.1640625,\n",
              "   'support': 384},\n",
              "  'comp.os.ms-windows.misc': {'f1': 0.005221932114882507,\n",
              "   'precision': 1.0,\n",
              "   'recall': 0.002617801047120419,\n",
              "   'support': 382},\n",
              "  'comp.sys.ibm.pc.hardware': {'f1': 0.010230179028132991,\n",
              "   'precision': 0.5,\n",
              "   'recall': 0.00516795865633075,\n",
              "   'support': 387},\n",
              "  'comp.sys.mac.hardware': {'f1': 0.1375921375921376,\n",
              "   'precision': 0.8484848484848485,\n",
              "   'recall': 0.0748663101604278,\n",
              "   'support': 374},\n",
              "  'comp.windows.x': {'f1': 0.4994686503719448,\n",
              "   'precision': 0.4296160877513711,\n",
              "   'recall': 0.5964467005076142,\n",
              "   'support': 394},\n",
              "  'copper': {'f1': 0.6153846153846153,\n",
              "   'precision': 1.0,\n",
              "   'recall': 0.4444444444444444,\n",
              "   'support': 18},\n",
              "  'copra-cake': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 1},\n",
              "  'corn': {'f1': 0.7927927927927927,\n",
              "   'precision': 0.8,\n",
              "   'recall': 0.7857142857142857,\n",
              "   'support': 56},\n",
              "  'cotton': {'f1': 0.4444444444444444,\n",
              "   'precision': 0.8571428571428571,\n",
              "   'recall': 0.3,\n",
              "   'support': 20},\n",
              "  'cotton-oil': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 2},\n",
              "  'cpi': {'f1': 0.6190476190476191,\n",
              "   'precision': 0.9285714285714286,\n",
              "   'recall': 0.4642857142857143,\n",
              "   'support': 28},\n",
              "  'cpu': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 1},\n",
              "  'crude': {'f1': 0.8497652582159624,\n",
              "   'precision': 0.7637130801687764,\n",
              "   'recall': 0.9576719576719577,\n",
              "   'support': 189},\n",
              "  'dfl': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 1},\n",
              "  'dlr': {'f1': 0.5882352941176471,\n",
              "   'precision': 0.8333333333333334,\n",
              "   'recall': 0.45454545454545453,\n",
              "   'support': 44},\n",
              "  'dmk': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 4},\n",
              "  'earn': {'f1': 0.9766803840877916,\n",
              "   'precision': 0.9709090909090909,\n",
              "   'recall': 0.9825206991720331,\n",
              "   'support': 1087},\n",
              "  'fuel': {'f1': 0.30769230769230765,\n",
              "   'precision': 0.6666666666666666,\n",
              "   'recall': 0.2,\n",
              "   'support': 10},\n",
              "  'gas': {'f1': 0.7741935483870968,\n",
              "   'precision': 0.8571428571428571,\n",
              "   'recall': 0.7058823529411765,\n",
              "   'support': 17},\n",
              "  'gnp': {'f1': 0.7692307692307692,\n",
              "   'precision': 0.8333333333333334,\n",
              "   'recall': 0.7142857142857143,\n",
              "   'support': 35},\n",
              "  'gold': {'f1': 0.6666666666666666,\n",
              "   'precision': 0.8095238095238095,\n",
              "   'recall': 0.5666666666666667,\n",
              "   'support': 30},\n",
              "  'grain': {'f1': 0.9128919860627177,\n",
              "   'precision': 0.9492753623188406,\n",
              "   'recall': 0.8791946308724832,\n",
              "   'support': 149},\n",
              "  'groundnut': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 4},\n",
              "  'groundnut-oil': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 1},\n",
              "  'heat': {'f1': 0.5,\n",
              "   'precision': 0.6666666666666666,\n",
              "   'recall': 0.4,\n",
              "   'support': 5},\n",
              "  'hog': {'f1': 0.4,\n",
              "   'precision': 0.5,\n",
              "   'recall': 0.3333333333333333,\n",
              "   'support': 6},\n",
              "  'housing': {'f1': 0.6666666666666666,\n",
              "   'precision': 1.0,\n",
              "   'recall': 0.5,\n",
              "   'support': 4},\n",
              "  'income': {'f1': 0.4444444444444445,\n",
              "   'precision': 1.0,\n",
              "   'recall': 0.2857142857142857,\n",
              "   'support': 7},\n",
              "  'instal-debt': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 1},\n",
              "  'interest': {'f1': 0.8088235294117647,\n",
              "   'precision': 0.7801418439716312,\n",
              "   'recall': 0.8396946564885496,\n",
              "   'support': 131},\n",
              "  'ipi': {'f1': 0.9600000000000001,\n",
              "   'precision': 0.9230769230769231,\n",
              "   'recall': 1.0,\n",
              "   'support': 12},\n",
              "  'iron-steel': {'f1': 0.5714285714285714,\n",
              "   'precision': 0.8571428571428571,\n",
              "   'recall': 0.42857142857142855,\n",
              "   'support': 14},\n",
              "  'jet': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 1},\n",
              "  'jobs': {'f1': 0.7272727272727273,\n",
              "   'precision': 1.0,\n",
              "   'recall': 0.5714285714285714,\n",
              "   'support': 21},\n",
              "  'l-cattle': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 2},\n",
              "  'lead': {'f1': 0.5714285714285714,\n",
              "   'precision': 0.8571428571428571,\n",
              "   'recall': 0.42857142857142855,\n",
              "   'support': 14},\n",
              "  'lei': {'f1': 0.8,\n",
              "   'precision': 1.0,\n",
              "   'recall': 0.6666666666666666,\n",
              "   'support': 3},\n",
              "  'lin-oil': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 1},\n",
              "  'livestock': {'f1': 0.6666666666666666,\n",
              "   'precision': 0.6666666666666666,\n",
              "   'recall': 0.6666666666666666,\n",
              "   'support': 24},\n",
              "  'lumber': {'f1': 0.2857142857142857,\n",
              "   'precision': 1.0,\n",
              "   'recall': 0.16666666666666666,\n",
              "   'support': 6},\n",
              "  'meal-feed': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 19},\n",
              "  'misc.forsale': {'f1': 0.7032640949554896,\n",
              "   'precision': 0.8286713286713286,\n",
              "   'recall': 0.6108247422680413,\n",
              "   'support': 388},\n",
              "  'money-fx': {'f1': 0.7933884297520662,\n",
              "   'precision': 0.782608695652174,\n",
              "   'recall': 0.8044692737430168,\n",
              "   'support': 179},\n",
              "  'money-supply': {'f1': 0.8108108108108107,\n",
              "   'precision': 0.75,\n",
              "   'recall': 0.8823529411764706,\n",
              "   'support': 34},\n",
              "  'naphtha': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 4},\n",
              "  'nat-gas': {'f1': 0.5106382978723405,\n",
              "   'precision': 0.7058823529411765,\n",
              "   'recall': 0.4,\n",
              "   'support': 30},\n",
              "  'nickel': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 1},\n",
              "  'nkr': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 2},\n",
              "  'nzdlr': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 2},\n",
              "  'oat': {'f1': 0.2857142857142857,\n",
              "   'precision': 1.0,\n",
              "   'recall': 0.16666666666666666,\n",
              "   'support': 6},\n",
              "  'oilseed': {'f1': 0.417910447761194,\n",
              "   'precision': 0.7,\n",
              "   'recall': 0.2978723404255319,\n",
              "   'support': 47},\n",
              "  'orange': {'f1': 0.7058823529411764,\n",
              "   'precision': 1.0,\n",
              "   'recall': 0.5454545454545454,\n",
              "   'support': 11},\n",
              "  'palladium': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 1},\n",
              "  'palm-oil': {'f1': 0.588235294117647,\n",
              "   'precision': 0.7142857142857143,\n",
              "   'recall': 0.5,\n",
              "   'support': 10},\n",
              "  'palmkernel': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 1},\n",
              "  'pet-chem': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 12},\n",
              "  'platinum': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 7},\n",
              "  'potato': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 3},\n",
              "  'propane': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 3},\n",
              "  'rand': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 1},\n",
              "  'rape-oil': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 3},\n",
              "  'rapeseed': {'f1': 0.6153846153846153,\n",
              "   'precision': 1.0,\n",
              "   'recall': 0.4444444444444444,\n",
              "   'support': 9},\n",
              "  'rec.autos': {'f1': 0.6153846153846153,\n",
              "   'precision': 0.8695652173913043,\n",
              "   'recall': 0.47619047619047616,\n",
              "   'support': 378},\n",
              "  'rec.motorcycles': {'f1': 0.47908745247148293,\n",
              "   'precision': 0.9402985074626866,\n",
              "   'recall': 0.32142857142857145,\n",
              "   'support': 392},\n",
              "  'rec.sport.baseball': {'f1': 0.7247956403269755,\n",
              "   'precision': 0.7621776504297995,\n",
              "   'recall': 0.6909090909090909,\n",
              "   'support': 385},\n",
              "  'rec.sport.hockey': {'f1': 0.8011444921316165,\n",
              "   'precision': 0.9120521172638436,\n",
              "   'recall': 0.7142857142857143,\n",
              "   'support': 392},\n",
              "  'reserves': {'f1': 0.6896551724137931,\n",
              "   'precision': 0.9090909090909091,\n",
              "   'recall': 0.5555555555555556,\n",
              "   'support': 18},\n",
              "  'retail': {'f1': 0.6666666666666666,\n",
              "   'precision': 1.0,\n",
              "   'recall': 0.5,\n",
              "   'support': 2},\n",
              "  'rice': {'f1': 0.48484848484848486,\n",
              "   'precision': 0.8888888888888888,\n",
              "   'recall': 0.3333333333333333,\n",
              "   'support': 24},\n",
              "  'rubber': {'f1': 0.7368421052631579,\n",
              "   'precision': 1.0,\n",
              "   'recall': 0.5833333333333334,\n",
              "   'support': 12},\n",
              "  'rye': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 1},\n",
              "  'sci.crypt': {'f1': 0.532620320855615,\n",
              "   'precision': 0.45027124773960214,\n",
              "   'recall': 0.6518324607329843,\n",
              "   'support': 382},\n",
              "  'sci.electronics': {'f1': 0.4360189573459716,\n",
              "   'precision': 0.552,\n",
              "   'recall': 0.360313315926893,\n",
              "   'support': 383},\n",
              "  'sci.med': {'f1': 0.6845637583892618,\n",
              "   'precision': 0.9622641509433962,\n",
              "   'recall': 0.53125,\n",
              "   'support': 384},\n",
              "  'sci.space': {'f1': 0.5963636363636363,\n",
              "   'precision': 0.9820359281437125,\n",
              "   'recall': 0.4281984334203655,\n",
              "   'support': 383},\n",
              "  'ship': {'f1': 0.7239263803680981,\n",
              "   'precision': 0.7972972972972973,\n",
              "   'recall': 0.6629213483146067,\n",
              "   'support': 89},\n",
              "  'silver': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 8},\n",
              "  'soc.religion.christian': {'f1': 0.6339468302658486,\n",
              "   'precision': 0.5245346869712352,\n",
              "   'recall': 0.8010335917312662,\n",
              "   'support': 387},\n",
              "  'sorghum': {'f1': 0.18181818181818182,\n",
              "   'precision': 1.0,\n",
              "   'recall': 0.1,\n",
              "   'support': 10},\n",
              "  'soy-meal': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 13},\n",
              "  'soy-oil': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 11},\n",
              "  'soybean': {'f1': 0.15384615384615385,\n",
              "   'precision': 0.5,\n",
              "   'recall': 0.09090909090909091,\n",
              "   'support': 33},\n",
              "  'strategic-metal': {'f1': 0.0,\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'support': 11},\n",
              "  'sugar': {'f1': 0.8064516129032258,\n",
              "   'precision': 0.9615384615384616,\n",
              "   'recall': 0.6944444444444444,\n",
              "   'support': 36},\n",
              "  'sun-meal': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 1},\n",
              "  'sun-oil': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 2},\n",
              "  'sunseed': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 5},\n",
              "  'talk.politics.guns': {'f1': 0.2127659574468085,\n",
              "   'precision': 0.6716417910447762,\n",
              "   'recall': 0.12640449438202248,\n",
              "   'support': 356},\n",
              "  'talk.politics.mideast': {'f1': 0.7250341997264022,\n",
              "   'precision': 0.7402234636871509,\n",
              "   'recall': 0.710455764075067,\n",
              "   'support': 373},\n",
              "  'talk.politics.misc': {'f1': 0.41296928327645055,\n",
              "   'precision': 0.4336917562724014,\n",
              "   'recall': 0.3941368078175896,\n",
              "   'support': 307},\n",
              "  'talk.religion.misc': {'f1': 0.0,\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'support': 246},\n",
              "  'tea': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 4},\n",
              "  'tin': {'f1': 0.5882352941176471,\n",
              "   'precision': 1.0,\n",
              "   'recall': 0.4166666666666667,\n",
              "   'support': 12},\n",
              "  'trade': {'f1': 0.7913043478260869,\n",
              "   'precision': 0.8053097345132744,\n",
              "   'recall': 0.7777777777777778,\n",
              "   'support': 117},\n",
              "  'veg-oil': {'f1': 0.5714285714285715,\n",
              "   'precision': 0.8421052631578947,\n",
              "   'recall': 0.43243243243243246,\n",
              "   'support': 37},\n",
              "  'wheat': {'f1': 0.7999999999999999,\n",
              "   'precision': 0.9259259259259259,\n",
              "   'recall': 0.704225352112676,\n",
              "   'support': 71},\n",
              "  'wpi': {'f1': 0.8235294117647058,\n",
              "   'precision': 1.0,\n",
              "   'recall': 0.7,\n",
              "   'support': 10},\n",
              "  'yen': {'f1': 0.3333333333333333,\n",
              "   'precision': 0.75,\n",
              "   'recall': 0.21428571428571427,\n",
              "   'support': 14},\n",
              "  'zinc': {'f1': 0.7272727272727274,\n",
              "   'precision': 0.8888888888888888,\n",
              "   'recall': 0.6153846153846154,\n",
              "   'support': 13}},\n",
              " 'f1-score': 0.5646481803703589,\n",
              " 'precision': 0.7414827154806805,\n",
              " 'recall': 0.5302321396436926,\n",
              " 'support': 11114}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 257
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFhPC2q9zpsm",
        "outputId": "e8f57954-1776-4fe8-86f5-feee5f2c7f3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "all_dataframes_test['title'][10360]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['money-fx']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3s6-rJGlq9BH"
      },
      "source": [
        "nltk_tokens = nltk.word_tokenize(text)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbh2CiAi0E_I"
      },
      "source": [
        "x=all_dataframes_test['text'][10360]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykcqh6DN0pyK"
      },
      "source": [
        "text=all_dataframes_test['text'][10001]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QScrCCpl2r87",
        "outputId": "764cae2b-ad6b-408b-e881-15e11a810630",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'jepson corp qtr net shr ct v ct net v sale mln v mln avg shrs mln v mln nine mths shr ct v ct net mln v mln sale mln v mln avg shrs mln v mln qtr per share reflects issuance of two mln share in initial public nine mth result include extraordinary gain of dlrs or ct'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od1HY3sr6JLz"
      },
      "source": [
        "all_dataframes_train.to_csv(\"train_allDatasets.csv\")\n",
        "all_dataframes_test.to_csv(\"test_allDatasets.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1eT7Wij6Vf_"
      },
      "source": [
        "!cp '/content/train_allDatasets.csv' '/content/drive/My Drive/'\n",
        "!cp '/content/test_allDatasets.csv' '/content/drive/My Drive/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJVFQ1gr6rQH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
