{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AllDataSets.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "10Q4C9D1TtT6",
        "q2DUzfTBVGDh",
        "LftfGaf7VxA5",
        "IC8WTXSKWG4Y"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alymostafa/Nlp_task/blob/main/Best_results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10Q4C9D1TtT6"
      },
      "source": [
        "##weights and biases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS4H24CcTb3m",
        "outputId": "32a928d5-cca9-44dd-a103-9cd6848dd9d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install  wandb"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/14/9a2c792e48e01e55913b9495ce0e8a16297e2bc1cc99e86a848d205c91e7/wandb-0.10.5-py2.py3-none-any.whl (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7MB 4.5MB/s \n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/d7/b2b0672e0331567157adf9281f41ee731c412ee518ca5e6552c27fa73c91/GitPython-3.1.9-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 29.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.3)\n",
            "Collecting watchdog>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/06/121302598a4fc01aca942d937f4a2c33430b7181137b35758913a8db10ad/watchdog-0.10.3.tar.gz (94kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 10.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.8.1)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/08/b2/ef713e0e67f6e7ec7d59aea3ee78d05b39c15930057e724cc6d362a8c3bb/configparser-5.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.23.0)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 10.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.15.0)\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/df/1145dc9389138eb47649806b42aaad5b0ecdfd3e93c7c51c1fffd80a8f90/sentry_sdk-0.18.0-py2.py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 28.4MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.8MB/s \n",
            "\u001b[?25hCollecting pathtools>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.12.0->wandb) (50.3.0)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: watchdog, subprocess32, pathtools\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for watchdog: filename=watchdog-0.10.3-cp36-none-any.whl size=73873 sha256=f2b4c86f2a587ed3e2de5ec2d645cbd7e23c84b54dc847cf9693ccb6bd38130c\n",
            "  Stored in directory: /root/.cache/pip/wheels/a8/1d/38/2c19bb311f67cc7b4d07a2ec5ea36ab1a0a0ea50db994a5bc7\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp36-none-any.whl size=6489 sha256=de7d56a35930f8ea2c5e9f30a97aaa694b6330a23867aad9ee2ccc32debd28dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8785 sha256=134a6ea9299bb16a90d2c81840ae75b521df1f0b65af655047899584d8632382\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "Successfully built watchdog subprocess32 pathtools\n",
            "Installing collected packages: smmap, gitdb, GitPython, docker-pycreds, pathtools, watchdog, configparser, shortuuid, subprocess32, sentry-sdk, wandb\n",
            "Successfully installed GitPython-3.1.9 configparser-5.0.1 docker-pycreds-0.4.0 gitdb-4.0.5 pathtools-0.1.2 sentry-sdk-0.18.0 shortuuid-1.0.1 smmap-3.0.4 subprocess32-3.5.4 wandb-0.10.5 watchdog-0.10.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXhzr-ddTytT",
        "outputId": "334ce1d5-9a83-49ca-c699-4c2b362c5580",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "!wandb login "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Huwg0stEesjT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2DUzfTBVGDh"
      },
      "source": [
        "##imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KQyzsfVTSu7",
        "outputId": "9c1da7a5-fa99-4d1e-9a84-cdccb76feaf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "from pprint import pprint\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import os, sys\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from collections import defaultdict\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import names\n",
        "import nltk\n",
        "nltk.download('names')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import re \n",
        "from nltk.corpus import stopwords\n",
        "#from sklearn.datasets import fetch_rcv1\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/names.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LftfGaf7VxA5"
      },
      "source": [
        "##<h1>First DataSets</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMB81FoajP3E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlZaGfDMjP0Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9FSY4FJjPXY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlsdfEhcTa5U"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import pandas as pd\n",
        "def twenty_newsgroup_to_csv(data,name):\n",
        "    newsgroups_train = fetch_20newsgroups(subset= data , remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "    df = pd.DataFrame([newsgroups_train.data, newsgroups_train.target.tolist()]).T\n",
        "    df.columns = ['text', 'target']\n",
        "\n",
        "    targets = pd.DataFrame( newsgroups_train.target_names)\n",
        "    targets.columns=['title']\n",
        "\n",
        "    out = pd.merge(df, targets, left_on='target', right_index=True)\n",
        "    out['date'] = pd.to_datetime('now')\n",
        "    out.to_csv(name+'.csv')\n",
        "\n",
        "twenty_newsgroup_to_csv('train','train')\n",
        "twenty_newsgroup_to_csv('test','test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUh0cOm6VOTn"
      },
      "source": [
        "df = pd.read_csv(\"train.csv\")\n",
        "df_test = pd.read_csv(\"test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTKU_zQ0VQQF"
      },
      "source": [
        "df.dropna(subset = [\"text\"], inplace=True)\n",
        "df_test.dropna(subset = [\"text\"], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfCWwSQaVR2U"
      },
      "source": [
        "all_names = names.words()\n",
        "WNL = WordNetLemmatizer()\n",
        "def clean(data):\n",
        "    cleaned = defaultdict(list)\n",
        "    count = 0\n",
        "    for group in data:\n",
        "        for words in group.split():\n",
        "            if words.isalpha() and words not in all_names:\n",
        "                cleaned[count].append(WNL.lemmatize(words.lower()))\n",
        "        cleaned[count] = ' '.join(cleaned[count])\n",
        "        count +=1 \n",
        "    return(list(cleaned.values()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-caJuK8-VT-e"
      },
      "source": [
        "df['text'] = clean(df['text'])\n",
        "df_test['text'] = clean(df_test['text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecqTmBE_VYB3",
        "outputId": "6cc47fc7-50f3-4d23-a577-fc22be24df79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(len(df))\n",
        "print(len(df_test))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11096\n",
            "7370\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Cfx_qrTc4uZ"
      },
      "source": [
        "df.drop(labels=['target','date'],axis=1,inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mSVxTOLdYgF"
      },
      "source": [
        "df_test.drop(labels=['target','date'],axis=1,inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC8WTXSKWG4Y"
      },
      "source": [
        "##<h1>Second Dataset</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnQjj487WGV1",
        "outputId": "92684f61-7975-4414-97f3-8275a9eb0eec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "nltk.download('reuters')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords, reuters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qNHmTA4WGZt"
      },
      "source": [
        "documents = reuters.fileids()\n",
        " \n",
        "train_docs_id = list(filter(lambda doc: doc.startswith(\"train\"),\n",
        "                            documents))\n",
        "test_docs_id = list(filter(lambda doc: doc.startswith(\"test\"),\n",
        "                           documents))\n",
        " \n",
        "train_docs = [reuters.raw(doc_id) for doc_id in train_docs_id]\n",
        "test_docs = [reuters.raw(doc_id) for doc_id in test_docs_id]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWlWSSVnWvni"
      },
      "source": [
        "docs_pdf_train = pd.DataFrame(train_docs) \n",
        "docs_pdf_test = pd.DataFrame(test_docs) \n",
        "docs_pdf_train['text'] = pd.DataFrame(train_docs) \n",
        "docs_pdf_test['text'] = pd.DataFrame(test_docs) \n",
        "docs_pdf_train.drop([docs_pdf_train.columns[0]], axis ='columns',inplace=True)\n",
        "docs_pdf_test.drop([docs_pdf_test.columns[0]], axis ='columns',inplace=True)\n",
        "docs_pdf_train.dropna(inplace=True)\n",
        "docs_pdf_test.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9fJXsNgWxXl"
      },
      "source": [
        "docs_pdf_train.dropna(subset = [\"text\"], inplace=True)\n",
        "docs_pdf_train.replace(r'-', ' ', regex=True,inplace=True)\n",
        "docs_pdf_train.replace(r'\\t', ' ', regex=True,inplace=True)\n",
        "docs_pdf_train.replace(r'\\n', ' ', regex=True,inplace=True)\n",
        "docs_pdf_train.replace(r'   ', ' ', regex=True,inplace=True)\n",
        "docs_pdf_test.replace(r'-', ' ', regex=True,inplace=True)\n",
        "docs_pdf_test.replace(r'\\t', ' ', regex=True,inplace=True)\n",
        "docs_pdf_test.replace(r'\\n', ' ', regex=True,inplace=True)\n",
        "docs_pdf_test.replace(r'   ', ' ', regex=True,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhPS757oWzAE"
      },
      "source": [
        "docs_pdf_train['text'] = clean(docs_pdf_train['text'])\n",
        "docs_pdf_test['text'] = clean(docs_pdf_test['text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz_dt1BFW-wj"
      },
      "source": [
        "train_labels = [reuters.categories(doc_id)for doc_id in train_docs_id]\n",
        "test_labels = [reuters.categories(doc_id)for doc_id in test_docs_id]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm-V3oLvXf0X"
      },
      "source": [
        "achedStopWords = stopwords.words(\"english\")\n",
        " \n",
        "def tokenize(text):\n",
        "  min_length = 3\n",
        "  words = map(lambda word: word.lower(), word_tokenize(text))\n",
        "  words = [word for word in words if word not in achedStopWords]\n",
        "  tokens = (list(map(lambda token: PorterStemmer().stem(token),\n",
        "                                   words)))\n",
        "  p = re.compile('[a-zA-Z]+');\n",
        "  filtered_tokens =list(filter (lambda token: p.match(token) and\n",
        "                               len(token) >= min_length,\n",
        "                               tokens))\n",
        "  return filtered_tokens\n",
        "\n",
        "def word_tokenizer():\n",
        "  tokenize_docs = []\n",
        "  docs_tokens = docs_pdf_train['text'].tolist()\n",
        "  length = len(docs_tokens)\n",
        "  for i in range(length):\n",
        "    tokenize_docs.append(tokenize(docs_tokens[i]))\n",
        "  return tokenize_docs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGBstEu1Xlg7"
      },
      "source": [
        "tokenize_docs = word_tokenizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZbeJ_w7XnJV"
      },
      "source": [
        "def word_tokenizer_test():\n",
        "  tokenize_docs = []\n",
        "  docs_tokens = docs_pdf_test['text'].tolist()\n",
        "  length = len(docs_tokens)\n",
        "  for i in range(length):\n",
        "    tokenize_docs.append(tokenize(docs_tokens[i]))\n",
        "  return tokenize_docs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qrk2e6C-Yigy"
      },
      "source": [
        "tokenize_docs_test = word_tokenizer_test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX5V-zHeZBRO"
      },
      "source": [
        "df_train_2=pd.DataFrame(docs_pdf_train,columns=['text'])\n",
        "df_train_2['target']=''\n",
        "df_train_2['target']=train_labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlA8Zg9lZS8b",
        "outputId": "df9c038e-8bd7-46c0-87ac-9e2ad78f8aba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "df_test_2=pd.DataFrame(docs_pdf_test,columns=['text'])\n",
        "df_test_2['target']=''\n",
        "df_test_2['target']=test_labels\n",
        "df_test_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>asian exporter fear damage from japan rift mou...</td>\n",
              "      <td>[trade]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>china daily say vermin eat pct grain stock a s...</td>\n",
              "      <td>[grain]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>japan to revise long term energy demand downwa...</td>\n",
              "      <td>[crude, nat-gas]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>thai trade deficit widens in first quarter tra...</td>\n",
              "      <td>[corn, grain, rice, rubber, sugar, tin, trade]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>indonesia see cpo price rising sharply indones...</td>\n",
              "      <td>[palm-oil, veg-oil]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3014</th>\n",
              "      <td>chase corp make offer for entregrowth corp ltd...</td>\n",
              "      <td>[acq]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3015</th>\n",
              "      <td>tokyo dealer see dollar poised to breach yen f...</td>\n",
              "      <td>[dlr, money-fx, yen]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3016</th>\n",
              "      <td>conference cut gulf war risk charge the pakist...</td>\n",
              "      <td>[ship]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3017</th>\n",
              "      <td>soviet industrial slower in the soviet industr...</td>\n",
              "      <td>[ipi]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3018</th>\n",
              "      <td>six killed in south african gold mine accident...</td>\n",
              "      <td>[gold]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3019 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text                                          target\n",
              "0     asian exporter fear damage from japan rift mou...                                         [trade]\n",
              "1     china daily say vermin eat pct grain stock a s...                                         [grain]\n",
              "2     japan to revise long term energy demand downwa...                                [crude, nat-gas]\n",
              "3     thai trade deficit widens in first quarter tra...  [corn, grain, rice, rubber, sugar, tin, trade]\n",
              "4     indonesia see cpo price rising sharply indones...                             [palm-oil, veg-oil]\n",
              "...                                                 ...                                             ...\n",
              "3014  chase corp make offer for entregrowth corp ltd...                                           [acq]\n",
              "3015  tokyo dealer see dollar poised to breach yen f...                            [dlr, money-fx, yen]\n",
              "3016  conference cut gulf war risk charge the pakist...                                          [ship]\n",
              "3017  soviet industrial slower in the soviet industr...                                           [ipi]\n",
              "3018  six killed in south african gold mine accident...                                          [gold]\n",
              "\n",
              "[3019 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H80bi5mJdij8"
      },
      "source": [
        "df_train_2.rename(columns={'target':'title'},inplace=True)\n",
        "df_test_2.rename(columns={'target':'title'},inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtSPEEMJbkT2"
      },
      "source": [
        "frames_train=[df,df_train_2]\n",
        "frames_test=[df_test,df_test_2]\n",
        "all_dataframes_train=pd.concat(frames_train,keys=['x','y'])\n",
        "all_dataframes_test=pd.concat(frames_test,keys=['x','y'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hD4urXUcO-j"
      },
      "source": [
        "all_dataframes_train.drop(labels='Unnamed: 0',inplace=True,axis=1)\n",
        "all_dataframes_test.drop(labels='Unnamed: 0',inplace=True,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LC1-CTjwf73w"
      },
      "source": [
        "##Bert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByKWd3XifaR-",
        "outputId": "5b418597-4531-4948-9023-0d10ab888d45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        }
      },
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "wandb.init(project=\"nlp-task\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malymostafa\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.5<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">vivid-music-15</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/alymostafa/nlp-task\" target=\"_blank\">https://wandb.ai/alymostafa/nlp-task</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/alymostafa/nlp-task/runs/12x51cbi\" target=\"_blank\">https://wandb.ai/alymostafa/nlp-task/runs/12x51cbi</a><br/>\n",
              "                Run data is saved locally in <code>wandb/run-20201012_042017-12x51cbi</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fd5f743b7f0>"
            ],
            "text/html": [
              "<h1>Run(12x51cbi)</h1><p></p><iframe src=\"https://wandb.ai/alymostafa/nlp-task/runs/12x51cbi\" style=\"border:none;width:100%;height:400px\"></iframe>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5v3uYAsgKhg",
        "outputId": "962a9509-0b77-4f18-dfa2-839e3c54810d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install 'kashgari>=2.0.0'\t"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kashgari>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/81/c638e3b166bcaaf4e1a86502dcca5912b15bc51db4b5235031df3b55565e/kashgari-2.0.0-py3-none-any.whl (85kB)\n",
            "\r\u001b[K     |███▉                            | 10kB 28.5MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 20kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 30kB 3.7MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 40kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 51kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 61kB 3.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 71kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 81kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.6/dist-packages (from kashgari>=2.0.0) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kashgari>=2.0.0) (4.41.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from kashgari>=2.0.0) (0.22.2.post1)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.6/dist-packages (from kashgari>=2.0.0) (0.8.3)\n",
            "Requirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from kashgari>=2.0.0) (2.3.0)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from kashgari>=2.0.0) (1.1.2)\n",
            "Collecting gensim>=3.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/e0/fa6326251692056dc880a64eb22117e03269906ba55a6864864d24ec8b4e/gensim-3.8.3-cp36-cp36m-manylinux1_x86_64.whl (24.2MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2MB 130kB/s \n",
            "\u001b[?25hCollecting bert4keras>=0.7.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/ef/1b0f236ba7b98197ee0878b445535ffa9e49a3166259431a6c2c2095fa01/bert4keras-0.8.8.tar.gz (40kB)\n",
            "\u001b[K     |████████████████████████████████| 40kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.1->kashgari>=2.0.0) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.1->kashgari>=2.0.0) (0.16.0)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons->kashgari>=2.0.0) (2.7.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->kashgari>=2.0.0) (0.10.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->kashgari>=2.0.0) (0.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->kashgari>=2.0.0) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->kashgari>=2.0.0) (2.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->kashgari>=2.0.0) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->kashgari>=2.0.0) (0.35.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->kashgari>=2.0.0) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->kashgari>=2.0.0) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->kashgari>=2.0.0) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->kashgari>=2.0.0) (2.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->kashgari>=2.0.0) (3.12.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->kashgari>=2.0.0) (1.32.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->kashgari>=2.0.0) (0.3.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->kashgari>=2.0.0) (1.1.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->kashgari>=2.0.0) (2.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.1->kashgari>=2.0.0) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.1->kashgari>=2.0.0) (2018.9)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.8.1->kashgari>=2.0.0) (2.2.0)\n",
            "Collecting keras<=2.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 57.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (50.3.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (1.7.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (0.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (1.17.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (1.0.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras>=0.7.9->kashgari>=2.0.0) (3.13)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (2.10)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (4.1.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->kashgari>=2.0.0) (3.2.0)\n",
            "Building wheels for collected packages: bert4keras\n",
            "  Building wheel for bert4keras (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert4keras: filename=bert4keras-0.8.8-cp36-none-any.whl size=39383 sha256=47a38b8758bbacfc41d50b17f71aeba3de01727a8a8fd83c1a2b34ded5cacb7b\n",
            "  Stored in directory: /root/.cache/pip/wheels/6f/07/52/94c66529c3cee3757d96608bb593adbe623b6f29881bec342b\n",
            "Successfully built bert4keras\n",
            "Installing collected packages: gensim, keras-applications, keras, bert4keras, kashgari\n",
            "  Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed bert4keras-0.8.8 gensim-3.8.3 kashgari-2.0.0 keras-2.3.1 keras-applications-1.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypzt10uwf-PA"
      },
      "source": [
        "import logging\n",
        "from kashgari.embeddings import BertEmbedding\n",
        "from kashgari.tasks.classification import BiGRU_Model\n",
        "from kashgari.tasks.classification import BiLSTM_Model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSVnaPskgF9U"
      },
      "source": [
        "logging.basicConfig(level='DEBUG')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjsemvPngPWn",
        "outputId": "91b1729d-9f7d-4493-baa5-d8aaf76b236a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-12 06:32:28--  https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 74.125.142.128, 74.125.195.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 407727028 (389M) [application/zip]\n",
            "Saving to: ‘uncased_L-12_H-768_A-12.zip’\n",
            "\n",
            "uncased_L-12_H-768_ 100%[===================>] 388.84M   137MB/s    in 2.8s    \n",
            "\n",
            "2020-10-12 06:32:31 (137 MB/s) - ‘uncased_L-12_H-768_A-12.zip’ saved [407727028/407727028]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NeVZMiSgSBB",
        "outputId": "c292bcad-ff74-49b9-f81e-c3d3db07d7fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "!unzip '/content/uncased_L-12_H-768_A-12.zip'"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/uncased_L-12_H-768_A-12.zip\n",
            "   creating: uncased_L-12_H-768_A-12/\n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: uncased_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_config.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVabElOcgTp4",
        "outputId": "ea537239-7db1-434e-bd9c-35e17fcec2cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "bert_embed = BertEmbedding('/content/uncased_L-12_H-768_A-12')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-12 06:32:36,162 [DEBUG] kashgari - ------------------------------------------------\n",
            "2020-10-12 06:32:36,163 [DEBUG] kashgari - Loaded transformer model's vocab\n",
            "2020-10-12 06:32:36,163 [DEBUG] kashgari - config_path       : /content/uncased_L-12_H-768_A-12/bert_config.json\n",
            "2020-10-12 06:32:36,164 [DEBUG] kashgari - vocab_path      : /content/uncased_L-12_H-768_A-12/vocab.txt\n",
            "2020-10-12 06:32:36,164 [DEBUG] kashgari - checkpoint_path : /content/uncased_L-12_H-768_A-12/bert_model.ckpt\n",
            "2020-10-12 06:32:36,165 [DEBUG] kashgari - Top 50 words    : ['[PAD]', '[unused0]', '[unused1]', '[unused2]', '[unused3]', '[unused4]', '[unused5]', '[unused6]', '[unused7]', '[unused8]', '[unused9]', '[unused10]', '[unused11]', '[unused12]', '[unused13]', '[unused14]', '[unused15]', '[unused16]', '[unused17]', '[unused18]', '[unused19]', '[unused20]', '[unused21]', '[unused22]', '[unused23]', '[unused24]', '[unused25]', '[unused26]', '[unused27]', '[unused28]', '[unused29]', '[unused30]', '[unused31]', '[unused32]', '[unused33]', '[unused34]', '[unused35]', '[unused36]', '[unused37]', '[unused38]', '[unused39]', '[unused40]', '[unused41]', '[unused42]', '[unused43]', '[unused44]', '[unused45]', '[unused46]', '[unused47]', '[unused48]']\n",
            "2020-10-12 06:32:36,165 [DEBUG] kashgari - ------------------------------------------------\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EV_emcz0gVvg"
      },
      "source": [
        "model = BiLSTM_Model(bert_embed)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMr2gDSMgi2x",
        "outputId": "a07fa219-bd95-4622-e9c4-bb26469134cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "source": [
        "toknize_train=all_dataframes_train['text'].tolist()\n",
        "toknize_train=[i.split(' ') for i in toknize_train]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-b06369afb0f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtoknize_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_dataframes_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtoknize_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoknize_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'all_dataframes_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XgK9Bi4gju6",
        "outputId": "7d9df6ec-4c74-4675-aab2-c8d1dc6f0621",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "source": [
        "modifed_list_labels=all_dataframes_train['title'][:11096].tolist()\n",
        "modifed_list_labels=[[i] for i in modifed_list_labels]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-4ce75dea4437>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodifed_list_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_dataframes_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m11096\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodifed_list_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodifed_list_labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'all_dataframes_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr7s-vOGoKtg"
      },
      "source": [
        "all_dataframes_train['title'][:11096]=modifed_list_labels\n",
        "train_labels_=all_dataframes_train['title'].tolist()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttWV252whBCw"
      },
      "source": [
        "toknize_test=all_dataframes_test['text'].tolist()\n",
        "toknize_test=[i.split(' ') for i in toknize_test]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFKoNncbibH0"
      },
      "source": [
        "modifed_list_labels_test=all_dataframes_test['title'][:7370].tolist()\n",
        "modifed_list_labels_test=[[i] for i in modifed_list_labels_test]\n",
        "all_dataframes_test['title'][:7370]=modifed_list_labels_test\n",
        "test_labels_=all_dataframes_test['title'].tolist()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80S1L3sHRn5M"
      },
      "source": [
        "##Wikipedia Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnZVPcjkR0GU",
        "outputId": "a2e68b42-8cea-42ba-bcb6-c75ce7a384ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize \n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english')) "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN0hBheIhQCn",
        "outputId": "08b63639-90e7-458e-bd12-bcba0bc1e406",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "source": [
        "!wget 'https://www.dropbox.com/s/dkfqa5otfngdl0o/all_dataset_fin%20%281%29.csv?dl=0' -O all_dataset_fin.csv"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-12 06:36:01--  https://www.dropbox.com/s/dkfqa5otfngdl0o/all_dataset_fin%20%281%29.csv?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.1, 2620:100:6016:1::a27d:101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/dkfqa5otfngdl0o/all_dataset_fin%20%281%29.csv [following]\n",
            "--2020-10-12 06:36:01--  https://www.dropbox.com/s/raw/dkfqa5otfngdl0o/all_dataset_fin%20%281%29.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucfdc5165b4661b0a64c7c98628f.dl.dropboxusercontent.com/cd/0/inline/BBFZF5bzt7qvLKba3BEb-oSQGb3BJQ9X6qo39yC8AI3qT5_BIbSJtGC_1KklhOl-tu7UWdtMpvkOwSPgd852vXUIPNu34XhrVR701_y0bhwQXbY_sweZEPBdJgmNhF1ryVc/file# [following]\n",
            "--2020-10-12 06:36:02--  https://ucfdc5165b4661b0a64c7c98628f.dl.dropboxusercontent.com/cd/0/inline/BBFZF5bzt7qvLKba3BEb-oSQGb3BJQ9X6qo39yC8AI3qT5_BIbSJtGC_1KklhOl-tu7UWdtMpvkOwSPgd852vXUIPNu34XhrVR701_y0bhwQXbY_sweZEPBdJgmNhF1ryVc/file\n",
            "Resolving ucfdc5165b4661b0a64c7c98628f.dl.dropboxusercontent.com (ucfdc5165b4661b0a64c7c98628f.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
            "Connecting to ucfdc5165b4661b0a64c7c98628f.dl.dropboxusercontent.com (ucfdc5165b4661b0a64c7c98628f.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7291384 (7.0M) [text/plain]\n",
            "Saving to: ‘all_dataset_fin.csv’\n",
            "\n",
            "all_dataset_fin.csv 100%[===================>]   6.95M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-10-12 06:36:02 (54.9 MB/s) - ‘all_dataset_fin.csv’ saved [7291384/7291384]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUWxpsLLhxd8",
        "outputId": "c1920779-bf0b-471d-d92e-cdc57b799d03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "!wget 'https://storage.googleapis.com/wandb-production.appspot.com/alymostafa/nlp-task/1mk6uv86/files/lstm/embed_model_weights.h5?Expires=1602484706&GoogleAccessId=gorilla-cloud-storage%40wandb-production.iam.gserviceaccount.com&Signature=gFAQhgcGf5ZsSAO3wNA1pkhaFRJ%2B4GrVSDISga8D1DBMBDAR%2B2Bn8A2P1qO9GhigGDwhTYNm1yV%2F9OoNAlwnbZPKvIMfKKE%2Bn0ncw7E2LJvRAuUTFMJxyPTQS8ocPLBrbx8kD7L98opmHZ%2Ft2LQLToQFfC5BgPZuzKgQ8W9H1Y4CjgGlL%2F2%2FYaJHmipcD6dIjsKx6Ig9yNjaC47bA6xZM8UE%2B%2BqmOV4US2ebpD3230zKTBQC9N%2B5nAetismkOFaMhSkbXwUKfPJTqZQvx1Nwauc4XOV0J71MsAl7e%2F%2BXDWQrDzcntN%2F6XZrauZZpzlldMtH1z92ArSlCpg3XWjdxkg%3D%3D' -O embed_model_weights.h5"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-12 06:38:05--  https://storage.googleapis.com/wandb-production.appspot.com/alymostafa/nlp-task/1mk6uv86/files/lstm/embed_model_weights.h5?Expires=1602484706&GoogleAccessId=gorilla-cloud-storage%40wandb-production.iam.gserviceaccount.com&Signature=gFAQhgcGf5ZsSAO3wNA1pkhaFRJ%2B4GrVSDISga8D1DBMBDAR%2B2Bn8A2P1qO9GhigGDwhTYNm1yV%2F9OoNAlwnbZPKvIMfKKE%2Bn0ncw7E2LJvRAuUTFMJxyPTQS8ocPLBrbx8kD7L98opmHZ%2Ft2LQLToQFfC5BgPZuzKgQ8W9H1Y4CjgGlL%2F2%2FYaJHmipcD6dIjsKx6Ig9yNjaC47bA6xZM8UE%2B%2BqmOV4US2ebpD3230zKTBQC9N%2B5nAetismkOFaMhSkbXwUKfPJTqZQvx1Nwauc4XOV0J71MsAl7e%2F%2BXDWQrDzcntN%2F6XZrauZZpzlldMtH1z92ArSlCpg3XWjdxkg%3D%3D\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 74.125.142.128, 74.125.195.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 435886848 (416M) [application/keras]\n",
            "Saving to: ‘embed_model_weights.h5’\n",
            "\n",
            "embed_model_weights 100%[===================>] 415.69M   269MB/s    in 1.5s    \n",
            "\n",
            "2020-10-12 06:38:06 (269 MB/s) - ‘embed_model_weights.h5’ saved [435886848/435886848]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBBmzAbNiEqp",
        "outputId": "140aae11-2c2b-4e1a-ad34-ec54af5d46fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "!wget 'https://storage.googleapis.com/wandb-production.appspot.com/alymostafa/nlp-task/1mk6uv86/files/lstm/model_config.json?Expires=1602484769&GoogleAccessId=gorilla-cloud-storage%40wandb-production.iam.gserviceaccount.com&Signature=qbLjOliKF%2BLx0T%2BRUurlVWwiSdIFmsdYFSJL0YVnCpI9dhT%2Bl1G2mYZcT9RIZJ%2BRoqXruosMCR5IjRd4%2BErMg0C7f%2BT3mTh%2Bggh2SH8%2FA5ZyK%2FJh%2BWRqJPa9pZSc6SF%2BAonsqBeQHsgqG277%2B3GwRyu4cWs%2BkAVLEw9QWWfLcw%2F%2FdRsbHXeQxHZurL%2F39%2BPNYBRdjx6p2SYZk9JhENJn8dobaQ%2FS3UIkpsK%2FNxeoZkd3d6wG%2BzcU7hLzwFI9Ua0tIBI6gakJqwD1HMf3O3sRUL6HaynsYHfd%2FhSW%2FNZJREf77cvSUyJA71zhB%2FD0MTq%2BIRfz3zJ%2F7g5OQxFv0swGQw%3D%3D' -O model_config.json"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-12 06:39:12--  https://storage.googleapis.com/wandb-production.appspot.com/alymostafa/nlp-task/1mk6uv86/files/lstm/model_config.json?Expires=1602484769&GoogleAccessId=gorilla-cloud-storage%40wandb-production.iam.gserviceaccount.com&Signature=qbLjOliKF%2BLx0T%2BRUurlVWwiSdIFmsdYFSJL0YVnCpI9dhT%2Bl1G2mYZcT9RIZJ%2BRoqXruosMCR5IjRd4%2BErMg0C7f%2BT3mTh%2Bggh2SH8%2FA5ZyK%2FJh%2BWRqJPa9pZSc6SF%2BAonsqBeQHsgqG277%2B3GwRyu4cWs%2BkAVLEw9QWWfLcw%2F%2FdRsbHXeQxHZurL%2F39%2BPNYBRdjx6p2SYZk9JhENJn8dobaQ%2FS3UIkpsK%2FNxeoZkd3d6wG%2BzcU7hLzwFI9Ua0tIBI6gakJqwD1HMf3O3sRUL6HaynsYHfd%2FhSW%2FNZJREf77cvSUyJA71zhB%2FD0MTq%2BIRfz3zJ%2F7g5OQxFv0swGQw%3D%3D\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.253.117.128, 74.125.199.128, 74.125.20.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.253.117.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 945225 (923K) [application/json]\n",
            "Saving to: ‘model_config.json’\n",
            "\n",
            "\rmodel_config.json     0%[                    ]       0  --.-KB/s               \rmodel_config.json   100%[===================>] 923.07K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2020-10-12 06:39:12 (147 MB/s) - ‘model_config.json’ saved [945225/945225]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-Zcnqj3iRWz",
        "outputId": "60224c4c-216b-4d93-e10e-d4f31846734a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "!wget 'https://storage.googleapis.com/wandb-production.appspot.com/alymostafa/nlp-task/1mk6uv86/files/lstm/model_weights.h5?Expires=1602484824&GoogleAccessId=gorilla-cloud-storage%40wandb-production.iam.gserviceaccount.com&Signature=B25KSYQ84dQexkR681l16pGwNzh6jSEoUE3LDd7gIiuxQW00elfnbW%2Fb1Tk3W8DhO9KNqLfK7dmvbtdyQ9HPuUF9jOfdY3PxTOdDJxmXVatZey74U5URhog%2BRCrYGeRexrqYkmj2MmoyMo2YCu9EASORkTQTg0gPi%2BOe0W%2FA5TZe3TXgmENhvFGsQDeuAeT50ygiHQmPMc3c58w%2FC%2FtoyHqvMfAdPgLvUbYfcWym940W1VLiV%2BC8GjqYbV04Tdgem86fHY4AfOQsIJ7YyAa6kZ%2Bat1V6%2FNj670Ge2Tp5mG6HhmcHsskzMX9S9y%2BgId9BKwk%2Fbgg982RdF5i6xwFlrQ%3D%3D' -O model_weights.h5"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-12 06:39:49--  https://storage.googleapis.com/wandb-production.appspot.com/alymostafa/nlp-task/1mk6uv86/files/lstm/model_weights.h5?Expires=1602484824&GoogleAccessId=gorilla-cloud-storage%40wandb-production.iam.gserviceaccount.com&Signature=B25KSYQ84dQexkR681l16pGwNzh6jSEoUE3LDd7gIiuxQW00elfnbW%2Fb1Tk3W8DhO9KNqLfK7dmvbtdyQ9HPuUF9jOfdY3PxTOdDJxmXVatZey74U5URhog%2BRCrYGeRexrqYkmj2MmoyMo2YCu9EASORkTQTg0gPi%2BOe0W%2FA5TZe3TXgmENhvFGsQDeuAeT50ygiHQmPMc3c58w%2FC%2FtoyHqvMfAdPgLvUbYfcWym940W1VLiV%2BC8GjqYbV04Tdgem86fHY4AfOQsIJ7YyAa6kZ%2Bat1V6%2FNj670Ge2Tp5mG6HhmcHsskzMX9S9y%2BgId9BKwk%2Fbgg982RdF5i6xwFlrQ%3D%3D\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 74.125.142.128, 74.125.195.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 439580724 (419M) [application/keras]\n",
            "Saving to: ‘model_weights.h5’\n",
            "\n",
            "model_weights.h5    100%[===================>] 419.22M   230MB/s    in 1.8s    \n",
            "\n",
            "2020-10-12 06:39:51 (230 MB/s) - ‘model_weights.h5’ saved [439580724/439580724]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaNw3Js1R56u"
      },
      "source": [
        "df=pd.read_csv(\"/content/all_dataset_fin.csv\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmL08KMb-Dqq",
        "outputId": "d030638a-15b1-479a-8d37-fb196d37fa2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Academic_Science</td>\n",
              "      <td>['an', 'academic', 'degree', 'is', 'a', 'quali...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Academic_Science</td>\n",
              "      <td>['an', 'alumnus', 'masculine', 'plural', 'alum...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Academic_Science</td>\n",
              "      <td>['an', 'example', 'of', 'an', 'amateur', 'radi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Academic_Science</td>\n",
              "      <td>['anthropology', 'is', 'the', 'study', 'of', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Academic_Science</td>\n",
              "      <td>['roman', 'ruins', 'lausanne', 'switzerland', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>158</td>\n",
              "      <td>Medical</td>\n",
              "      <td>['surgeons', 'repairing', 'a', 'ruptured', 'ac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>159</td>\n",
              "      <td>Medical</td>\n",
              "      <td>['a', 'syndrome', 'is', 'a', 'set', 'of', 'med...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>160</td>\n",
              "      <td>Medical</td>\n",
              "      <td>['therapy', 'often', 'abbreviated', 'tx', 'tx'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>161</td>\n",
              "      <td>Medical</td>\n",
              "      <td>['organ', 'transplantation', 'is', 'a', 'medic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162</th>\n",
              "      <td>162</td>\n",
              "      <td>Medical</td>\n",
              "      <td>['a', 'veterinary', 'technician', 'in', 'ethio...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>163 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0  ...                                               text\n",
              "0             0  ...  ['an', 'academic', 'degree', 'is', 'a', 'quali...\n",
              "1             1  ...  ['an', 'alumnus', 'masculine', 'plural', 'alum...\n",
              "2             2  ...  ['an', 'example', 'of', 'an', 'amateur', 'radi...\n",
              "3             3  ...  ['anthropology', 'is', 'the', 'study', 'of', '...\n",
              "4             4  ...  ['roman', 'ruins', 'lausanne', 'switzerland', ...\n",
              "..          ...  ...                                                ...\n",
              "158         158  ...  ['surgeons', 'repairing', 'a', 'ruptured', 'ac...\n",
              "159         159  ...  ['a', 'syndrome', 'is', 'a', 'set', 'of', 'med...\n",
              "160         160  ...  ['therapy', 'often', 'abbreviated', 'tx', 'tx'...\n",
              "161         161  ...  ['organ', 'transplantation', 'is', 'a', 'medic...\n",
              "162         162  ...  ['a', 'veterinary', 'technician', 'in', 'ethio...\n",
              "\n",
              "[163 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMScuvFzPuHu",
        "outputId": "b4b7a495-5e05-43a0-b001-9ed9ba18d29b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        }
      },
      "source": [
        "df[df['title']=='Miscellaneous']"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>116</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['the', 'miscellaneous', 'was', 'a', 's', 'alt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>117</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['nasa', 'test', 'aircraft', 'the', 'mil', 'mi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>118</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['aviation', 'is', 'the', 'practical', 'aspect...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>119</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['animals', 'are', 'multicellular', 'eukaryoti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>120</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['some', 'of', 'the', 'trophies', 'earned', 'b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>121</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['obverse', 'of', 'medal', 'distributed', 'by'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>122</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['farmland', 'in', 'the', 'united', 'states', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>123</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['fields', 'in', 'z', 'horie', 'slovakia', 'a'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>124</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['various', 'foods', 'foods', 'from', 'plant',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>125</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['the', 'nutrition', 'facts', 'table', 'displa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>126</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['foundation', 'may', 'refer', 'to', 'literatu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>127</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['__notoc__', 'a', 'journal', 'through', 'fren...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>128</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['photography', 'is', 'the', 'science', 'art',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>129</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['imaging', 'is', 'the', 'representation', 'or...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>130</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['artwork', 'by', 'david', 'revoy', 'for', 'th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>131</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['a', 'shipping', 'line', 'is', 'a', 'business...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>132</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>['sailing', 'employs', 'the', 'wind', 'acting'...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0  ...                                               text\n",
              "116         116  ...  ['the', 'miscellaneous', 'was', 'a', 's', 'alt...\n",
              "117         117  ...  ['nasa', 'test', 'aircraft', 'the', 'mil', 'mi...\n",
              "118         118  ...  ['aviation', 'is', 'the', 'practical', 'aspect...\n",
              "119         119  ...  ['animals', 'are', 'multicellular', 'eukaryoti...\n",
              "120         120  ...  ['some', 'of', 'the', 'trophies', 'earned', 'b...\n",
              "121         121  ...  ['obverse', 'of', 'medal', 'distributed', 'by'...\n",
              "122         122  ...  ['farmland', 'in', 'the', 'united', 'states', ...\n",
              "123         123  ...  ['fields', 'in', 'z', 'horie', 'slovakia', 'a'...\n",
              "124         124  ...  ['various', 'foods', 'foods', 'from', 'plant',...\n",
              "125         125  ...  ['the', 'nutrition', 'facts', 'table', 'displa...\n",
              "126         126  ...  ['foundation', 'may', 'refer', 'to', 'literatu...\n",
              "127         127  ...  ['__notoc__', 'a', 'journal', 'through', 'fren...\n",
              "128         128  ...  ['photography', 'is', 'the', 'science', 'art',...\n",
              "129         129  ...  ['imaging', 'is', 'the', 'representation', 'or...\n",
              "130         130  ...  ['artwork', 'by', 'david', 'revoy', 'for', 'th...\n",
              "131         131  ...  ['a', 'shipping', 'line', 'is', 'a', 'business...\n",
              "132         132  ...  ['sailing', 'employs', 'the', 'wind', 'acting'...\n",
              "\n",
              "[17 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw3fehuj82SI",
        "outputId": "13d98601-f290-442a-dca5-5011aada44ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "df['title'].unique()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Academic_Science', 'Business', 'Community', 'Computing',\n",
              "       'Governmental', 'Miscellaneous', 'Medical'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwN88yEHyVzX"
      },
      "source": [
        "Academic_Science = df[df['title']=='Academic_Science']\n",
        "Business = df[df['title']=='Business']\n",
        "Community = df[df['title']=='Community']\n",
        "Computing = df[df['title']=='Computing']\n",
        "Governmental = df[df['title']=='Governmental']\n",
        "Miscellaneous = df[df['title']=='Miscellaneous']\n",
        "Medical = df[df['title']=='Medical']"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CQXJXcP5uLv"
      },
      "source": [
        "list_Academic_Science = list(Academic_Science['text'])\n",
        "list_Business = list(Business['text'])\n",
        "list_Community = list(Community['text'])\n",
        "list_Computing = list(Computing['text'])\n",
        "list_Governmental = list(Governmental['text'])\n",
        "list_Miscellaneous = list(Miscellaneous['text'])\n",
        "list_Medical = list(Medical['text'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ-fgw_U5uI0"
      },
      "source": [
        "import ast\n",
        "list_Academic_Science=[ast.literal_eval(i) for i in list_Academic_Science]\n",
        "list_Business=[ast.literal_eval(i) for i in list_Business]\n",
        "list_Community=[ast.literal_eval(i) for i in list_Community]\n",
        "list_Computing=[ast.literal_eval(i) for i in list_Computing]\n",
        "list_Governmental=[ast.literal_eval(i) for i in list_Governmental]\n",
        "list_Miscellaneous=[ast.literal_eval(i) for i in list_Miscellaneous]\n",
        "list_Medical=[ast.literal_eval(i) for i in list_Medical]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41knx3Is5uFa"
      },
      "source": [
        "seq = 150\n",
        "count = 0\n",
        "list_list_Aca=[]\n",
        "list_Aca= [] \n",
        "for w in list_Academic_Science:\n",
        "  for j in w:\n",
        "    list_Aca.append(j)\n",
        "    count = count + 1\n",
        "    if count == seq:\n",
        "      list_list_Aca.append(list_Aca)\n",
        "      count = 0\n",
        "      list_Aca = []\n",
        "\n",
        "\n",
        "count = 0\n",
        "list_list_bus=[]\n",
        "list_bus= [] \n",
        "for w in list_Business:\n",
        "  for j in w:\n",
        "    list_bus.append(j)\n",
        "    count = count + 1\n",
        "    if count == seq:\n",
        "      list_list_bus.append(list_bus)\n",
        "      count = 0\n",
        "      list_bus = []\n",
        "\n",
        "\n",
        "count = 0\n",
        "list_list_comm=[]\n",
        "list_comm= [] \n",
        "for w in list_Community:\n",
        "  for j in w:\n",
        "    list_comm.append(j)\n",
        "    count = count + 1\n",
        "    if count == seq:\n",
        "      list_list_comm.append(list_comm)\n",
        "      count = 0\n",
        "      list_comm = []\n",
        "\n",
        "\n",
        "count = 0\n",
        "list_list_comp=[]\n",
        "list_comp= [] \n",
        "for w in list_Computing:\n",
        "  for j in w:\n",
        "    list_comp.append(j)\n",
        "    count = count + 1\n",
        "    if count == seq:\n",
        "      list_list_comp.append(list_comp)\n",
        "      count = 0\n",
        "      list_comp = []\n",
        "\n",
        "count = 0\n",
        "list_list_cov=[]\n",
        "list_cov= [] \n",
        "for w in list_Governmental:\n",
        "  for j in w:\n",
        "    list_cov.append(j)\n",
        "    count = count + 1\n",
        "    if count == seq:\n",
        "      list_list_cov.append(list_cov)\n",
        "      count = 0\n",
        "      list_cov = []\n",
        "\n",
        "\n",
        "count = 0\n",
        "list_list_mis=[]\n",
        "list_mis= [] \n",
        "for w in list_Miscellaneous:\n",
        "  for j in w:\n",
        "    list_mis.append(j)\n",
        "    count = count + 1\n",
        "    if count == seq:\n",
        "      list_list_mis.append(list_mis)\n",
        "      count = 0\n",
        "      list_mis = []\n",
        "\n",
        "\n",
        "count = 0\n",
        "list_list_med=[]\n",
        "list_med= [] \n",
        "for w in list_Medical:\n",
        "  for j in w:\n",
        "    list_med.append(j)\n",
        "    count = count + 1\n",
        "    if count == seq:\n",
        "      list_list_med.append(list_med)\n",
        "      count = 0\n",
        "      list_med = []\n",
        "\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hseEpXet80o8"
      },
      "source": [
        "df_aca = pd.DataFrame()\n",
        "df_aca['text'] = list_list_Aca\n",
        "df_aca['title'] = \"acadamic_science\"\n",
        "\n",
        "df_bus = pd.DataFrame()\n",
        "df_bus['text'] = list_list_bus\n",
        "df_bus['title'] = \"Business\"\n",
        "\n",
        "df_comm = pd.DataFrame()\n",
        "df_comm['text'] = list_list_comm\n",
        "df_comm['title'] = \"community\"\n",
        "\n",
        "df_comp = pd.DataFrame()\n",
        "df_comp['text'] = list_list_comp\n",
        "df_comp['title'] = \"computing\"\n",
        "\n",
        "df_gov = pd.DataFrame()\n",
        "df_gov['text'] = list_list_cov\n",
        "df_gov['title'] = \"govermnetal\"\n",
        "\n",
        "df_mis = pd.DataFrame()\n",
        "df_mis['text'] = list_Miscellaneous\n",
        "df_mis['title'] = \"Miscellaneous\"\n",
        "\n",
        "df_med = pd.DataFrame()\n",
        "df_med['text'] = list_list_med\n",
        "df_med['title'] = \"medical\""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ml-bOJYb80iV"
      },
      "source": [
        "df_all_cat = pd.concat([df_aca,df_bus,df_comm,df_comp,df_gov,df_mis,df_med],ignore_index = True)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdrAyz3Gu1v_"
      },
      "source": [
        "df_all_cat['text'] = df_all_cat['text'].apply(lambda x: [item for item in x if item not in stop_words])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uU8h37m2u9KH",
        "outputId": "ef98f198-276f-4193-ec2b-b5e7382d89cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "df_all_cat"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[academic, degree, qualification, awarded, stu...</td>\n",
              "      <td>acadamic_science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[master, degree, doctorate, adopted, diverse, ...</td>\n",
              "      <td>acadamic_science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[ecclesiastic, scholastic, right, remained, bo...</td>\n",
              "      <td>acadamic_science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[master, doctor, latin, meaning, literally, te...</td>\n",
              "      <td>acadamic_science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[due, renaissance, conviction, real, knowledge...</td>\n",
              "      <td>acadamic_science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4699</th>\n",
              "      <td>[society, meeting, resolved, promote, study, f...</td>\n",
              "      <td>medical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4700</th>\n",
              "      <td>[early, th, century, boston, new, york, philad...</td>\n",
              "      <td>medical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4701</th>\n",
              "      <td>[designated, exceptions, paraveterinary, worke...</td>\n",
              "      <td>medical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4702</th>\n",
              "      <td>[way, prior, kittens, adoption, paraveterinary...</td>\n",
              "      <td>medical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4703</th>\n",
              "      <td>[farriers, involved, shoeing, horses, many, ca...</td>\n",
              "      <td>medical</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4704 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text             title\n",
              "0     [academic, degree, qualification, awarded, stu...  acadamic_science\n",
              "1     [master, degree, doctorate, adopted, diverse, ...  acadamic_science\n",
              "2     [ecclesiastic, scholastic, right, remained, bo...  acadamic_science\n",
              "3     [master, doctor, latin, meaning, literally, te...  acadamic_science\n",
              "4     [due, renaissance, conviction, real, knowledge...  acadamic_science\n",
              "...                                                 ...               ...\n",
              "4699  [society, meeting, resolved, promote, study, f...           medical\n",
              "4700  [early, th, century, boston, new, york, philad...           medical\n",
              "4701  [designated, exceptions, paraveterinary, worke...           medical\n",
              "4702  [way, prior, kittens, adoption, paraveterinary...           medical\n",
              "4703  [farriers, involved, shoeing, horses, many, ca...           medical\n",
              "\n",
              "[4704 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_olCcLFG8p3",
        "outputId": "bf3ea321-8eb7-40bf-92ac-64f72dcff5c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "df_all_cat[df_all_cat['title']=='acadamic_science']"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[academic, degree, qualification, awarded, stu...</td>\n",
              "      <td>acadamic_science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[master, degree, doctorate, adopted, diverse, ...</td>\n",
              "      <td>acadamic_science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[ecclesiastic, scholastic, right, remained, bo...</td>\n",
              "      <td>acadamic_science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[master, doctor, latin, meaning, literally, te...</td>\n",
              "      <td>acadamic_science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[due, renaissance, conviction, real, knowledge...</td>\n",
              "      <td>acadamic_science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1533</th>\n",
              "      <td>[biology, entered, evolutionary, biology, init...</td>\n",
              "      <td>acadamic_science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1534</th>\n",
              "      <td>[system, outdated, modern, alternative, classi...</td>\n",
              "      <td>acadamic_science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1535</th>\n",
              "      <td>[classification, system, called, linnaean, tax...</td>\n",
              "      <td>acadamic_science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1536</th>\n",
              "      <td>[earth, focusing, topics, like, plate, tectoni...</td>\n",
              "      <td>acadamic_science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1537</th>\n",
              "      <td>[practical, classes, contrast, previous, forma...</td>\n",
              "      <td>acadamic_science</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1538 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text             title\n",
              "0     [academic, degree, qualification, awarded, stu...  acadamic_science\n",
              "1     [master, degree, doctorate, adopted, diverse, ...  acadamic_science\n",
              "2     [ecclesiastic, scholastic, right, remained, bo...  acadamic_science\n",
              "3     [master, doctor, latin, meaning, literally, te...  acadamic_science\n",
              "4     [due, renaissance, conviction, real, knowledge...  acadamic_science\n",
              "...                                                 ...               ...\n",
              "1533  [biology, entered, evolutionary, biology, init...  acadamic_science\n",
              "1534  [system, outdated, modern, alternative, classi...  acadamic_science\n",
              "1535  [classification, system, called, linnaean, tax...  acadamic_science\n",
              "1536  [earth, focusing, topics, like, plate, tectoni...  acadamic_science\n",
              "1537  [practical, classes, contrast, previous, forma...  acadamic_science\n",
              "\n",
              "[1538 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Xd5mQBnyrTZ"
      },
      "source": [
        "msk = np.random.rand(len(df_all_cat)) < 0.8\n",
        "train_df = df_all_cat[msk]\n",
        "test_val_df = df_all_cat[~msk]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oH6aNx04yrQ6"
      },
      "source": [
        "msk = np.random.rand(len(test_val_df)) < 0.5\n",
        "test_df = test_val_df[msk]\n",
        "validate_df = test_val_df[~msk]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joclRMGcOt7b",
        "outputId": "4e52ad84-a75f-4937-9371-16977e2632ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "validate_df[validate_df['title']=='Miscellaneous']"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3841</th>\n",
              "      <td>[foundation, may, refer, literature, foundatio...</td>\n",
              "      <td>Miscellaneous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3846</th>\n",
              "      <td>[shipping, line, business, transports, cargo, ...</td>\n",
              "      <td>Miscellaneous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3847</th>\n",
              "      <td>[sailing, employs, wind, acting, sails, wingsa...</td>\n",
              "      <td>Miscellaneous</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text          title\n",
              "3841  [foundation, may, refer, literature, foundatio...  Miscellaneous\n",
              "3846  [shipping, line, business, transports, cargo, ...  Miscellaneous\n",
              "3847  [sailing, employs, wind, acting, sails, wingsa...  Miscellaneous"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4TFEsh5yrL8",
        "outputId": "84288665-101b-4122-e64f-272e0364d1ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print(f'train data count: {len(train_df)}')\n",
        "print(f'test data count: {len(test_df)}')\n",
        "print(f'validate data count: {len(validate_df)}')\n",
        "train_x, train_y = list(train_df['text']), list(train_df['title'])\n",
        "test_x, test_y = list(test_df['text']), list(test_df['title'])\n",
        "validate_x, validate_y = list(validate_df['text']), list(validate_df['title'])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train data count: 3739\n",
            "test data count: 475\n",
            "validate data count: 490\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tAdofSUzXOl",
        "outputId": "7529b001-ca3d-4093-f3b1-1dfb2c49803a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(train_x,train_y,validate_x,validate_y,epochs=20, callbacks=[WandbCallback()])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing text vocab dict: 100%|██████████| 2838/2838 [00:00<00:00, 32454.41it/s]\n",
            "Preparing text vocab dict: 100%|██████████| 331/331 [00:00<00:00, 22953.80it/s]\n",
            "2020-10-12 04:21:14,307 [DEBUG] kashgari - --- Build vocab dict finished, Total: 14327 ---\n",
            "2020-10-12 04:21:14,309 [DEBUG] kashgari - Top-10: ['[PAD]', '[UNK]', '[CLS]', '[SEP]', 'also', 'may', 'used', 'one', 'many', 'first']\n",
            "Preparing classification label vocab dict: 100%|██████████| 2838/2838 [00:00<00:00, 711289.80it/s]\n",
            "Preparing classification label vocab dict: 100%|██████████| 331/331 [00:00<00:00, 370513.64it/s]\n",
            "Calculating sequence length: 100%|██████████| 2838/2838 [00:00<00:00, 1002985.74it/s]\n",
            "Calculating sequence length: 100%|██████████| 331/331 [00:00<00:00, 512671.57it/s]\n",
            "2020-10-12 04:21:30,982 [DEBUG] kashgari - Calculated sequence length = 142\n",
            "2020-10-12 04:21:32,523 [DEBUG] kashgari - Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Input-Token (InputLayer)        [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Input-Segment (InputLayer)      [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token (Embedding)     (None, None, 768)    23440896    Input-Token[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Segment (Embedding)   (None, None, 768)    1536        Input-Segment[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token-Segment (Add)   (None, None, 768)    0           Embedding-Token[0][0]            \n",
            "                                                                 Embedding-Segment[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Position (PositionEmb (None, None, 768)    393216      Embedding-Token-Segment[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Norm (LayerNormalizat (None, None, 768)    1536        Embedding-Position[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Dropout (Dropout)     (None, None, 768)    0           Embedding-Norm[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-0-MultiHeadSelfAtte (None, None, 768)    2362368     Embedding-Dropout[0][0]          \n",
            "                                                                 Embedding-Dropout[0][0]          \n",
            "                                                                 Embedding-Dropout[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Embedding-Dropout[0][0]          \n",
            "                                                                 Transformer-0-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-0-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-0-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-0-FeedForward (Feed (None, None, 768)    4722432     Transformer-0-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-0-FeedForward-Dropo (None, None, 768)    0           Transformer-0-FeedForward[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-0-FeedForward-Add ( (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent\n",
            "                                                                 Transformer-0-FeedForward-Dropout\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-0-FeedForward-Norm  (None, None, 768)    1536        Transformer-0-FeedForward-Add[0][\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-1-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-0-FeedForward-Norm[0]\n",
            "                                                                 Transformer-0-FeedForward-Norm[0]\n",
            "                                                                 Transformer-0-FeedForward-Norm[0]\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-FeedForward-Norm[0]\n",
            "                                                                 Transformer-1-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-1-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-1-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-1-FeedForward (Feed (None, None, 768)    4722432     Transformer-1-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-1-FeedForward-Dropo (None, None, 768)    0           Transformer-1-FeedForward[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-1-FeedForward-Add ( (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent\n",
            "                                                                 Transformer-1-FeedForward-Dropout\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-1-FeedForward-Norm  (None, None, 768)    1536        Transformer-1-FeedForward-Add[0][\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-2-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-1-FeedForward-Norm[0]\n",
            "                                                                 Transformer-1-FeedForward-Norm[0]\n",
            "                                                                 Transformer-1-FeedForward-Norm[0]\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-FeedForward-Norm[0]\n",
            "                                                                 Transformer-2-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-2-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-2-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-2-FeedForward (Feed (None, None, 768)    4722432     Transformer-2-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-2-FeedForward-Dropo (None, None, 768)    0           Transformer-2-FeedForward[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-2-FeedForward-Add ( (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent\n",
            "                                                                 Transformer-2-FeedForward-Dropout\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-2-FeedForward-Norm  (None, None, 768)    1536        Transformer-2-FeedForward-Add[0][\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-3-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-2-FeedForward-Norm[0]\n",
            "                                                                 Transformer-2-FeedForward-Norm[0]\n",
            "                                                                 Transformer-2-FeedForward-Norm[0]\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-FeedForward-Norm[0]\n",
            "                                                                 Transformer-3-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-3-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-3-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-3-FeedForward (Feed (None, None, 768)    4722432     Transformer-3-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-3-FeedForward-Dropo (None, None, 768)    0           Transformer-3-FeedForward[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-3-FeedForward-Add ( (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent\n",
            "                                                                 Transformer-3-FeedForward-Dropout\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-3-FeedForward-Norm  (None, None, 768)    1536        Transformer-3-FeedForward-Add[0][\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-4-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-3-FeedForward-Norm[0]\n",
            "                                                                 Transformer-3-FeedForward-Norm[0]\n",
            "                                                                 Transformer-3-FeedForward-Norm[0]\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-4-MultiHeadSelfAtte (None, None, 768)    0           Transformer-4-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-4-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-FeedForward-Norm[0]\n",
            "                                                                 Transformer-4-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-4-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-4-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-4-FeedForward (Feed (None, None, 768)    4722432     Transformer-4-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-4-FeedForward-Dropo (None, None, 768)    0           Transformer-4-FeedForward[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-4-FeedForward-Add ( (None, None, 768)    0           Transformer-4-MultiHeadSelfAttent\n",
            "                                                                 Transformer-4-FeedForward-Dropout\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-4-FeedForward-Norm  (None, None, 768)    1536        Transformer-4-FeedForward-Add[0][\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-5-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-4-FeedForward-Norm[0]\n",
            "                                                                 Transformer-4-FeedForward-Norm[0]\n",
            "                                                                 Transformer-4-FeedForward-Norm[0]\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-5-MultiHeadSelfAtte (None, None, 768)    0           Transformer-5-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-5-MultiHeadSelfAtte (None, None, 768)    0           Transformer-4-FeedForward-Norm[0]\n",
            "                                                                 Transformer-5-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-5-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-5-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-5-FeedForward (Feed (None, None, 768)    4722432     Transformer-5-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-5-FeedForward-Dropo (None, None, 768)    0           Transformer-5-FeedForward[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-5-FeedForward-Add ( (None, None, 768)    0           Transformer-5-MultiHeadSelfAttent\n",
            "                                                                 Transformer-5-FeedForward-Dropout\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-5-FeedForward-Norm  (None, None, 768)    1536        Transformer-5-FeedForward-Add[0][\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-6-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-5-FeedForward-Norm[0]\n",
            "                                                                 Transformer-5-FeedForward-Norm[0]\n",
            "                                                                 Transformer-5-FeedForward-Norm[0]\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-6-MultiHeadSelfAtte (None, None, 768)    0           Transformer-6-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-6-MultiHeadSelfAtte (None, None, 768)    0           Transformer-5-FeedForward-Norm[0]\n",
            "                                                                 Transformer-6-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-6-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-6-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-6-FeedForward (Feed (None, None, 768)    4722432     Transformer-6-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-6-FeedForward-Dropo (None, None, 768)    0           Transformer-6-FeedForward[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-6-FeedForward-Add ( (None, None, 768)    0           Transformer-6-MultiHeadSelfAttent\n",
            "                                                                 Transformer-6-FeedForward-Dropout\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-6-FeedForward-Norm  (None, None, 768)    1536        Transformer-6-FeedForward-Add[0][\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-7-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-6-FeedForward-Norm[0]\n",
            "                                                                 Transformer-6-FeedForward-Norm[0]\n",
            "                                                                 Transformer-6-FeedForward-Norm[0]\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-7-MultiHeadSelfAtte (None, None, 768)    0           Transformer-7-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-7-MultiHeadSelfAtte (None, None, 768)    0           Transformer-6-FeedForward-Norm[0]\n",
            "                                                                 Transformer-7-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-7-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-7-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-7-FeedForward (Feed (None, None, 768)    4722432     Transformer-7-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-7-FeedForward-Dropo (None, None, 768)    0           Transformer-7-FeedForward[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-7-FeedForward-Add ( (None, None, 768)    0           Transformer-7-MultiHeadSelfAttent\n",
            "                                                                 Transformer-7-FeedForward-Dropout\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-7-FeedForward-Norm  (None, None, 768)    1536        Transformer-7-FeedForward-Add[0][\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-8-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-7-FeedForward-Norm[0]\n",
            "                                                                 Transformer-7-FeedForward-Norm[0]\n",
            "                                                                 Transformer-7-FeedForward-Norm[0]\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-8-MultiHeadSelfAtte (None, None, 768)    0           Transformer-8-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-8-MultiHeadSelfAtte (None, None, 768)    0           Transformer-7-FeedForward-Norm[0]\n",
            "                                                                 Transformer-8-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-8-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-8-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-8-FeedForward (Feed (None, None, 768)    4722432     Transformer-8-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-8-FeedForward-Dropo (None, None, 768)    0           Transformer-8-FeedForward[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-8-FeedForward-Add ( (None, None, 768)    0           Transformer-8-MultiHeadSelfAttent\n",
            "                                                                 Transformer-8-FeedForward-Dropout\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-8-FeedForward-Norm  (None, None, 768)    1536        Transformer-8-FeedForward-Add[0][\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-9-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-8-FeedForward-Norm[0]\n",
            "                                                                 Transformer-8-FeedForward-Norm[0]\n",
            "                                                                 Transformer-8-FeedForward-Norm[0]\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-9-MultiHeadSelfAtte (None, None, 768)    0           Transformer-9-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-9-MultiHeadSelfAtte (None, None, 768)    0           Transformer-8-FeedForward-Norm[0]\n",
            "                                                                 Transformer-9-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-9-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-9-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-9-FeedForward (Feed (None, None, 768)    4722432     Transformer-9-MultiHeadSelfAttent\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-9-FeedForward-Dropo (None, None, 768)    0           Transformer-9-FeedForward[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-9-FeedForward-Add ( (None, None, 768)    0           Transformer-9-MultiHeadSelfAttent\n",
            "                                                                 Transformer-9-FeedForward-Dropout\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-9-FeedForward-Norm  (None, None, 768)    1536        Transformer-9-FeedForward-Add[0][\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-10-MultiHeadSelfAtt (None, None, 768)    2362368     Transformer-9-FeedForward-Norm[0]\n",
            "                                                                 Transformer-9-FeedForward-Norm[0]\n",
            "                                                                 Transformer-9-FeedForward-Norm[0]\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-10-MultiHeadSelfAtt (None, None, 768)    0           Transformer-10-MultiHeadSelfAtten\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-10-MultiHeadSelfAtt (None, None, 768)    0           Transformer-9-FeedForward-Norm[0]\n",
            "                                                                 Transformer-10-MultiHeadSelfAtten\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-10-MultiHeadSelfAtt (None, None, 768)    1536        Transformer-10-MultiHeadSelfAtten\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-10-FeedForward (Fee (None, None, 768)    4722432     Transformer-10-MultiHeadSelfAtten\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-10-FeedForward-Drop (None, None, 768)    0           Transformer-10-FeedForward[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-10-FeedForward-Add  (None, None, 768)    0           Transformer-10-MultiHeadSelfAtten\n",
            "                                                                 Transformer-10-FeedForward-Dropou\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-10-FeedForward-Norm (None, None, 768)    1536        Transformer-10-FeedForward-Add[0]\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-11-MultiHeadSelfAtt (None, None, 768)    2362368     Transformer-10-FeedForward-Norm[0\n",
            "                                                                 Transformer-10-FeedForward-Norm[0\n",
            "                                                                 Transformer-10-FeedForward-Norm[0\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-11-MultiHeadSelfAtt (None, None, 768)    0           Transformer-11-MultiHeadSelfAtten\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-11-MultiHeadSelfAtt (None, None, 768)    0           Transformer-10-FeedForward-Norm[0\n",
            "                                                                 Transformer-11-MultiHeadSelfAtten\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-11-MultiHeadSelfAtt (None, None, 768)    1536        Transformer-11-MultiHeadSelfAtten\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-11-FeedForward (Fee (None, None, 768)    4722432     Transformer-11-MultiHeadSelfAtten\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-11-FeedForward-Drop (None, None, 768)    0           Transformer-11-FeedForward[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Transformer-11-FeedForward-Add  (None, None, 768)    0           Transformer-11-MultiHeadSelfAtten\n",
            "                                                                 Transformer-11-FeedForward-Dropou\n",
            "__________________________________________________________________________________________________\n",
            "Transformer-11-FeedForward-Norm (None, None, 768)    1536        Transformer-11-FeedForward-Add[0]\n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 256)          918528      Transformer-11-FeedForward-Norm[0\n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 7)            1799        bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 7)            0           dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 109,811,975\n",
            "Trainable params: 920,327\n",
            "Non-trainable params: 108,891,648\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "44/44 [==============================] - 39s 884ms/step - loss: 1.0623 - accuracy: 0.6236 - val_loss: 0.6440 - val_accuracy: 0.7500\n",
            "Epoch 2/20\n",
            "44/44 [==============================] - 38s 858ms/step - loss: 0.4433 - accuracy: 0.8505 - val_loss: 0.4266 - val_accuracy: 0.8281\n",
            "Epoch 3/20\n",
            "44/44 [==============================] - 39s 887ms/step - loss: 0.3824 - accuracy: 0.8654 - val_loss: 0.3168 - val_accuracy: 0.8781\n",
            "Epoch 4/20\n",
            "44/44 [==============================] - 52s 1s/step - loss: 0.2520 - accuracy: 0.9116 - val_loss: 0.3127 - val_accuracy: 0.8719\n",
            "Epoch 5/20\n",
            "44/44 [==============================] - 56s 1s/step - loss: 0.2383 - accuracy: 0.9165 - val_loss: 0.2914 - val_accuracy: 0.8625\n",
            "Epoch 6/20\n",
            "44/44 [==============================] - 59s 1s/step - loss: 0.1786 - accuracy: 0.9386 - val_loss: 0.2883 - val_accuracy: 0.8844\n",
            "Epoch 7/20\n",
            "44/44 [==============================] - 36s 828ms/step - loss: 0.1302 - accuracy: 0.9574 - val_loss: 0.3377 - val_accuracy: 0.8719\n",
            "Epoch 8/20\n",
            "44/44 [==============================] - 60s 1s/step - loss: 0.1271 - accuracy: 0.9538 - val_loss: 0.2870 - val_accuracy: 0.8875\n",
            "Epoch 9/20\n",
            "44/44 [==============================] - 54s 1s/step - loss: 0.0854 - accuracy: 0.9702 - val_loss: 0.2734 - val_accuracy: 0.8906\n",
            "Epoch 10/20\n",
            "44/44 [==============================] - 37s 830ms/step - loss: 0.0746 - accuracy: 0.9769 - val_loss: 0.2823 - val_accuracy: 0.9062\n",
            "Epoch 11/20\n",
            "14/44 [========>.....................] - ETA: 21s - loss: 0.0579 - accuracy: 0.9810"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-42b0e67359c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidate_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidate_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mWandbCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kashgari/tasks/classification/abc_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x_train, y_train, x_validate, y_validate, batch_size, epochs, callbacks, fit_kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m                                   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                                   \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m                                   fit_kwargs=fit_kwargs)\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     def fit_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kashgari/tasks/classification/abc_model.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, train_sample_gen, valid_sample_gen, batch_size, epochs, callbacks, fit_kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m                                  \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m                                  \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m                                  **fit_kwargs)\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     def predict(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/wandb/integration/keras/keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZK2J09Nidtd",
        "outputId": "e5dfcb6f-3ebf-48af-84fe-e13eeca7d898",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "loaded_model = model.load_model('/content/lstm')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-12 06:40:39,183 [DEBUG] kashgari - ------------------------------------------------\n",
            "2020-10-12 06:40:39,185 [DEBUG] kashgari - Loaded transformer model's vocab\n",
            "2020-10-12 06:40:39,186 [DEBUG] kashgari - config_path       : /content/uncased_L-12_H-768_A-12/bert_config.json\n",
            "2020-10-12 06:40:39,186 [DEBUG] kashgari - vocab_path      : /content/uncased_L-12_H-768_A-12/vocab.txt\n",
            "2020-10-12 06:40:39,187 [DEBUG] kashgari - checkpoint_path : /content/uncased_L-12_H-768_A-12/bert_model.ckpt\n",
            "2020-10-12 06:40:39,188 [DEBUG] kashgari - Top 50 words    : ['[PAD]', '[unused0]', '[unused1]', '[unused2]', '[unused3]', '[unused4]', '[unused5]', '[unused6]', '[unused7]', '[unused8]', '[unused9]', '[unused10]', '[unused11]', '[unused12]', '[unused13]', '[unused14]', '[unused15]', '[unused16]', '[unused17]', '[unused18]', '[unused19]', '[unused20]', '[unused21]', '[unused22]', '[unused23]', '[unused24]', '[unused25]', '[unused26]', '[unused27]', '[unused28]', '[unused29]', '[unused30]', '[unused31]', '[unused32]', '[unused33]', '[unused34]', '[unused35]', '[unused36]', '[unused37]', '[unused38]', '[unused39]', '[unused40]', '[unused41]', '[unused42]', '[unused43]', '[unused44]', '[unused45]', '[unused46]', '[unused47]', '[unused48]']\n",
            "2020-10-12 06:40:39,188 [DEBUG] kashgari - ------------------------------------------------\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"class_name\": \"Functional\", \"config\": {\"name\": \"functional_3\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, null], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"Input-Token\"}, \"name\": \"Input-Token\", \"inbound_nodes\": []}, {\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, null], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"Input-Segment\"}, \"name\": \"Input-Segment\", \"inbound_nodes\": []}, {\"class_name\": \"Embedding\", \"config\": {\"name\": \"Embedding-Token\", \"trainable\": false, \"batch_input_shape\": [null, null], \"dtype\": \"float32\", \"input_dim\": 30522, \"output_dim\": 768, \"embeddings_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}, \"embeddings_regularizer\": null, \"activity_regularizer\": null, \"embeddings_constraint\": null, \"mask_zero\": true, \"input_length\": null}, \"name\": \"Embedding-Token\", \"inbound_nodes\": [[[\"Input-Token\", 0, 0, {}]]]}, {\"class_name\": \"Embedding\", \"config\": {\"name\": \"Embedding-Segment\", \"trainable\": false, \"batch_input_shape\": [null, null], \"dtype\": \"float32\", \"input_dim\": 2, \"output_dim\": 768, \"embeddings_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}, \"embeddings_regularizer\": null, \"activity_regularizer\": null, \"embeddings_constraint\": null, \"mask_zero\": false, \"input_length\": null}, \"name\": \"Embedding-Segment\", \"inbound_nodes\": [[[\"Input-Segment\", 0, 0, {}]]]}, {\"class_name\": \"Add\", \"config\": {\"name\": \"Embedding-Token-Segment\", \"trainable\": false, \"dtype\": \"float32\"}, \"name\": \"Embedding-Token-Segment\", \"inbound_nodes\": [[[\"Embedding-Token\", 0, 0, {}], [\"Embedding-Segment\", 0, 0, {}]]]}, {\"class_name\": \"PositionEmbedding\", \"config\": {\"name\": \"Embedding-Position\", \"trainable\": false, \"dtype\": \"float32\", \"input_dim\": 512, \"output_dim\": 768, \"merge_mode\": \"add\", \"embeddings_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}, \"custom_position_ids\": false}, \"name\": \"Embedding-Position\", \"inbound_nodes\": [[[\"Embedding-Token-Segment\", 0, 0, {}]]]}, {\"class_name\": \"LayerNormalization\", \"config\": {\"name\": \"Embedding-Norm\", \"trainable\": false, \"dtype\": \"float32\", \"center\": true, \"scale\": true, \"epsilon\": 1e-12, \"conditional\": false, \"hidden_units\": null, \"hidden_activation\": \"linear\", \"hidden_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Embedding-Norm\", \"inbound_nodes\": [[[\"Embedding-Position\", 0, 0, {}]]]}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"Embedding-Dropout\", \"trainable\": false, \"dtype\": \"float32\", \"rate\": 0.1, \"noise_shape\": null, \"seed\": null}, \"name\": \"Embedding-Dropout\", \"inbound_nodes\": [[[\"Embedding-Norm\", 0, 0, {}]]]}, {\"class_name\": \"MultiHeadAttention\", \"config\": {\"name\": \"Transformer-0-MultiHeadSelfAttention\", \"trainable\": false, \"dtype\": \"float32\", \"heads\": 12, \"head_size\": 64, \"key_size\": 64, \"use_bias\": true, \"attention_scale\": true, \"kernel_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-0-MultiHeadSelfAttention\", \"inbound_nodes\": [[[\"Embedding-Dropout\", 0, 0, {\"a_mask\": null}], [\"Embedding-Dropout\", 0, 0, {\"a_mask\": null}], [\"Embedding-Dropout\", 0, 0, {\"a_mask\": null}]]]}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"Transformer-0-MultiHeadSelfAttention-Dropout\", \"trainable\": false, \"dtype\": \"float32\", \"rate\": 0.1, \"noise_shape\": null, \"seed\": null}, \"name\": \"Transformer-0-MultiHeadSelfAttention-Dropout\", \"inbound_nodes\": [[[\"Transformer-0-MultiHeadSelfAttention\", 0, 0, {}]]]}, {\"class_name\": \"Add\", \"config\": {\"name\": \"Transformer-0-MultiHeadSelfAttention-Add\", \"trainable\": false, \"dtype\": \"float32\"}, \"name\": \"Transformer-0-MultiHeadSelfAttention-Add\", \"inbound_nodes\": [[[\"Embedding-Dropout\", 0, 0, {}], [\"Transformer-0-MultiHeadSelfAttention-Dropout\", 0, 0, {}]]]}, {\"class_name\": \"LayerNormalization\", \"config\": {\"name\": \"Transformer-0-MultiHeadSelfAttention-Norm\", \"trainable\": false, \"dtype\": \"float32\", \"center\": true, \"scale\": true, \"epsilon\": 1e-12, \"conditional\": false, \"hidden_units\": null, \"hidden_activation\": \"linear\", \"hidden_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-0-MultiHeadSelfAttention-Norm\", \"inbound_nodes\": [[[\"Transformer-0-MultiHeadSelfAttention-Add\", 0, 0, {}]]]}, {\"class_name\": \"FeedForward\", \"config\": {\"name\": \"Transformer-0-FeedForward\", \"trainable\": false, \"dtype\": \"float32\", \"units\": 3072, \"activation\": \"gelu_erf\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-0-FeedForward\", \"inbound_nodes\": [[[\"Transformer-0-MultiHeadSelfAttention-Norm\", 0, 0, {}]]]}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"Transformer-0-FeedForward-Dropout\", \"trainable\": false, \"dtype\": \"float32\", \"rate\": 0.1, \"noise_shape\": null, \"seed\": null}, \"name\": \"Transformer-0-FeedForward-Dropout\", \"inbound_nodes\": [[[\"Transformer-0-FeedForward\", 0, 0, {}]]]}, {\"class_name\": \"Add\", \"config\": {\"name\": \"Transformer-0-FeedForward-Add\", \"trainable\": false, \"dtype\": \"float32\"}, \"name\": \"Transformer-0-FeedForward-Add\", \"inbound_nodes\": [[[\"Transformer-0-MultiHeadSelfAttention-Norm\", 0, 0, {}], [\"Transformer-0-FeedForward-Dropout\", 0, 0, {}]]]}, {\"class_name\": \"LayerNormalization\", \"config\": {\"name\": \"Transformer-0-FeedForward-Norm\", \"trainable\": false, \"dtype\": \"float32\", \"center\": true, \"scale\": true, \"epsilon\": 1e-12, \"conditional\": false, \"hidden_units\": null, \"hidden_activation\": \"linear\", \"hidden_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-0-FeedForward-Norm\", \"inbound_nodes\": [[[\"Transformer-0-FeedForward-Add\", 0, 0, {}]]]}, {\"class_name\": \"MultiHeadAttention\", \"config\": {\"name\": \"Transformer-1-MultiHeadSelfAttention\", \"trainable\": false, \"dtype\": \"float32\", \"heads\": 12, \"head_size\": 64, \"key_size\": 64, \"use_bias\": true, \"attention_scale\": true, \"kernel_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-1-MultiHeadSelfAttention\", \"inbound_nodes\": [[[\"Transformer-0-FeedForward-Norm\", 0, 0, {\"a_mask\": null}], [\"Transformer-0-FeedForward-Norm\", 0, 0, {\"a_mask\": null}], [\"Transformer-0-FeedForward-Norm\", 0, 0, {\"a_mask\": null}]]]}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"Transformer-1-MultiHeadSelfAttention-Dropout\", \"trainable\": false, \"dtype\": \"float32\", \"rate\": 0.1, \"noise_shape\": null, \"seed\": null}, \"name\": \"Transformer-1-MultiHeadSelfAttention-Dropout\", \"inbound_nodes\": [[[\"Transformer-1-MultiHeadSelfAttention\", 0, 0, {}]]]}, {\"class_name\": \"Add\", \"config\": {\"name\": \"Transformer-1-MultiHeadSelfAttention-Add\", \"trainable\": false, \"dtype\": \"float32\"}, \"name\": \"Transformer-1-MultiHeadSelfAttention-Add\", \"inbound_nodes\": [[[\"Transformer-0-FeedForward-Norm\", 0, 0, {}], [\"Transformer-1-MultiHeadSelfAttention-Dropout\", 0, 0, {}]]]}, {\"class_name\": \"LayerNormalization\", \"config\": {\"name\": \"Transformer-1-MultiHeadSelfAttention-Norm\", \"trainable\": false, \"dtype\": \"float32\", \"center\": true, \"scale\": true, \"epsilon\": 1e-12, \"conditional\": false, \"hidden_units\": null, \"hidden_activation\": \"linear\", \"hidden_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-1-MultiHeadSelfAttention-Norm\", \"inbound_nodes\": [[[\"Transformer-1-MultiHeadSelfAttention-Add\", 0, 0, {}]]]}, {\"class_name\": \"FeedForward\", \"config\": {\"name\": \"Transformer-1-FeedForward\", \"trainable\": false, \"dtype\": \"float32\", \"units\": 3072, \"activation\": \"gelu_erf\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-1-FeedForward\", \"inbound_nodes\": [[[\"Transformer-1-MultiHeadSelfAttention-Norm\", 0, 0, {}]]]}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"Transformer-1-FeedForward-Dropout\", \"trainable\": false, \"dtype\": \"float32\", \"rate\": 0.1, \"noise_shape\": null, \"seed\": null}, \"name\": \"Transformer-1-FeedForward-Dropout\", \"inbound_nodes\": [[[\"Transformer-1-FeedForward\", 0, 0, {}]]]}, {\"class_name\": \"Add\", \"config\": {\"name\": \"Transformer-1-FeedForward-Add\", \"trainable\": false, \"dtype\": \"float32\"}, \"name\": \"Transformer-1-FeedForward-Add\", \"inbound_nodes\": [[[\"Transformer-1-MultiHeadSelfAttention-Norm\", 0, 0, {}], [\"Transformer-1-FeedForward-Dropout\", 0, 0, {}]]]}, {\"class_name\": \"LayerNormalization\", \"config\": {\"name\": \"Transformer-1-FeedForward-Norm\", \"trainable\": false, \"dtype\": \"float32\", \"center\": true, \"scale\": true, \"epsilon\": 1e-12, \"conditional\": false, \"hidden_units\": null, \"hidden_activation\": \"linear\", \"hidden_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-1-FeedForward-Norm\", \"inbound_nodes\": [[[\"Transformer-1-FeedForward-Add\", 0, 0, {}]]]}, {\"class_name\": \"MultiHeadAttention\", \"config\": {\"name\": \"Transformer-2-MultiHeadSelfAttention\", \"trainable\": false, \"dtype\": \"float32\", \"heads\": 12, \"head_size\": 64, \"key_size\": 64, \"use_bias\": true, \"attention_scale\": true, \"kernel_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-2-MultiHeadSelfAttention\", \"inbound_nodes\": [[[\"Transformer-1-FeedForward-Norm\", 0, 0, {\"a_mask\": null}], [\"Transformer-1-FeedForward-Norm\", 0, 0, {\"a_mask\": null}], [\"Transformer-1-FeedForward-Norm\", 0, 0, {\"a_mask\": null}]]]}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"Transformer-2-MultiHeadSelfAttention-Dropout\", \"trainable\": false, \"dtype\": \"float32\", \"rate\": 0.1, \"noise_shape\": null, \"seed\": null}, \"name\": \"Transformer-2-MultiHeadSelfAttention-Dropout\", \"inbound_nodes\": [[[\"Transformer-2-MultiHeadSelfAttention\", 0, 0, {}]]]}, {\"class_name\": \"Add\", \"config\": {\"name\": \"Transformer-2-MultiHeadSelfAttention-Add\", \"trainable\": false, \"dtype\": \"float32\"}, \"name\": \"Transformer-2-MultiHeadSelfAttention-Add\", \"inbound_nodes\": [[[\"Transformer-1-FeedForward-Norm\", 0, 0, {}], [\"Transformer-2-MultiHeadSelfAttention-Dropout\", 0, 0, {}]]]}, {\"class_name\": \"LayerNormalization\", \"config\": {\"name\": \"Transformer-2-MultiHeadSelfAttention-Norm\", \"trainable\": false, \"dtype\": \"float32\", \"center\": true, \"scale\": true, \"epsilon\": 1e-12, \"conditional\": false, \"hidden_units\": null, \"hidden_activation\": \"linear\", \"hidden_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-2-MultiHeadSelfAttention-Norm\", \"inbound_nodes\": [[[\"Transformer-2-MultiHeadSelfAttention-Add\", 0, 0, {}]]]}, {\"class_name\": \"FeedForward\", \"config\": {\"name\": \"Transformer-2-FeedForward\", \"trainable\": false, \"dtype\": \"float32\", \"units\": 3072, \"activation\": \"gelu_erf\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-2-FeedForward\", \"inbound_nodes\": [[[\"Transformer-2-MultiHeadSelfAttention-Norm\", 0, 0, {}]]]}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"Transformer-2-FeedForward-Dropout\", \"trainable\": false, \"dtype\": \"float32\", \"rate\": 0.1, \"noise_shape\": null, \"seed\": null}, \"name\": \"Transformer-2-FeedForward-Dropout\", \"inbound_nodes\": [[[\"Transformer-2-FeedForward\", 0, 0, {}]]]}, {\"class_name\": \"Add\", \"config\": {\"name\": \"Transformer-2-FeedForward-Add\", \"trainable\": false, \"dtype\": \"float32\"}, \"name\": \"Transformer-2-FeedForward-Add\", \"inbound_nodes\": [[[\"Transformer-2-MultiHeadSelfAttention-Norm\", 0, 0, {}], [\"Transformer-2-FeedForward-Dropout\", 0, 0, {}]]]}, {\"class_name\": \"LayerNormalization\", \"config\": {\"name\": \"Transformer-2-FeedForward-Norm\", \"trainable\": false, \"dtype\": \"float32\", \"center\": true, \"scale\": true, \"epsilon\": 1e-12, \"conditional\": false, \"hidden_units\": null, \"hidden_activation\": \"linear\", \"hidden_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-2-FeedForward-Norm\", \"inbound_nodes\": [[[\"Transformer-2-FeedForward-Add\", 0, 0, {}]]]}, {\"class_name\": \"MultiHeadAttention\", \"config\": {\"name\": \"Transformer-3-MultiHeadSelfAttention\", \"trainable\": false, \"dtype\": \"float32\", \"heads\": 12, \"head_size\": 64, \"key_size\": 64, \"use_bias\": true, \"attention_scale\": true, \"kernel_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-3-MultiHeadSelfAttention\", \"inbound_nodes\": [[[\"Transformer-2-FeedForward-Norm\", 0, 0, {\"a_mask\": null}], [\"Transformer-2-FeedForward-Norm\", 0, 0, {\"a_mask\": null}], [\"Transformer-2-FeedForward-Norm\", 0, 0, {\"a_mask\": null}]]]}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"Transformer-3-MultiHeadSelfAttention-Dropout\", \"trainable\": false, \"dtype\": \"float32\", \"rate\": 0.1, \"noise_shape\": null, \"seed\": null}, \"name\": \"Transformer-3-MultiHeadSelfAttention-Dropout\", \"inbound_nodes\": [[[\"Transformer-3-MultiHeadSelfAttention\", 0, 0, {}]]]}, {\"class_name\": \"Add\", \"config\": {\"name\": \"Transformer-3-MultiHeadSelfAttention-Add\", \"trainable\": false, \"dtype\": \"float32\"}, \"name\": \"Transformer-3-MultiHeadSelfAttention-Add\", \"inbound_nodes\": [[[\"Transformer-2-FeedForward-Norm\", 0, 0, {}], [\"Transformer-3-MultiHeadSelfAttention-Dropout\", 0, 0, {}]]]}, {\"class_name\": \"LayerNormalization\", \"config\": {\"name\": \"Transformer-3-MultiHeadSelfAttention-Norm\", \"trainable\": false, \"dtype\": \"float32\", \"center\": true, \"scale\": true, \"epsilon\": 1e-12, \"conditional\": false, \"hidden_units\": null, \"hidden_activation\": \"linear\", \"hidden_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-3-MultiHeadSelfAttention-Norm\", \"inbound_nodes\": [[[\"Transformer-3-MultiHeadSelfAttention-Add\", 0, 0, {}]]]}, {\"class_name\": \"FeedForward\", \"config\": {\"name\": \"Transformer-3-FeedForward\", \"trainable\": false, \"dtype\": \"float32\", \"units\": 3072, \"activation\": \"gelu_erf\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-3-FeedForward\", \"inbound_nodes\": [[[\"Transformer-3-MultiHeadSelfAttention-Norm\", 0, 0, {}]]]}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"Transformer-3-FeedForward-Dropout\", \"trainable\": false, \"dtype\": \"float32\", \"rate\": 0.1, \"noise_shape\": null, \"seed\": null}, \"name\": \"Transformer-3-FeedForward-Dropout\", \"inbound_nodes\": [[[\"Transformer-3-FeedForward\", 0, 0, {}]]]}, {\"class_name\": \"Add\", \"config\": {\"name\": \"Transformer-3-FeedForward-Add\", \"trainable\": false, \"dtype\": \"float32\"}, \"name\": \"Transformer-3-FeedForward-Add\", \"inbound_nodes\": [[[\"Transformer-3-MultiHeadSelfAttention-Norm\", 0, 0, {}], [\"Transformer-3-FeedForward-Dropout\", 0, 0, {}]]]}, {\"class_name\": \"LayerNormalization\", \"config\": {\"name\": \"Transformer-3-FeedForward-Norm\", \"trainable\": false, \"dtype\": \"float32\", \"center\": true, \"scale\": true, \"epsilon\": 1e-12, \"conditional\": false, \"hidden_units\": null, \"hidden_activation\": \"linear\", \"hidden_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-3-FeedForward-Norm\", \"inbound_nodes\": [[[\"Transformer-3-FeedForward-Add\", 0, 0, {}]]]}, {\"class_name\": \"MultiHeadAttention\", \"config\": {\"name\": \"Transformer-4-MultiHeadSelfAttention\", \"trainable\": false, \"dtype\": \"float32\", \"heads\": 12, \"head_size\": 64, \"key_size\": 64, \"use_bias\": true, \"attention_scale\": true, \"kernel_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-4-MultiHeadSelfAttention\", \"inbound_nodes\": [[[\"Transformer-3-FeedForward-Norm\", 0, 0, {\"a_mask\": null}], [\"Transformer-3-FeedForward-Norm\", 0, 0, {\"a_mask\": null}], [\"Transformer-3-FeedForward-Norm\", 0, 0, {\"a_mask\": null}]]]}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"Transformer-4-MultiHeadSelfAttention-Dropout\", \"trainable\": false, \"dtype\": \"float32\", \"rate\": 0.1, \"noise_shape\": null, \"seed\": null}, \"name\": \"Transformer-4-MultiHeadSelfAttention-Dropout\", \"inbound_nodes\": [[[\"Transformer-4-MultiHeadSelfAttention\", 0, 0, {}]]]}, {\"class_name\": \"Add\", \"config\": {\"name\": \"Transformer-4-MultiHeadSelfAttention-Add\", \"trainable\": false, \"dtype\": \"float32\"}, \"name\": \"Transformer-4-MultiHeadSelfAttention-Add\", \"inbound_nodes\": [[[\"Transformer-3-FeedForward-Norm\", 0, 0, {}], [\"Transformer-4-MultiHeadSelfAttention-Dropout\", 0, 0, {}]]]}, {\"class_name\": \"LayerNormalization\", \"config\": {\"name\": \"Transformer-4-MultiHeadSelfAttention-Norm\", \"trainable\": false, \"dtype\": \"float32\", \"center\": true, \"scale\": true, \"epsilon\": 1e-12, \"conditional\": false, \"hidden_units\": null, \"hidden_activation\": \"linear\", \"hidden_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-4-MultiHeadSelfAttention-Norm\", \"inbound_nodes\": [[[\"Transformer-4-MultiHeadSelfAttention-Add\", 0, 0, {}]]]}, {\"class_name\": \"FeedForward\", \"config\": {\"name\": \"Transformer-4-FeedForward\", \"trainable\": false, \"dtype\": \"float32\", \"units\": 3072, \"activation\": \"gelu_erf\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-4-FeedForward\", \"inbound_nodes\": [[[\"Transformer-4-MultiHeadSelfAttention-Norm\", 0, 0, {}]]]}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"Transformer-4-FeedForward-Dropout\", \"trainable\": false, \"dtype\": \"float32\", \"rate\": 0.1, \"noise_shape\": null, \"seed\": null}, \"name\": \"Transformer-4-FeedForward-Dropout\", \"inbound_nodes\": [[[\"Transformer-4-FeedForward\", 0, 0, {}]]]}, {\"class_name\": \"Add\", \"config\": {\"name\": \"Transformer-4-FeedForward-Add\", \"trainable\": false, \"dtype\": \"float32\"}, \"name\": \"Transformer-4-FeedForward-Add\", \"inbound_nodes\": [[[\"Transformer-4-MultiHeadSelfAttention-Norm\", 0, 0, {}], [\"Transformer-4-FeedForward-Dropout\", 0, 0, {}]]]}, {\"class_name\": \"LayerNormalization\", \"config\": {\"name\": \"Transformer-4-FeedForward-Norm\", \"trainable\": false, \"dtype\": \"float32\", \"center\": true, \"scale\": true, \"epsilon\": 1e-12, \"conditional\": false, \"hidden_units\": null, \"hidden_activation\": \"linear\", \"hidden_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-4-FeedForward-Norm\", \"inbound_nodes\": [[[\"Transformer-4-FeedForward-Add\", 0, 0, {}]]]}, {\"class_name\": \"MultiHeadAttention\", \"config\": {\"name\": \"Transformer-5-MultiHeadSelfAttention\", \"trainable\": false, \"dtype\": \"float32\", \"heads\": 12, \"head_size\": 64, \"key_size\": 64, \"use_bias\": true, \"attention_scale\": true, \"kernel_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-5-MultiHeadSelfAttention\", \"inbound_nodes\": [[[\"Transformer-4-FeedForward-Norm\", 0, 0, {\"a_mask\": null}], [\"Transformer-4-FeedForward-Norm\", 0, 0, {\"a_mask\": null}], [\"Transformer-4-FeedForward-Norm\", 0, 0, {\"a_mask\": null}]]]}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"Transformer-5-MultiHeadSelfAttention-Dropout\", \"trainable\": false, \"dtype\": \"float32\", \"rate\": 0.1, \"noise_shape\": null, \"seed\": null}, \"name\": \"Transformer-5-MultiHeadSelfAttention-Dropout\", \"inbound_nodes\": [[[\"Transformer-5-MultiHeadSelfAttention\", 0, 0, {}]]]}, {\"class_name\": \"Add\", \"config\": {\"name\": \"Transformer-5-MultiHeadSelfAttention-Add\", \"trainable\": false, \"dtype\": \"float32\"}, \"name\": \"Transformer-5-MultiHeadSelfAttention-Add\", \"inbound_nodes\": [[[\"Transformer-4-FeedForward-Norm\", 0, 0, {}], [\"Transformer-5-MultiHeadSelfAttention-Dropout\", 0, 0, {}]]]}, {\"class_name\": \"LayerNormalization\", \"config\": {\"name\": \"Transformer-5-MultiHeadSelfAttention-Norm\", \"trainable\": false, \"dtype\": \"float32\", \"center\": true, \"scale\": true, \"epsilon\": 1e-12, \"conditional\": false, \"hidden_units\": null, \"hidden_activation\": \"linear\", \"hidden_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-5-MultiHeadSelfAttention-Norm\", \"inbound_nodes\": [[[\"Transformer-5-MultiHeadSelfAttention-Add\", 0, 0, {}]]]}, {\"class_name\": \"FeedForward\", \"config\": {\"name\": \"Transformer-5-FeedForward\", \"trainable\": false, \"dtype\": \"float32\", \"units\": 3072, \"activation\": \"gelu_erf\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-5-FeedForward\", \"inbound_nodes\": [[[\"Transformer-5-MultiHeadSelfAttention-Norm\", 0, 0, {}]]]}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"Transformer-5-FeedForward-Dropout\", \"trainable\": false, \"dtype\": \"float32\", \"rate\": 0.1, \"noise_shape\": null, \"seed\": null}, \"name\": \"Transformer-5-FeedForward-Dropout\", \"inbound_nodes\": [[[\"Transformer-5-FeedForward\", 0, 0, {}]]]}, {\"class_name\": \"Add\", \"config\": {\"name\": \"Transformer-5-FeedForward-Add\", \"trainable\": false, \"dtype\": \"float32\"}, \"name\": \"Transformer-5-FeedForward-Add\", \"inbound_nodes\": [[[\"Transformer-5-MultiHeadSelfAttention-Norm\", 0, 0, {}], [\"Transformer-5-FeedForward-Dropout\", 0, 0, {}]]]}, {\"class_name\": \"LayerNormalization\", \"config\": {\"name\": \"Transformer-5-FeedForward-Norm\", \"trainable\": false, \"dtype\": \"float32\", \"center\": true, \"scale\": true, \"epsilon\": 1e-12, \"conditional\": false, \"hidden_units\": null, \"hidden_activation\": \"linear\", \"hidden_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-5-FeedForward-Norm\", \"inbound_nodes\": [[[\"Transformer-5-FeedForward-Add\", 0, 0, {}]]]}, {\"class_name\": \"MultiHeadAttention\", \"config\": {\"name\": \"Transformer-6-MultiHeadSelfAttention\", \"trainable\": false, \"dtype\": \"float32\", \"heads\": 12, \"head_size\": 64, \"key_size\": 64, \"use_bias\": true, \"attention_scale\": true, \"kernel_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-6-MultiHeadSelfAttention\", \"inbound_nodes\": [[[\"Transformer-5-FeedForward-Norm\", 0, 0, {\"a_mask\": null}], [\"Transformer-5-FeedForward-Norm\", 0, 0, {\"a_mask\": null}], [\"Transformer-5-FeedForward-Norm\", 0, 0, {\"a_mask\": null}]]]}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"Transformer-6-MultiHeadSelfAttention-Dropout\", \"trainable\": false, \"dtype\": \"float32\", \"rate\": 0.1, \"noise_shape\": null, \"seed\": null}, \"name\": \"Transformer-6-MultiHeadSelfAttention-Dropout\", \"inbound_nodes\": [[[\"Transformer-6-MultiHeadSelfAttention\", 0, 0, {}]]]}, {\"class_name\": \"Add\", \"config\": {\"name\": \"Transformer-6-MultiHeadSelfAttention-Add\", \"trainable\": false, \"dtype\": \"float32\"}, \"name\": \"Transformer-6-MultiHeadSelfAttention-Add\", \"inbound_nodes\": [[[\"Transformer-5-FeedForward-Norm\", 0, 0, {}], [\"Transformer-6-MultiHeadSelfAttention-Dropout\", 0, 0, {}]]]}, {\"class_name\": \"LayerNormalization\", \"config\": {\"name\": \"Transformer-6-MultiHeadSelfAttention-Norm\", \"trainable\": false, \"dtype\": \"float32\", \"center\": true, \"scale\": true, \"epsilon\": 1e-12, \"conditional\": false, \"hidden_units\": null, \"hidden_activation\": \"linear\", \"hidden_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-6-MultiHeadSelfAttention-Norm\", \"inbound_nodes\": [[[\"Transformer-6-MultiHeadSelfAttention-Add\", 0, 0, {}]]]}, {\"class_name\": \"FeedForward\", \"config\": {\"name\": \"Transformer-6-FeedForward\", \"trainable\": false, \"dtype\": \"float32\", \"units\": 3072, \"activation\": \"gelu_erf\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-6-FeedForward\", \"inbound_nodes\": [[[\"Transformer-6-MultiHeadSelfAttention-Norm\", 0, 0, {}]]]}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"Transformer-6-FeedForward-Dropout\", \"trainable\": false, \"dtype\": \"float32\", \"rate\": 0.1, \"noise_shape\": null, \"seed\": null}, \"name\": \"Transformer-6-FeedForward-Dropout\", \"inbound_nodes\": [[[\"Transformer-6-FeedForward\", 0, 0, {}]]]}, {\"class_name\": \"Add\", \"config\": {\"name\": \"Transformer-6-FeedForward-Add\", \"trainable\": false, \"dtype\": \"float32\"}, \"name\": \"Transformer-6-FeedForward-Add\", \"inbound_nodes\": [[[\"Transformer-6-MultiHeadSelfAttention-Norm\", 0, 0, {}], [\"Transformer-6-FeedForward-Dropout\", 0, 0, {}]]]}, {\"class_name\": \"LayerNormalization\", \"config\": {\"name\": \"Transformer-6-FeedForward-Norm\", \"trainable\": false, \"dtype\": \"float32\", \"center\": true, \"scale\": true, \"epsilon\": 1e-12, \"conditional\": false, \"hidden_units\": null, \"hidden_activation\": \"linear\", \"hidden_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-6-FeedForward-Norm\", \"inbound_nodes\": [[[\"Transformer-6-FeedForward-Add\", 0, 0, {}]]]}, {\"class_name\": \"MultiHeadAttention\", \"config\": {\"name\": \"Transformer-7-MultiHeadSelfAttention\", \"trainable\": false, \"dtype\": \"float32\", \"heads\": 12, \"head_size\": 64, \"key_size\": 64, \"use_bias\": true, \"attention_scale\": true, \"kernel_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-7-MultiHeadSelfAttention\", \"inbound_nodes\": [[[\"Transformer-6-FeedForward-Norm\", 0, 0, {\"a_mask\": null}], [\"Transformer-6-FeedForward-Norm\", 0, 0, {\"a_mask\": null}], [\"Transformer-6-FeedForward-Norm\", 0, 0, {\"a_mask\": null}]]]}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"Transformer-7-MultiHeadSelfAttention-Dropout\", \"trainable\": false, \"dtype\": \"float32\", \"rate\": 0.1, \"noise_shape\": null, \"seed\": null}, \"name\": \"Transformer-7-MultiHeadSelfAttention-Dropout\", \"inbound_nodes\": [[[\"Transformer-7-MultiHeadSelfAttention\", 0, 0, {}]]]}, {\"class_name\": \"Add\", \"config\": {\"name\": \"Transformer-7-MultiHeadSelfAttention-Add\", \"trainable\": false, \"dtype\": \"float32\"}, \"name\": \"Transformer-7-MultiHeadSelfAttention-Add\", \"inbound_nodes\": [[[\"Transformer-6-FeedForward-Norm\", 0, 0, {}], [\"Transformer-7-MultiHeadSelfAttention-Dropout\", 0, 0, {}]]]}, {\"class_name\": \"LayerNormalization\", \"config\": {\"name\": \"Transformer-7-MultiHeadSelfAttention-Norm\", \"trainable\": false, \"dtype\": \"float32\", \"center\": true, \"scale\": true, \"epsilon\": 1e-12, \"conditional\": false, \"hidden_units\": null, \"hidden_activation\": \"linear\", \"hidden_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-7-MultiHeadSelfAttention-Norm\", \"inbound_nodes\": [[[\"Transformer-7-MultiHeadSelfAttention-Add\", 0, 0, {}]]]}, {\"class_name\": \"FeedForward\", \"config\": {\"name\": \"Transformer-7-FeedForward\", \"trainable\": false, \"dtype\": \"float32\", \"units\": 3072, \"activation\": \"gelu_erf\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-7-FeedForward\", \"inbound_nodes\": [[[\"Transformer-7-MultiHeadSelfAttention-Norm\", 0, 0, {}]]]}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"Transformer-7-FeedForward-Dropout\", \"trainable\": false, \"dtype\": \"float32\", \"rate\": 0.1, \"noise_shape\": null, \"seed\": null}, \"name\": \"Transformer-7-FeedForward-Dropout\", \"inbound_nodes\": [[[\"Transformer-7-FeedForward\", 0, 0, {}]]]}, {\"class_name\": \"Add\", \"config\": {\"name\": \"Transformer-7-FeedForward-Add\", \"trainable\": false, \"dtype\": \"float32\"}, \"name\": \"Transformer-7-FeedForward-Add\", \"inbound_nodes\": [[[\"Transformer-7-MultiHeadSelfAttention-Norm\", 0, 0, {}], [\"Transformer-7-FeedForward-Dropout\", 0, 0, {}]]]}, {\"class_name\": \"LayerNormalization\", \"config\": {\"name\": \"Transformer-7-FeedForward-Norm\", \"trainable\": false, \"dtype\": \"float32\", \"center\": true, \"scale\": true, \"epsilon\": 1e-12, \"conditional\": false, \"hidden_units\": null, \"hidden_activation\": \"linear\", \"hidden_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-7-FeedForward-Norm\", \"inbound_nodes\": [[[\"Transformer-7-FeedForward-Add\", 0, 0, {}]]]}, {\"class_name\": \"MultiHeadAttention\", \"config\": {\"name\": \"Transformer-8-MultiHeadSelfAttention\", \"trainable\": false, \"dtype\": \"float32\", \"heads\": 12, \"head_size\": 64, \"key_size\": 64, \"use_bias\": true, \"attention_scale\": true, \"kernel_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-8-MultiHeadSelfAttention\", \"inbound_nodes\": [[[\"Transformer-7-FeedForward-Norm\", 0, 0, {\"a_mask\": null}], [\"Transformer-7-FeedForward-Norm\", 0, 0, {\"a_mask\": null}], [\"Transformer-7-FeedForward-Norm\", 0, 0, {\"a_mask\": null}]]]}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"Transformer-8-MultiHeadSelfAttention-Dropout\", \"trainable\": false, \"dtype\": \"float32\", \"rate\": 0.1, \"noise_shape\": null, \"seed\": null}, \"name\": \"Transformer-8-MultiHeadSelfAttention-Dropout\", \"inbound_nodes\": [[[\"Transformer-8-MultiHeadSelfAttention\", 0, 0, {}]]]}, {\"class_name\": \"Add\", \"config\": {\"name\": \"Transformer-8-MultiHeadSelfAttention-Add\", \"trainable\": false, \"dtype\": \"float32\"}, \"name\": \"Transformer-8-MultiHeadSelfAttention-Add\", \"inbound_nodes\": [[[\"Transformer-7-FeedForward-Norm\", 0, 0, {}], [\"Transformer-8-MultiHeadSelfAttention-Dropout\", 0, 0, {}]]]}, {\"class_name\": \"LayerNormalization\", \"config\": {\"name\": \"Transformer-8-MultiHeadSelfAttention-Norm\", \"trainable\": false, \"dtype\": \"float32\", \"center\": true, \"scale\": true, \"epsilon\": 1e-12, \"conditional\": false, \"hidden_units\": null, \"hidden_activation\": \"linear\", \"hidden_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-8-MultiHeadSelfAttention-Norm\", \"inbound_nodes\": [[[\"Transformer-8-MultiHeadSelfAttention-Add\", 0, 0, {}]]]}, {\"class_name\": \"FeedForward\", \"config\": {\"name\": \"Transformer-8-FeedForward\", \"trainable\": false, \"dtype\": \"float32\", \"units\": 3072, \"activation\": \"gelu_erf\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-8-FeedForward\", \"inbound_nodes\": [[[\"Transformer-8-MultiHeadSelfAttention-Norm\", 0, 0, {}]]]}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"Transformer-8-FeedForward-Dropout\", \"trainable\": false, \"dtype\": \"float32\", \"rate\": 0.1, \"noise_shape\": null, \"seed\": null}, \"name\": \"Transformer-8-FeedForward-Dropout\", \"inbound_nodes\": [[[\"Transformer-8-FeedForward\", 0, 0, {}]]]}, {\"class_name\": \"Add\", \"config\": {\"name\": \"Transformer-8-FeedForward-Add\", \"trainable\": false, \"dtype\": \"float32\"}, \"name\": \"Transformer-8-FeedForward-Add\", \"inbound_nodes\": [[[\"Transformer-8-MultiHeadSelfAttention-Norm\", 0, 0, {}], [\"Transformer-8-FeedForward-Dropout\", 0, 0, {}]]]}, {\"class_name\": \"LayerNormalization\", \"config\": {\"name\": \"Transformer-8-FeedForward-Norm\", \"trainable\": false, \"dtype\": \"float32\", \"center\": true, \"scale\": true, \"epsilon\": 1e-12, \"conditional\": false, \"hidden_units\": null, \"hidden_activation\": \"linear\", \"hidden_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-8-FeedForward-Norm\", \"inbound_nodes\": [[[\"Transformer-8-FeedForward-Add\", 0, 0, {}]]]}, {\"class_name\": \"MultiHeadAttention\", \"config\": {\"name\": \"Transformer-9-MultiHeadSelfAttention\", \"trainable\": false, \"dtype\": \"float32\", \"heads\": 12, \"head_size\": 64, \"key_size\": 64, \"use_bias\": true, \"attention_scale\": true, \"kernel_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-9-MultiHeadSelfAttention\", \"inbound_nodes\": [[[\"Transformer-8-FeedForward-Norm\", 0, 0, {\"a_mask\": null}], [\"Transformer-8-FeedForward-Norm\", 0, 0, {\"a_mask\": null}], [\"Transformer-8-FeedForward-Norm\", 0, 0, {\"a_mask\": null}]]]}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"Transformer-9-MultiHeadSelfAttention-Dropout\", \"trainable\": false, \"dtype\": \"float32\", \"rate\": 0.1, \"noise_shape\": null, \"seed\": null}, \"name\": \"Transformer-9-MultiHeadSelfAttention-Dropout\", \"inbound_nodes\": [[[\"Transformer-9-MultiHeadSelfAttention\", 0, 0, {}]]]}, {\"class_name\": \"Add\", \"config\": {\"name\": \"Transformer-9-MultiHeadSelfAttention-Add\", \"trainable\": false, \"dtype\": \"float32\"}, \"name\": \"Transformer-9-MultiHeadSelfAttention-Add\", \"inbound_nodes\": [[[\"Transformer-8-FeedForward-Norm\", 0, 0, {}], [\"Transformer-9-MultiHeadSelfAttention-Dropout\", 0, 0, {}]]]}, {\"class_name\": \"LayerNormalization\", \"config\": {\"name\": \"Transformer-9-MultiHeadSelfAttention-Norm\", \"trainable\": false, \"dtype\": \"float32\", \"center\": true, \"scale\": true, \"epsilon\": 1e-12, \"conditional\": false, \"hidden_units\": null, \"hidden_activation\": \"linear\", \"hidden_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-9-MultiHeadSelfAttention-Norm\", \"inbound_nodes\": [[[\"Transformer-9-MultiHeadSelfAttention-Add\", 0, 0, {}]]]}, {\"class_name\": \"FeedForward\", \"config\": {\"name\": \"Transformer-9-FeedForward\", \"trainable\": false, \"dtype\": \"float32\", \"units\": 3072, \"activation\": \"gelu_erf\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-9-FeedForward\", \"inbound_nodes\": [[[\"Transformer-9-MultiHeadSelfAttention-Norm\", 0, 0, {}]]]}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"Transformer-9-FeedForward-Dropout\", \"trainable\": false, \"dtype\": \"float32\", \"rate\": 0.1, \"noise_shape\": null, \"seed\": null}, \"name\": \"Transformer-9-FeedForward-Dropout\", \"inbound_nodes\": [[[\"Transformer-9-FeedForward\", 0, 0, {}]]]}, {\"class_name\": \"Add\", \"config\": {\"name\": \"Transformer-9-FeedForward-Add\", \"trainable\": false, \"dtype\": \"float32\"}, \"name\": \"Transformer-9-FeedForward-Add\", \"inbound_nodes\": [[[\"Transformer-9-MultiHeadSelfAttention-Norm\", 0, 0, {}], [\"Transformer-9-FeedForward-Dropout\", 0, 0, {}]]]}, {\"class_name\": \"LayerNormalization\", \"config\": {\"name\": \"Transformer-9-FeedForward-Norm\", \"trainable\": false, \"dtype\": \"float32\", \"center\": true, \"scale\": true, \"epsilon\": 1e-12, \"conditional\": false, \"hidden_units\": null, \"hidden_activation\": \"linear\", \"hidden_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-9-FeedForward-Norm\", \"inbound_nodes\": [[[\"Transformer-9-FeedForward-Add\", 0, 0, {}]]]}, {\"class_name\": \"MultiHeadAttention\", \"config\": {\"name\": \"Transformer-10-MultiHeadSelfAttention\", \"trainable\": false, \"dtype\": \"float32\", \"heads\": 12, \"head_size\": 64, \"key_size\": 64, \"use_bias\": true, \"attention_scale\": true, \"kernel_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-10-MultiHeadSelfAttention\", \"inbound_nodes\": [[[\"Transformer-9-FeedForward-Norm\", 0, 0, {\"a_mask\": null}], [\"Transformer-9-FeedForward-Norm\", 0, 0, {\"a_mask\": null}], [\"Transformer-9-FeedForward-Norm\", 0, 0, {\"a_mask\": null}]]]}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"Transformer-10-MultiHeadSelfAttention-Dropout\", \"trainable\": false, \"dtype\": \"float32\", \"rate\": 0.1, \"noise_shape\": null, \"seed\": null}, \"name\": \"Transformer-10-MultiHeadSelfAttention-Dropout\", \"inbound_nodes\": [[[\"Transformer-10-MultiHeadSelfAttention\", 0, 0, {}]]]}, {\"class_name\": \"Add\", \"config\": {\"name\": \"Transformer-10-MultiHeadSelfAttention-Add\", \"trainable\": false, \"dtype\": \"float32\"}, \"name\": \"Transformer-10-MultiHeadSelfAttention-Add\", \"inbound_nodes\": [[[\"Transformer-9-FeedForward-Norm\", 0, 0, {}], [\"Transformer-10-MultiHeadSelfAttention-Dropout\", 0, 0, {}]]]}, {\"class_name\": \"LayerNormalization\", \"config\": {\"name\": \"Transformer-10-MultiHeadSelfAttention-Norm\", \"trainable\": false, \"dtype\": \"float32\", \"center\": true, \"scale\": true, \"epsilon\": 1e-12, \"conditional\": false, \"hidden_units\": null, \"hidden_activation\": \"linear\", \"hidden_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-10-MultiHeadSelfAttention-Norm\", \"inbound_nodes\": [[[\"Transformer-10-MultiHeadSelfAttention-Add\", 0, 0, {}]]]}, {\"class_name\": \"FeedForward\", \"config\": {\"name\": \"Transformer-10-FeedForward\", \"trainable\": false, \"dtype\": \"float32\", \"units\": 3072, \"activation\": \"gelu_erf\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-10-FeedForward\", \"inbound_nodes\": [[[\"Transformer-10-MultiHeadSelfAttention-Norm\", 0, 0, {}]]]}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"Transformer-10-FeedForward-Dropout\", \"trainable\": false, \"dtype\": \"float32\", \"rate\": 0.1, \"noise_shape\": null, \"seed\": null}, \"name\": \"Transformer-10-FeedForward-Dropout\", \"inbound_nodes\": [[[\"Transformer-10-FeedForward\", 0, 0, {}]]]}, {\"class_name\": \"Add\", \"config\": {\"name\": \"Transformer-10-FeedForward-Add\", \"trainable\": false, \"dtype\": \"float32\"}, \"name\": \"Transformer-10-FeedForward-Add\", \"inbound_nodes\": [[[\"Transformer-10-MultiHeadSelfAttention-Norm\", 0, 0, {}], [\"Transformer-10-FeedForward-Dropout\", 0, 0, {}]]]}, {\"class_name\": \"LayerNormalization\", \"config\": {\"name\": \"Transformer-10-FeedForward-Norm\", \"trainable\": false, \"dtype\": \"float32\", \"center\": true, \"scale\": true, \"epsilon\": 1e-12, \"conditional\": false, \"hidden_units\": null, \"hidden_activation\": \"linear\", \"hidden_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-10-FeedForward-Norm\", \"inbound_nodes\": [[[\"Transformer-10-FeedForward-Add\", 0, 0, {}]]]}, {\"class_name\": \"MultiHeadAttention\", \"config\": {\"name\": \"Transformer-11-MultiHeadSelfAttention\", \"trainable\": false, \"dtype\": \"float32\", \"heads\": 12, \"head_size\": 64, \"key_size\": 64, \"use_bias\": true, \"attention_scale\": true, \"kernel_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-11-MultiHeadSelfAttention\", \"inbound_nodes\": [[[\"Transformer-10-FeedForward-Norm\", 0, 0, {\"a_mask\": null}], [\"Transformer-10-FeedForward-Norm\", 0, 0, {\"a_mask\": null}], [\"Transformer-10-FeedForward-Norm\", 0, 0, {\"a_mask\": null}]]]}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"Transformer-11-MultiHeadSelfAttention-Dropout\", \"trainable\": false, \"dtype\": \"float32\", \"rate\": 0.1, \"noise_shape\": null, \"seed\": null}, \"name\": \"Transformer-11-MultiHeadSelfAttention-Dropout\", \"inbound_nodes\": [[[\"Transformer-11-MultiHeadSelfAttention\", 0, 0, {}]]]}, {\"class_name\": \"Add\", \"config\": {\"name\": \"Transformer-11-MultiHeadSelfAttention-Add\", \"trainable\": false, \"dtype\": \"float32\"}, \"name\": \"Transformer-11-MultiHeadSelfAttention-Add\", \"inbound_nodes\": [[[\"Transformer-10-FeedForward-Norm\", 0, 0, {}], [\"Transformer-11-MultiHeadSelfAttention-Dropout\", 0, 0, {}]]]}, {\"class_name\": \"LayerNormalization\", \"config\": {\"name\": \"Transformer-11-MultiHeadSelfAttention-Norm\", \"trainable\": false, \"dtype\": \"float32\", \"center\": true, \"scale\": true, \"epsilon\": 1e-12, \"conditional\": false, \"hidden_units\": null, \"hidden_activation\": \"linear\", \"hidden_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-11-MultiHeadSelfAttention-Norm\", \"inbound_nodes\": [[[\"Transformer-11-MultiHeadSelfAttention-Add\", 0, 0, {}]]]}, {\"class_name\": \"FeedForward\", \"config\": {\"name\": \"Transformer-11-FeedForward\", \"trainable\": false, \"dtype\": \"float32\", \"units\": 3072, \"activation\": \"gelu_erf\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-11-FeedForward\", \"inbound_nodes\": [[[\"Transformer-11-MultiHeadSelfAttention-Norm\", 0, 0, {}]]]}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"Transformer-11-FeedForward-Dropout\", \"trainable\": false, \"dtype\": \"float32\", \"rate\": 0.1, \"noise_shape\": null, \"seed\": null}, \"name\": \"Transformer-11-FeedForward-Dropout\", \"inbound_nodes\": [[[\"Transformer-11-FeedForward\", 0, 0, {}]]]}, {\"class_name\": \"Add\", \"config\": {\"name\": \"Transformer-11-FeedForward-Add\", \"trainable\": false, \"dtype\": \"float32\"}, \"name\": \"Transformer-11-FeedForward-Add\", \"inbound_nodes\": [[[\"Transformer-11-MultiHeadSelfAttention-Norm\", 0, 0, {}], [\"Transformer-11-FeedForward-Dropout\", 0, 0, {}]]]}, {\"class_name\": \"LayerNormalization\", \"config\": {\"name\": \"Transformer-11-FeedForward-Norm\", \"trainable\": false, \"dtype\": \"float32\", \"center\": true, \"scale\": true, \"epsilon\": 1e-12, \"conditional\": false, \"hidden_units\": null, \"hidden_activation\": \"linear\", \"hidden_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.02, \"seed\": null}}}, \"name\": \"Transformer-11-FeedForward-Norm\", \"inbound_nodes\": [[[\"Transformer-11-FeedForward-Add\", 0, 0, {}]]]}, {\"class_name\": \"Bidirectional\", \"config\": {\"name\": \"bidirectional\", \"trainable\": true, \"dtype\": \"float32\", \"layer\": {\"class_name\": \"LSTM\", \"config\": {\"name\": \"lstm\", \"trainable\": true, \"dtype\": \"float32\", \"return_sequences\": false, \"return_state\": false, \"go_backwards\": false, \"stateful\": false, \"unroll\": false, \"time_major\": false, \"units\": 128, \"activation\": \"tanh\", \"recurrent_activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"recurrent_initializer\": {\"class_name\": \"Orthogonal\", \"config\": {\"gain\": 1.0, \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"unit_forget_bias\": true, \"kernel_regularizer\": null, \"recurrent_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"recurrent_constraint\": null, \"bias_constraint\": null, \"dropout\": 0.0, \"recurrent_dropout\": 0.0, \"implementation\": 2}}, \"merge_mode\": \"concat\"}, \"name\": \"bidirectional\", \"inbound_nodes\": [[[\"Transformer-11-FeedForward-Norm\", 0, 0, {}]]]}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 7, \"activation\": \"linear\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"name\": \"dense\", \"inbound_nodes\": [[[\"bidirectional\", 0, 0, {}]]]}, {\"class_name\": \"Activation\", \"config\": {\"name\": \"activation\", \"trainable\": true, \"dtype\": \"float32\", \"activation\": \"softmax\"}, \"name\": \"activation\", \"inbound_nodes\": [[[\"dense\", 0, 0, {}]]]}], \"input_layers\": [[\"Input-Token\", 0, 0], [\"Input-Segment\", 0, 0]], \"output_layers\": [[\"activation\", 0, 0]]}, \"keras_version\": \"2.4.0\", \"backend\": \"tensorflow\"}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1tAWfbRQO3r",
        "outputId": "ce3ef46e-3548-4f6c-8031-365a212b3064",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "loaded_model.evaluate(test_x,test_y)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-12 06:41:05,265 [WARNING] kashgari - Sequence length is None, will use the max length of the samples, which is 128\n",
            "2020-10-12 06:41:05,298 [DEBUG] kashgari - predict input shape (2, 475, 128) x: \n",
            "(array([[  101,  3218,  3262, ...,     0,     0,     0],\n",
            "       [  101,  3787,  2647, ...,     0,     0,     0],\n",
            "       [  101,  3570,  2658, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [  101, 29571,  5812, ...,     0,     0,     0],\n",
            "       [  101,  5069,  9518, ...,     0,     0,     0],\n",
            "       [  101,  2220, 16215, ...,     0,     0,     0]], dtype=int32), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32))\n",
            "2020-10-12 06:41:17,993 [DEBUG] kashgari - predict output shape (475, 7)\n",
            "2020-10-12 06:41:17,996 [DEBUG] kashgari - predict output argmax: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 5 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 3 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 5 0 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 4 4 4 4 4 4 4\n",
            " 4 4 4 4 4 4 4 4 4 4 4 4 4 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
            " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                  precision    recall  f1-score   support\n",
            "\n",
            "        Business     0.9608    1.0000    0.9800        49\n",
            "acadamic_science     0.9799    0.9605    0.9701       152\n",
            "       community     0.9877    0.9877    0.9877        81\n",
            "       computing     0.9348    0.9773    0.9556        44\n",
            "     govermnetal     1.0000    0.9853    0.9926        68\n",
            "         medical     0.9753    0.9753    0.9753        81\n",
            "\n",
            "        accuracy                         0.9768       475\n",
            "       macro avg     0.9731    0.9810    0.9769       475\n",
            "    weighted avg     0.9772    0.9768    0.9769       475\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'detail': {'Business': {'f1-score': 0.98,\n",
              "   'precision': 0.9607843137254902,\n",
              "   'recall': 1.0,\n",
              "   'support': 49},\n",
              "  'acadamic_science': {'f1-score': 0.9700996677740865,\n",
              "   'precision': 0.9798657718120806,\n",
              "   'recall': 0.9605263157894737,\n",
              "   'support': 152},\n",
              "  'accuracy': 0.9768421052631578,\n",
              "  'community': {'f1-score': 0.9876543209876543,\n",
              "   'precision': 0.9876543209876543,\n",
              "   'recall': 0.9876543209876543,\n",
              "   'support': 81},\n",
              "  'computing': {'f1-score': 0.9555555555555557,\n",
              "   'precision': 0.9347826086956522,\n",
              "   'recall': 0.9772727272727273,\n",
              "   'support': 44},\n",
              "  'govermnetal': {'f1-score': 0.9925925925925926,\n",
              "   'precision': 1.0,\n",
              "   'recall': 0.9852941176470589,\n",
              "   'support': 68},\n",
              "  'macro avg': {'f1-score': 0.976868463147533,\n",
              "   'precision': 0.973065942866031,\n",
              "   'recall': 0.9810093539453705,\n",
              "   'support': 475},\n",
              "  'medical': {'f1-score': 0.9753086419753086,\n",
              "   'precision': 0.9753086419753086,\n",
              "   'recall': 0.9753086419753086,\n",
              "   'support': 81},\n",
              "  'weighted avg': {'f1-score': 0.9768755584050566,\n",
              "   'precision': 0.9771546599380926,\n",
              "   'recall': 0.9768421052631578,\n",
              "   'support': 475}},\n",
              " 'f1-score': 0.9768755584050566,\n",
              " 'precision': 0.9771546599380926,\n",
              " 'recall': 0.9768421052631578,\n",
              " 'support': 475}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2GF7gwK6QDq",
        "outputId": "2b3890ca-5bfa-4d44-f1af-cc11fbbeb416",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swUPQCD96AyO"
      },
      "source": [
        "achedStopWords = stopwords.words(\"english\")\n",
        " \n",
        "def tokenize(text):\n",
        "  min_length = 3\n",
        "  words = map(lambda word: word.lower(), word_tokenize(text))\n",
        "  words = [word for word in words if word not in achedStopWords]\n",
        "  tokens = (list(map(lambda token: PorterStemmer().stem(token),\n",
        "                                   words)))\n",
        "  p = re.compile('[a-zA-Z]+');\n",
        "  filtered_tokens =list(filter (lambda token: p.match(token) and\n",
        "                               len(token) >= min_length,\n",
        "                               tokens))\n",
        "  return filtered_tokens\n",
        "\n",
        "def word_tokenizer():\n",
        "  tokenize_docs = []\n",
        "  docs_tokens = docs_pdf_train['text'].tolist()\n",
        "  length = len(docs_tokens)\n",
        "  for i in range(length):\n",
        "    tokenize_docs.append(tokenize(docs_tokens[i]))\n",
        "  return tokenize_docs"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLlggrsqSSFB"
      },
      "source": [
        "def predict(docs):\n",
        "  tokenize_docs = []\n",
        "  df=pd.DataFrame([docs],columns=['text'])\n",
        "  docs_tokens = df['text'].tolist()\n",
        "  length = len(docs_tokens)\n",
        "  for i in range(length):\n",
        "    tokenize_docs.append(tokenize(docs_tokens[i]))\n",
        "  return tokenize_docs"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNh5BUVDSVPf"
      },
      "source": [
        "x = predict('A medical encyclopaedia is a comprehensive written compendium that holds information about diseases, medical conditions, tests, symptoms, injuries, and surgeries. It may contain an extensive gallery of medicine-related photographs and illustrations. [1] A medical encyclopaedia provides information to readers about health questions. It may also contain some information about the history of diseases, the development of medical technology uses to detect diseases in its early phase. A licensed physician should be consulted for diagnosis and treatment of any and all medical conditions.')"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXYVnH4iXwTI",
        "outputId": "ebdfa61a-bf43-4077-8266-ec03268af226",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(x[0])"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2gZk5o1Q0mm",
        "outputId": "07a3b997-86e0-430e-f8ae-63c064f344c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "loaded_model.predict(x)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-12 06:46:30,903 [DEBUG] kashgari - predict input shape (2, 1, 51) x: \n",
            "(array([[  101,   100,   100,   100,  2517,   100,  2907, 12367,   100,\n",
            "          100,   100,  3231,   100,   100,   100,  2089,  5383,   100,\n",
            "          100,   100,  9982,   100,   100,   100,   100, 12367,  8068,\n",
            "         2740,  3160,  2089,  2036,  5383, 12367,   100,   100,  4503,\n",
            "          100,   100,  2224, 11487,   100,   100,  4403,   100,  7522,\n",
            "        23363,   100,  3949,   100,   100,   102]], dtype=int32), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0]], dtype=int32))\n",
            "2020-10-12 06:46:30,976 [DEBUG] kashgari - predict output shape (1, 7)\n",
            "2020-10-12 06:46:30,976 [DEBUG] kashgari - predict output argmax: [2]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['medical']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bez9rcLf7QZQ",
        "outputId": "c44e5908-d91f-49ae-e674-f01daa77a9b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "model.save('lstm_1')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-12 04:33:06,828 [INFO] kashgari - model saved to /content/lstm_1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/lstm_1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX9_eyhP7UgE",
        "outputId": "52bc64f3-0a58-463c-b7ee-cb37e1d6c807",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "wandb.save('/content/lstm_1')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['wandb/run-20201012_042017-12x51cbi/files/lstm_1']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DavroIXN85Bc",
        "outputId": "54355be9-6e71-4679-e2c7-35408cd75531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "wandb.save(\"/content/wandb/latest-run/files/lstm_1/embed_model_weights.h5\", base_path=\"/content/wandb/latest-run/\")\n",
        "wandb.save(\"/content/wandb/latest-run/files/lstm_1/model_config.json\", base_path=\"/content/wandb/latest-run/\")\n",
        "wandb.save(\"/content/wandb/latest-run/files/lstm_1/model_weights.h5\", base_path=\"/content/wandb/latest-run/\")\n",
        "\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['wandb/run-20201012_042017-12x51cbi/files/files/lstm_1/model_weights.h5',\n",
              " 'wandb/run-20201012_042017-12x51cbi/files/files/lstm_1/model_weights.h5']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vs_OFRzYyrJa",
        "outputId": "acf9011c-5219-4f6a-cf73-9533e4c4c9d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "train_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Academic_Science</td>\n",
              "      <td>['an', 'academic', 'degree', 'is', 'a', 'quali...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Academic_Science</td>\n",
              "      <td>['an', 'alumnus', 'masculine', 'plural', 'alum...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Academic_Science</td>\n",
              "      <td>['an', 'example', 'of', 'an', 'amateur', 'radi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Academic_Science</td>\n",
              "      <td>['anthropology', 'is', 'the', 'study', 'of', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Academic_Science</td>\n",
              "      <td>['roman', 'ruins', 'lausanne', 'switzerland', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>154</td>\n",
              "      <td>Medical</td>\n",
              "      <td>['rehabilitation', 'psychology', 'is', 'a', 's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>155</td>\n",
              "      <td>Medical</td>\n",
              "      <td>['surgeons', 'repairing', 'a', 'ruptured', 'ac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>156</td>\n",
              "      <td>Medical</td>\n",
              "      <td>['a', 'syndrome', 'is', 'a', 'set', 'of', 'med...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>157</td>\n",
              "      <td>Medical</td>\n",
              "      <td>['therapy', 'often', 'abbreviated', 'tx', 'tx'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>159</td>\n",
              "      <td>Medical</td>\n",
              "      <td>['a', 'veterinary', 'technician', 'in', 'ethio...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>133 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0  ...                                               text\n",
              "0             0  ...  ['an', 'academic', 'degree', 'is', 'a', 'quali...\n",
              "1             1  ...  ['an', 'alumnus', 'masculine', 'plural', 'alum...\n",
              "2             2  ...  ['an', 'example', 'of', 'an', 'amateur', 'radi...\n",
              "3             3  ...  ['anthropology', 'is', 'the', 'study', 'of', '...\n",
              "4             4  ...  ['roman', 'ruins', 'lausanne', 'switzerland', ...\n",
              "..          ...  ...                                                ...\n",
              "154         154  ...  ['rehabilitation', 'psychology', 'is', 'a', 's...\n",
              "155         155  ...  ['surgeons', 'repairing', 'a', 'ruptured', 'ac...\n",
              "156         156  ...  ['a', 'syndrome', 'is', 'a', 'set', 'of', 'med...\n",
              "157         157  ...  ['therapy', 'often', 'abbreviated', 'tx', 'tx'...\n",
              "159         159  ...  ['a', 'veterinary', 'technician', 'in', 'ethio...\n",
              "\n",
              "[133 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olNF8iDoZkTk"
      },
      "source": [
        "import ast\n",
        "X_train=[ast.literal_eval(i) for i in X_train]\n",
        "X_test=[ast.literal_eval(i) for i in X_test]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ni0w1Hgxgpn0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uGkEZHH5gra"
      },
      "source": [
        "X_train_filtered_list=[]\n",
        "X_train_filtered= [] \n",
        "for w in X_train:\n",
        "  for j in w:\n",
        "    if j not in stop_words: \n",
        "      X_train_filtered.append(j)\n",
        "  X_train_filtered_list.append(X_train_filtered)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qv2Q7jANkbHM"
      },
      "source": [
        "X_train_filtered_list=[]\n",
        "X_train_filtered= [] \n",
        "for w in X_train:\n",
        "  for j in w:\n",
        "    if j not in stop_words: \n",
        "      X_train_filtered.append(j)\n",
        "  X_train_filtered_list.append(X_train_filtered)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JcnUrz8k8yI"
      },
      "source": [
        "X_test_filtered_list=[]\n",
        "X_test_filtered= [] \n",
        "for w in X_test:\n",
        "  for j in w:\n",
        "    if j not in stop_words: \n",
        "      X_test_filtered.append(j)\n",
        "  X_test_filtered_list.append(X_test_filtered)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbRzaUCoyHnK"
      },
      "source": [
        "X_test_filtered_list[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jro7aZ4AgYio"
      },
      "source": [
        "model.fit(X_train_filtered_list,y_train,X_test_filtered_list,y_test,epochs=35,batch_size=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfzSX05vr-l4"
      },
      "source": [
        "model.save(\"LSTM\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTymvzVAadFa"
      },
      "source": [
        "!mkdir '/content/LSTM' \n",
        "!cp  '/content/drive/My Drive/Model_weights/embed_model_weights.h5' '/content/LSTM'\n",
        "!cp  '/content/drive/My Drive/Model_weights/model_config.json' '/content/LSTM'\n",
        "!cp  '/content/drive/My Drive/Model_weights/model_weights.h5' '/content/LSTM'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKd8k3nxyu1G",
        "outputId": "82eeaceb-fbbd-48a6-adf5-a8dd549e63f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "\n",
        "loaded_model = BiLSTM_Model.load_model('/content/LSTM/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-09-01 17:51:13,866 [DEBUG] kashgari - ------------------------------------------------\n",
            "2020-09-01 17:51:13,867 [DEBUG] kashgari - Loaded transformer model's vocab\n",
            "2020-09-01 17:51:13,868 [DEBUG] kashgari - config_path       : /content/uncased_L-12_H-768_A-12/bert_config.json\n",
            "2020-09-01 17:51:13,870 [DEBUG] kashgari - vocab_path      : /content/uncased_L-12_H-768_A-12/vocab.txt\n",
            "2020-09-01 17:51:13,871 [DEBUG] kashgari - checkpoint_path : /content/uncased_L-12_H-768_A-12/bert_model.ckpt\n",
            "2020-09-01 17:51:13,872 [DEBUG] kashgari - Top 50 words    : ['[PAD]', '[unused0]', '[unused1]', '[unused2]', '[unused3]', '[unused4]', '[unused5]', '[unused6]', '[unused7]', '[unused8]', '[unused9]', '[unused10]', '[unused11]', '[unused12]', '[unused13]', '[unused14]', '[unused15]', '[unused16]', '[unused17]', '[unused18]', '[unused19]', '[unused20]', '[unused21]', '[unused22]', '[unused23]', '[unused24]', '[unused25]', '[unused26]', '[unused27]', '[unused28]', '[unused29]', '[unused30]', '[unused31]', '[unused32]', '[unused33]', '[unused34]', '[unused35]', '[unused36]', '[unused37]', '[unused38]', '[unused39]', '[unused40]', '[unused41]', '[unused42]', '[unused43]', '[unused44]', '[unused45]', '[unused46]', '[unused47]', '[unused48]']\n",
            "2020-09-01 17:51:13,873 [DEBUG] kashgari - ------------------------------------------------\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x_qJMLXYjBs"
      },
      "source": [
        "def predict(docs):\n",
        "  tokenize_docs = []\n",
        "  df=pd.DataFrame([docs],columns=['text'])\n",
        "  docs_tokens = df['text'].tolist()\n",
        "  length = len(docs_tokens)\n",
        "  for i in range(length):\n",
        "    tokenize_docs.append(tokenize(docs_tokens[i]))\n",
        "  return tokenize_docs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ge6kaDKzZ7MP",
        "outputId": "0ea9960c-1148-4e0d-b310-1fec7e8e6873",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "loaded_model.predict([nltk_tokens])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-09-01 18:08:44,835 [DEBUG] kashgari - predict input shape (2, 1, 62) x: \n",
            "(array([[  101,   100, 13058,   100,  5658,   100, 14931,  1058, 14931,\n",
            "         5658,  1058,  5096,   100,  1058,   100,   100,   100,   100,\n",
            "         1058,   100,  3157,   100,   100, 14931,  1058, 14931,  5658,\n",
            "          100,  1058,   100,  5096,   100,  1058,   100,   100,   100,\n",
            "          100,  1058,   100,   100,  2566,  3745, 11138,   100,  1997,\n",
            "         2048,   100,  3745,  1999,  3988,  2270,  3157,   100,  2765,\n",
            "         2421,  9313,  5114,  1997,   100,  2030, 14931,   102]],\n",
            "      dtype=int32), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "      dtype=int32))\n",
            "2020-09-01 18:08:44,907 [DEBUG] kashgari - predict output shape (1, 110)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['earn']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkFtf1vr3CZY",
        "outputId": "e6104158-be12-49a5-a69d-e415fd044faf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "loaded_model.evaluate(toknize_test,test_labels_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-09-01 18:10:17,533 [DEBUG] kashgari - predict input shape (2, 10389, 512) x: \n",
            "(array([[ 101, 1045, 2572, ...,    0,    0,    0],\n",
            "       [ 101, 1045, 2031, ...,    0,    0,    0],\n",
            "       [ 101, 1045, 2342, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [ 101, 3034, 3013, ...,    0,    0,    0],\n",
            "       [ 101, 3354, 3919, ...,    0,    0,    0],\n",
            "       [ 101, 2416, 2730, ...,    0,    0,    0]], dtype=int32), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32))\n",
            "2020-09-01 18:17:21,525 [DEBUG] kashgari - predict output shape (10389, 110)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                      precision    recall  f1-score   support\n",
            "                earn     0.9709    0.9825    0.9767      1087\n",
            "                 acq     0.9677    0.9583    0.9630       719\n",
            "      comp.windows.x     0.4296    0.5964    0.4995       394\n",
            "    rec.sport.hockey     0.9121    0.7143    0.8011       392\n",
            "soc.religion.christian     0.5245    0.8010    0.6339       387\n",
            "     rec.motorcycles     0.9403    0.3214    0.4791       392\n",
            "comp.sys.ibm.pc.hardware     0.5000    0.0052    0.0102       387\n",
            "        misc.forsale     0.8287    0.6108    0.7033       388\n",
            "             sci.med     0.9623    0.5312    0.6846       384\n",
            "  rec.sport.baseball     0.7622    0.6909    0.7248       385\n",
            "           sci.crypt     0.4503    0.6518    0.5326       382\n",
            "           sci.space     0.9820    0.4282    0.5964       383\n",
            "     sci.electronics     0.5520    0.3603    0.4360       383\n",
            "comp.os.ms-windows.misc     1.0000    0.0026    0.0052       382\n",
            "       comp.graphics     0.7683    0.1641    0.2704       384\n",
            "           rec.autos     0.8696    0.4762    0.6154       378\n",
            "comp.sys.mac.hardware     0.8485    0.0749    0.1376       374\n",
            "talk.politics.mideast     0.7402    0.7105    0.7250       373\n",
            "  talk.politics.guns     0.6716    0.1264    0.2128       356\n",
            "         alt.atheism     0.0000    0.0000    0.0000       313\n",
            "  talk.politics.misc     0.4337    0.3941    0.4130       307\n",
            "            money-fx     0.7826    0.8045    0.7934       179\n",
            "  talk.religion.misc     0.0000    0.0000    0.0000       246\n",
            "               grain     0.9493    0.8792    0.9129       149\n",
            "               crude     0.7637    0.9577    0.8498       189\n",
            "               trade     0.8053    0.7778    0.7913       117\n",
            "            interest     0.7801    0.8397    0.8088       131\n",
            "                ship     0.7973    0.6629    0.7239        89\n",
            "               wheat     0.9259    0.7042    0.8000        71\n",
            "                corn     0.8000    0.7857    0.7928        56\n",
            "                 dlr     0.8333    0.4545    0.5882        44\n",
            "        money-supply     0.7500    0.8824    0.8108        34\n",
            "             oilseed     0.7000    0.2979    0.4179        47\n",
            "               sugar     0.9615    0.6944    0.8065        36\n",
            "              coffee     0.9615    0.8929    0.9259        28\n",
            "                 gnp     0.8333    0.7143    0.7692        35\n",
            "             veg-oil     0.8421    0.4324    0.5714        37\n",
            "                gold     0.8095    0.5667    0.6667        30\n",
            "             soybean     0.5000    0.0909    0.1538        33\n",
            "             nat-gas     0.7059    0.4000    0.5106        30\n",
            "                 bop     0.6500    0.4333    0.5200        30\n",
            "           livestock     0.6667    0.6667    0.6667        24\n",
            "                 cpi     0.9286    0.4643    0.6190        28\n",
            "               cocoa     1.0000    0.9444    0.9714        18\n",
            "            reserves     0.9091    0.5556    0.6897        18\n",
            "             carcass     0.7143    0.5556    0.6250        18\n",
            "                jobs     1.0000    0.5714    0.7273        21\n",
            "              copper     1.0000    0.4444    0.6154        18\n",
            "              cotton     0.8571    0.3000    0.4444        20\n",
            "                 yen     0.7500    0.2143    0.3333        14\n",
            "                rice     0.8889    0.3333    0.4848        24\n",
            "                alum     0.9091    0.4348    0.5882        23\n",
            "                 gas     0.8571    0.7059    0.7742        17\n",
            "          iron-steel     0.8571    0.4286    0.5714        14\n",
            "                 ipi     0.9231    1.0000    0.9600        12\n",
            "              barley     0.6250    0.3571    0.4545        14\n",
            "           meal-feed     0.0000    0.0000    0.0000        19\n",
            "              rubber     1.0000    0.5833    0.7368        12\n",
            "            palm-oil     0.7143    0.5000    0.5882        10\n",
            "             sorghum     1.0000    0.1000    0.1818        10\n",
            "                zinc     0.8889    0.6154    0.7273        13\n",
            "            pet-chem     0.0000    0.0000    0.0000        12\n",
            "                 tin     1.0000    0.4167    0.5882        12\n",
            "                lead     0.8571    0.4286    0.5714        14\n",
            "              silver     0.0000    0.0000    0.0000         8\n",
            "                 wpi     1.0000    0.7000    0.8235        10\n",
            "     strategic-metal     0.0000    0.0000    0.0000        11\n",
            "            rapeseed     1.0000    0.4444    0.6154         9\n",
            "              orange     1.0000    0.5455    0.7059        11\n",
            "            soy-meal     0.0000    0.0000    0.0000        13\n",
            "             soy-oil     0.0000    0.0000    0.0000        11\n",
            "              retail     1.0000    0.5000    0.6667         2\n",
            "                fuel     0.6667    0.2000    0.3077        10\n",
            "                 hog     0.5000    0.3333    0.4000         6\n",
            "             housing     1.0000    0.5000    0.6667         4\n",
            "                heat     0.6667    0.4000    0.5000         5\n",
            "              income     1.0000    0.2857    0.4444         7\n",
            "             sunseed     0.0000    0.0000    0.0000         5\n",
            "              lumber     1.0000    0.1667    0.2857         6\n",
            "                 lei     1.0000    0.6667    0.8000         3\n",
            "                 dmk     0.0000    0.0000    0.0000         4\n",
            "                 oat     1.0000    0.1667    0.2857         6\n",
            "                 tea     0.0000    0.0000    0.0000         4\n",
            "            platinum     0.0000    0.0000    0.0000         7\n",
            "              nickel     0.0000    0.0000    0.0000         1\n",
            "           groundnut     0.0000    0.0000    0.0000         4\n",
            "            rape-oil     0.0000    0.0000    0.0000         3\n",
            "            l-cattle     0.0000    0.0000    0.0000         2\n",
            "             sun-oil     0.0000    0.0000    0.0000         2\n",
            "         coconut-oil     0.0000    0.0000    0.0000         3\n",
            "             propane     0.0000    0.0000    0.0000         3\n",
            "             coconut     0.0000    0.0000    0.0000         2\n",
            "         instal-debt     0.0000    0.0000    0.0000         1\n",
            "              potato     0.0000    0.0000    0.0000         3\n",
            "             naphtha     0.0000    0.0000    0.0000         4\n",
            "                 jet     0.0000    0.0000    0.0000         1\n",
            "               nzdlr     0.0000    0.0000    0.0000         2\n",
            "                 cpu     0.0000    0.0000    0.0000         1\n",
            "                 dfl     0.0000    0.0000    0.0000         1\n",
            "          palmkernel     0.0000    0.0000    0.0000         1\n",
            "                 nkr     0.0000    0.0000    0.0000         2\n",
            "          copra-cake     0.0000    0.0000    0.0000         1\n",
            "           palladium     0.0000    0.0000    0.0000         1\n",
            "          cotton-oil     0.0000    0.0000    0.0000         2\n",
            "                rand     0.0000    0.0000    0.0000         1\n",
            "          castor-oil     0.0000    0.0000    0.0000         1\n",
            "            sun-meal     0.0000    0.0000    0.0000         1\n",
            "       groundnut-oil     0.0000    0.0000    0.0000         1\n",
            "             lin-oil     0.0000    0.0000    0.0000         1\n",
            "                 rye     0.0000    0.0000    0.0000         1\n",
            "           macro avg     0.7415    0.5302    0.5646     11114\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'detail': {'acq': {'f1': 0.962962962962963,\n",
              "   'precision': 0.9676966292134831,\n",
              "   'recall': 0.9582753824756607,\n",
              "   'support': 719},\n",
              "  'alt.atheism': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 313},\n",
              "  'alum': {'f1': 0.5882352941176471,\n",
              "   'precision': 0.9090909090909091,\n",
              "   'recall': 0.43478260869565216,\n",
              "   'support': 23},\n",
              "  'barley': {'f1': 0.45454545454545453,\n",
              "   'precision': 0.625,\n",
              "   'recall': 0.35714285714285715,\n",
              "   'support': 14},\n",
              "  'bop': {'f1': 0.5199999999999999,\n",
              "   'precision': 0.65,\n",
              "   'recall': 0.43333333333333335,\n",
              "   'support': 30},\n",
              "  'carcass': {'f1': 0.6250000000000001,\n",
              "   'precision': 0.7142857142857143,\n",
              "   'recall': 0.5555555555555556,\n",
              "   'support': 18},\n",
              "  'castor-oil': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 1},\n",
              "  'cocoa': {'f1': 0.9714285714285714,\n",
              "   'precision': 1.0,\n",
              "   'recall': 0.9444444444444444,\n",
              "   'support': 18},\n",
              "  'coconut': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 2},\n",
              "  'coconut-oil': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 3},\n",
              "  'coffee': {'f1': 0.9259259259259259,\n",
              "   'precision': 0.9615384615384616,\n",
              "   'recall': 0.8928571428571429,\n",
              "   'support': 28},\n",
              "  'comp.graphics': {'f1': 0.27038626609442057,\n",
              "   'precision': 0.7682926829268293,\n",
              "   'recall': 0.1640625,\n",
              "   'support': 384},\n",
              "  'comp.os.ms-windows.misc': {'f1': 0.005221932114882507,\n",
              "   'precision': 1.0,\n",
              "   'recall': 0.002617801047120419,\n",
              "   'support': 382},\n",
              "  'comp.sys.ibm.pc.hardware': {'f1': 0.010230179028132991,\n",
              "   'precision': 0.5,\n",
              "   'recall': 0.00516795865633075,\n",
              "   'support': 387},\n",
              "  'comp.sys.mac.hardware': {'f1': 0.1375921375921376,\n",
              "   'precision': 0.8484848484848485,\n",
              "   'recall': 0.0748663101604278,\n",
              "   'support': 374},\n",
              "  'comp.windows.x': {'f1': 0.4994686503719448,\n",
              "   'precision': 0.4296160877513711,\n",
              "   'recall': 0.5964467005076142,\n",
              "   'support': 394},\n",
              "  'copper': {'f1': 0.6153846153846153,\n",
              "   'precision': 1.0,\n",
              "   'recall': 0.4444444444444444,\n",
              "   'support': 18},\n",
              "  'copra-cake': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 1},\n",
              "  'corn': {'f1': 0.7927927927927927,\n",
              "   'precision': 0.8,\n",
              "   'recall': 0.7857142857142857,\n",
              "   'support': 56},\n",
              "  'cotton': {'f1': 0.4444444444444444,\n",
              "   'precision': 0.8571428571428571,\n",
              "   'recall': 0.3,\n",
              "   'support': 20},\n",
              "  'cotton-oil': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 2},\n",
              "  'cpi': {'f1': 0.6190476190476191,\n",
              "   'precision': 0.9285714285714286,\n",
              "   'recall': 0.4642857142857143,\n",
              "   'support': 28},\n",
              "  'cpu': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 1},\n",
              "  'crude': {'f1': 0.8497652582159624,\n",
              "   'precision': 0.7637130801687764,\n",
              "   'recall': 0.9576719576719577,\n",
              "   'support': 189},\n",
              "  'dfl': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 1},\n",
              "  'dlr': {'f1': 0.5882352941176471,\n",
              "   'precision': 0.8333333333333334,\n",
              "   'recall': 0.45454545454545453,\n",
              "   'support': 44},\n",
              "  'dmk': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 4},\n",
              "  'earn': {'f1': 0.9766803840877916,\n",
              "   'precision': 0.9709090909090909,\n",
              "   'recall': 0.9825206991720331,\n",
              "   'support': 1087},\n",
              "  'fuel': {'f1': 0.30769230769230765,\n",
              "   'precision': 0.6666666666666666,\n",
              "   'recall': 0.2,\n",
              "   'support': 10},\n",
              "  'gas': {'f1': 0.7741935483870968,\n",
              "   'precision': 0.8571428571428571,\n",
              "   'recall': 0.7058823529411765,\n",
              "   'support': 17},\n",
              "  'gnp': {'f1': 0.7692307692307692,\n",
              "   'precision': 0.8333333333333334,\n",
              "   'recall': 0.7142857142857143,\n",
              "   'support': 35},\n",
              "  'gold': {'f1': 0.6666666666666666,\n",
              "   'precision': 0.8095238095238095,\n",
              "   'recall': 0.5666666666666667,\n",
              "   'support': 30},\n",
              "  'grain': {'f1': 0.9128919860627177,\n",
              "   'precision': 0.9492753623188406,\n",
              "   'recall': 0.8791946308724832,\n",
              "   'support': 149},\n",
              "  'groundnut': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 4},\n",
              "  'groundnut-oil': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 1},\n",
              "  'heat': {'f1': 0.5,\n",
              "   'precision': 0.6666666666666666,\n",
              "   'recall': 0.4,\n",
              "   'support': 5},\n",
              "  'hog': {'f1': 0.4,\n",
              "   'precision': 0.5,\n",
              "   'recall': 0.3333333333333333,\n",
              "   'support': 6},\n",
              "  'housing': {'f1': 0.6666666666666666,\n",
              "   'precision': 1.0,\n",
              "   'recall': 0.5,\n",
              "   'support': 4},\n",
              "  'income': {'f1': 0.4444444444444445,\n",
              "   'precision': 1.0,\n",
              "   'recall': 0.2857142857142857,\n",
              "   'support': 7},\n",
              "  'instal-debt': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 1},\n",
              "  'interest': {'f1': 0.8088235294117647,\n",
              "   'precision': 0.7801418439716312,\n",
              "   'recall': 0.8396946564885496,\n",
              "   'support': 131},\n",
              "  'ipi': {'f1': 0.9600000000000001,\n",
              "   'precision': 0.9230769230769231,\n",
              "   'recall': 1.0,\n",
              "   'support': 12},\n",
              "  'iron-steel': {'f1': 0.5714285714285714,\n",
              "   'precision': 0.8571428571428571,\n",
              "   'recall': 0.42857142857142855,\n",
              "   'support': 14},\n",
              "  'jet': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 1},\n",
              "  'jobs': {'f1': 0.7272727272727273,\n",
              "   'precision': 1.0,\n",
              "   'recall': 0.5714285714285714,\n",
              "   'support': 21},\n",
              "  'l-cattle': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 2},\n",
              "  'lead': {'f1': 0.5714285714285714,\n",
              "   'precision': 0.8571428571428571,\n",
              "   'recall': 0.42857142857142855,\n",
              "   'support': 14},\n",
              "  'lei': {'f1': 0.8,\n",
              "   'precision': 1.0,\n",
              "   'recall': 0.6666666666666666,\n",
              "   'support': 3},\n",
              "  'lin-oil': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 1},\n",
              "  'livestock': {'f1': 0.6666666666666666,\n",
              "   'precision': 0.6666666666666666,\n",
              "   'recall': 0.6666666666666666,\n",
              "   'support': 24},\n",
              "  'lumber': {'f1': 0.2857142857142857,\n",
              "   'precision': 1.0,\n",
              "   'recall': 0.16666666666666666,\n",
              "   'support': 6},\n",
              "  'meal-feed': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 19},\n",
              "  'misc.forsale': {'f1': 0.7032640949554896,\n",
              "   'precision': 0.8286713286713286,\n",
              "   'recall': 0.6108247422680413,\n",
              "   'support': 388},\n",
              "  'money-fx': {'f1': 0.7933884297520662,\n",
              "   'precision': 0.782608695652174,\n",
              "   'recall': 0.8044692737430168,\n",
              "   'support': 179},\n",
              "  'money-supply': {'f1': 0.8108108108108107,\n",
              "   'precision': 0.75,\n",
              "   'recall': 0.8823529411764706,\n",
              "   'support': 34},\n",
              "  'naphtha': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 4},\n",
              "  'nat-gas': {'f1': 0.5106382978723405,\n",
              "   'precision': 0.7058823529411765,\n",
              "   'recall': 0.4,\n",
              "   'support': 30},\n",
              "  'nickel': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 1},\n",
              "  'nkr': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 2},\n",
              "  'nzdlr': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 2},\n",
              "  'oat': {'f1': 0.2857142857142857,\n",
              "   'precision': 1.0,\n",
              "   'recall': 0.16666666666666666,\n",
              "   'support': 6},\n",
              "  'oilseed': {'f1': 0.417910447761194,\n",
              "   'precision': 0.7,\n",
              "   'recall': 0.2978723404255319,\n",
              "   'support': 47},\n",
              "  'orange': {'f1': 0.7058823529411764,\n",
              "   'precision': 1.0,\n",
              "   'recall': 0.5454545454545454,\n",
              "   'support': 11},\n",
              "  'palladium': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 1},\n",
              "  'palm-oil': {'f1': 0.588235294117647,\n",
              "   'precision': 0.7142857142857143,\n",
              "   'recall': 0.5,\n",
              "   'support': 10},\n",
              "  'palmkernel': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 1},\n",
              "  'pet-chem': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 12},\n",
              "  'platinum': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 7},\n",
              "  'potato': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 3},\n",
              "  'propane': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 3},\n",
              "  'rand': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 1},\n",
              "  'rape-oil': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 3},\n",
              "  'rapeseed': {'f1': 0.6153846153846153,\n",
              "   'precision': 1.0,\n",
              "   'recall': 0.4444444444444444,\n",
              "   'support': 9},\n",
              "  'rec.autos': {'f1': 0.6153846153846153,\n",
              "   'precision': 0.8695652173913043,\n",
              "   'recall': 0.47619047619047616,\n",
              "   'support': 378},\n",
              "  'rec.motorcycles': {'f1': 0.47908745247148293,\n",
              "   'precision': 0.9402985074626866,\n",
              "   'recall': 0.32142857142857145,\n",
              "   'support': 392},\n",
              "  'rec.sport.baseball': {'f1': 0.7247956403269755,\n",
              "   'precision': 0.7621776504297995,\n",
              "   'recall': 0.6909090909090909,\n",
              "   'support': 385},\n",
              "  'rec.sport.hockey': {'f1': 0.8011444921316165,\n",
              "   'precision': 0.9120521172638436,\n",
              "   'recall': 0.7142857142857143,\n",
              "   'support': 392},\n",
              "  'reserves': {'f1': 0.6896551724137931,\n",
              "   'precision': 0.9090909090909091,\n",
              "   'recall': 0.5555555555555556,\n",
              "   'support': 18},\n",
              "  'retail': {'f1': 0.6666666666666666,\n",
              "   'precision': 1.0,\n",
              "   'recall': 0.5,\n",
              "   'support': 2},\n",
              "  'rice': {'f1': 0.48484848484848486,\n",
              "   'precision': 0.8888888888888888,\n",
              "   'recall': 0.3333333333333333,\n",
              "   'support': 24},\n",
              "  'rubber': {'f1': 0.7368421052631579,\n",
              "   'precision': 1.0,\n",
              "   'recall': 0.5833333333333334,\n",
              "   'support': 12},\n",
              "  'rye': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 1},\n",
              "  'sci.crypt': {'f1': 0.532620320855615,\n",
              "   'precision': 0.45027124773960214,\n",
              "   'recall': 0.6518324607329843,\n",
              "   'support': 382},\n",
              "  'sci.electronics': {'f1': 0.4360189573459716,\n",
              "   'precision': 0.552,\n",
              "   'recall': 0.360313315926893,\n",
              "   'support': 383},\n",
              "  'sci.med': {'f1': 0.6845637583892618,\n",
              "   'precision': 0.9622641509433962,\n",
              "   'recall': 0.53125,\n",
              "   'support': 384},\n",
              "  'sci.space': {'f1': 0.5963636363636363,\n",
              "   'precision': 0.9820359281437125,\n",
              "   'recall': 0.4281984334203655,\n",
              "   'support': 383},\n",
              "  'ship': {'f1': 0.7239263803680981,\n",
              "   'precision': 0.7972972972972973,\n",
              "   'recall': 0.6629213483146067,\n",
              "   'support': 89},\n",
              "  'silver': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 8},\n",
              "  'soc.religion.christian': {'f1': 0.6339468302658486,\n",
              "   'precision': 0.5245346869712352,\n",
              "   'recall': 0.8010335917312662,\n",
              "   'support': 387},\n",
              "  'sorghum': {'f1': 0.18181818181818182,\n",
              "   'precision': 1.0,\n",
              "   'recall': 0.1,\n",
              "   'support': 10},\n",
              "  'soy-meal': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 13},\n",
              "  'soy-oil': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 11},\n",
              "  'soybean': {'f1': 0.15384615384615385,\n",
              "   'precision': 0.5,\n",
              "   'recall': 0.09090909090909091,\n",
              "   'support': 33},\n",
              "  'strategic-metal': {'f1': 0.0,\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'support': 11},\n",
              "  'sugar': {'f1': 0.8064516129032258,\n",
              "   'precision': 0.9615384615384616,\n",
              "   'recall': 0.6944444444444444,\n",
              "   'support': 36},\n",
              "  'sun-meal': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 1},\n",
              "  'sun-oil': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 2},\n",
              "  'sunseed': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 5},\n",
              "  'talk.politics.guns': {'f1': 0.2127659574468085,\n",
              "   'precision': 0.6716417910447762,\n",
              "   'recall': 0.12640449438202248,\n",
              "   'support': 356},\n",
              "  'talk.politics.mideast': {'f1': 0.7250341997264022,\n",
              "   'precision': 0.7402234636871509,\n",
              "   'recall': 0.710455764075067,\n",
              "   'support': 373},\n",
              "  'talk.politics.misc': {'f1': 0.41296928327645055,\n",
              "   'precision': 0.4336917562724014,\n",
              "   'recall': 0.3941368078175896,\n",
              "   'support': 307},\n",
              "  'talk.religion.misc': {'f1': 0.0,\n",
              "   'precision': 0.0,\n",
              "   'recall': 0.0,\n",
              "   'support': 246},\n",
              "  'tea': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 4},\n",
              "  'tin': {'f1': 0.5882352941176471,\n",
              "   'precision': 1.0,\n",
              "   'recall': 0.4166666666666667,\n",
              "   'support': 12},\n",
              "  'trade': {'f1': 0.7913043478260869,\n",
              "   'precision': 0.8053097345132744,\n",
              "   'recall': 0.7777777777777778,\n",
              "   'support': 117},\n",
              "  'veg-oil': {'f1': 0.5714285714285715,\n",
              "   'precision': 0.8421052631578947,\n",
              "   'recall': 0.43243243243243246,\n",
              "   'support': 37},\n",
              "  'wheat': {'f1': 0.7999999999999999,\n",
              "   'precision': 0.9259259259259259,\n",
              "   'recall': 0.704225352112676,\n",
              "   'support': 71},\n",
              "  'wpi': {'f1': 0.8235294117647058,\n",
              "   'precision': 1.0,\n",
              "   'recall': 0.7,\n",
              "   'support': 10},\n",
              "  'yen': {'f1': 0.3333333333333333,\n",
              "   'precision': 0.75,\n",
              "   'recall': 0.21428571428571427,\n",
              "   'support': 14},\n",
              "  'zinc': {'f1': 0.7272727272727274,\n",
              "   'precision': 0.8888888888888888,\n",
              "   'recall': 0.6153846153846154,\n",
              "   'support': 13}},\n",
              " 'f1-score': 0.5646481803703589,\n",
              " 'precision': 0.7414827154806805,\n",
              " 'recall': 0.5302321396436926,\n",
              " 'support': 11114}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 257
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFhPC2q9zpsm",
        "outputId": "e8f57954-1776-4fe8-86f5-feee5f2c7f3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "all_dataframes_test['title'][10360]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['money-fx']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3s6-rJGlq9BH"
      },
      "source": [
        "nltk_tokens = nltk.word_tokenize(text)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbh2CiAi0E_I"
      },
      "source": [
        "x=all_dataframes_test['text'][10360]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykcqh6DN0pyK"
      },
      "source": [
        "text=all_dataframes_test['text'][10001]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QScrCCpl2r87",
        "outputId": "764cae2b-ad6b-408b-e881-15e11a810630",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'jepson corp qtr net shr ct v ct net v sale mln v mln avg shrs mln v mln nine mths shr ct v ct net mln v mln sale mln v mln avg shrs mln v mln qtr per share reflects issuance of two mln share in initial public nine mth result include extraordinary gain of dlrs or ct'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od1HY3sr6JLz"
      },
      "source": [
        "all_dataframes_train.to_csv(\"train_allDatasets.csv\")\n",
        "all_dataframes_test.to_csv(\"test_allDatasets.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1eT7Wij6Vf_"
      },
      "source": [
        "!cp '/content/train_allDatasets.csv' '/content/drive/My Drive/'\n",
        "!cp '/content/test_allDatasets.csv' '/content/drive/My Drive/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJVFQ1gr6rQH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}